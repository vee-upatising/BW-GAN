{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.color import rgb2gray, gray2rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "        color = []\n",
    "        bw = []\n",
    "        paths = []\n",
    "        #get all files in this folder\n",
    "        for r, d, f in os.walk(r\"E:\\DF\\DFL2\\workspace\\bw\"):\n",
    "            for file in f:\n",
    "                if '.jpg' in file:\n",
    "                    paths.append(os.path.join(r, file))\n",
    "        #for each file add normal resolution and small resolution to arrays\n",
    "        for path in paths:\n",
    "            img = Image.open(path)\n",
    "            x = img.resize((128,128))\n",
    "            bw.append(np.array(x))\n",
    "        del paths    \n",
    "        paths = []\n",
    "        for r, d, f in os.walk(r\"E:\\DF\\DFL2\\workspace\\color\"):\n",
    "            for file in f:\n",
    "                if '.jpg' in file:\n",
    "                    paths.append(os.path.join(r, file))\n",
    "\n",
    "        for path in paths:\n",
    "            img = Image.open(path)\n",
    "            x = img.resize((128,128))\n",
    "            color.append(np.array(x))\n",
    "            \n",
    "        #reshaping data to be four dimension required for input to neural network\n",
    "        y_train = np.array(color)\n",
    "        y_train = y_train.reshape(len(color),128,128,3)\n",
    "        x_train = np.array(bw)\n",
    "        x_train = x_train.reshape(len(bw),128,128,3)\n",
    "        return y_train, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Shape of high resolution output image\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        # Shape of low resolution input image\n",
    "        self.latent_dim = (128,128,3)\n",
    "\n",
    "        #optimizer (learning rate and beta values)\n",
    "        optimizer = Adam(0.0001, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "        generator = self.generator\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=self.latent_dim)\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(140, input_shape=(128, 128, 3), kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(140, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(140, kernel_size=(2,2), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(140, kernel_size=(4,4), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(140, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(140, kernel_size=(3,3), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Conv2D(3, kernel_size=(2,2), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=self.latent_dim)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "    \n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        Y_train, X_train = load_data()\n",
    "\n",
    "        # Rescale to be between 0 & 1\n",
    "        X_train = X_train / 255\n",
    "        Y_train = Y_train / 255\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        # Placeholder for loss function values\n",
    "        g_loss_epochs = np.zeros((epochs, 1))\n",
    "        d_loss_epochs = np.zeros((epochs, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, Y_train.shape[0], batch_size)\n",
    "            imgs = Y_train[idx]\n",
    "\n",
    "            # Generate super resolution images from the random batch of images\n",
    "            gen_imgs = self.generator.predict(X_train[idx])\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(X_train[idx], valid)\n",
    "            \n",
    "            #save loss history\n",
    "            g_loss_epochs[epoch] = g_loss\n",
    "            d_loss_epochs[epoch] = d_loss[0]\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch, X_train, idx)\n",
    "                \n",
    "        return g_loss_epochs, d_loss_epochs\n",
    "\n",
    "    def save_imgs(self, epoch, X_train, idx):\n",
    "        r, c = 3, 3\n",
    "        # Select 9 random images\n",
    "        index = np.random.randint(0, X_train.shape[0], 9)\n",
    "        images = X_train[idx]\n",
    "        # Super resolution the images\n",
    "        gen_imgs = self.generator.predict(images)\n",
    "        gen_imgs = np.array(gen_imgs) * 255\n",
    "        gen_imgs = gen_imgs.astype(int)\n",
    "        # Plot each image\n",
    "        fig=plt.figure(figsize=(20, 20))\n",
    "        for i in range(1, c*r+1):\n",
    "            img = gen_imgs[i-1]\n",
    "            fig.add_subplot(r, c, i)\n",
    "            plt.imshow(img)\n",
    "        fig.savefig(r\"C:\\Users\\Vee\\Desktop\\python\\GAN\\epoch_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "        # save model to .h5 file\n",
    "        self.generator.save(\"generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65537     \n",
      "=================================================================\n",
      "Total params: 455,745\n",
      "Trainable params: 454,849\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 128, 128, 140)     3920      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 128, 128, 140)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 128, 128, 140)     176540    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 128, 128, 140)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 128, 128, 140)     78540     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 128, 128, 140)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 128, 140)     313740    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 128, 128, 140)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 128, 128, 140)     176540    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 128, 128, 140)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 128, 128, 140)     176540    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 128, 128, 140)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 128, 128, 3)       1683      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 927,503\n",
      "Trainable params: 927,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = SRGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.241861, acc.: 38.89%] [G loss: 0.643162]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vee\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 0.698089, acc.: 55.56%] [G loss: 1.060630]\n",
      "2 [D loss: 0.983266, acc.: 27.78%] [G loss: 1.045596]\n",
      "3 [D loss: 0.782481, acc.: 44.44%] [G loss: 1.431036]\n",
      "4 [D loss: 0.797676, acc.: 44.44%] [G loss: 1.488469]\n",
      "5 [D loss: 1.516940, acc.: 16.67%] [G loss: 0.989677]\n",
      "6 [D loss: 0.861779, acc.: 33.33%] [G loss: 0.991150]\n",
      "7 [D loss: 0.918415, acc.: 55.56%] [G loss: 0.671598]\n",
      "8 [D loss: 1.094389, acc.: 27.78%] [G loss: 0.870130]\n",
      "9 [D loss: 1.107681, acc.: 33.33%] [G loss: 2.210557]\n",
      "10 [D loss: 0.767895, acc.: 61.11%] [G loss: 1.550735]\n",
      "11 [D loss: 0.568156, acc.: 66.67%] [G loss: 1.082131]\n",
      "12 [D loss: 0.820658, acc.: 50.00%] [G loss: 1.641689]\n",
      "13 [D loss: 1.011848, acc.: 33.33%] [G loss: 1.151701]\n",
      "14 [D loss: 0.735364, acc.: 50.00%] [G loss: 1.045194]\n",
      "15 [D loss: 0.565102, acc.: 66.67%] [G loss: 1.200214]\n",
      "16 [D loss: 0.600385, acc.: 55.56%] [G loss: 1.198238]\n",
      "17 [D loss: 0.634257, acc.: 72.22%] [G loss: 1.160763]\n",
      "18 [D loss: 0.778912, acc.: 50.00%] [G loss: 0.946984]\n",
      "19 [D loss: 0.631237, acc.: 72.22%] [G loss: 1.147023]\n",
      "20 [D loss: 0.782208, acc.: 38.89%] [G loss: 1.255677]\n",
      "21 [D loss: 0.998128, acc.: 33.33%] [G loss: 1.481932]\n",
      "22 [D loss: 0.769197, acc.: 50.00%] [G loss: 1.163323]\n",
      "23 [D loss: 0.739913, acc.: 44.44%] [G loss: 1.401618]\n",
      "24 [D loss: 0.998324, acc.: 38.89%] [G loss: 1.410603]\n",
      "25 [D loss: 0.820447, acc.: 27.78%] [G loss: 1.198738]\n",
      "26 [D loss: 0.773487, acc.: 50.00%] [G loss: 1.114215]\n",
      "27 [D loss: 0.700567, acc.: 55.56%] [G loss: 1.348112]\n",
      "28 [D loss: 1.136984, acc.: 27.78%] [G loss: 2.120031]\n",
      "29 [D loss: 1.287085, acc.: 38.89%] [G loss: 1.257045]\n",
      "30 [D loss: 0.710911, acc.: 61.11%] [G loss: 1.883358]\n",
      "31 [D loss: 0.649093, acc.: 66.67%] [G loss: 1.282009]\n",
      "32 [D loss: 0.897980, acc.: 50.00%] [G loss: 1.111344]\n",
      "33 [D loss: 1.169944, acc.: 27.78%] [G loss: 0.999126]\n",
      "34 [D loss: 0.986495, acc.: 22.22%] [G loss: 1.174431]\n",
      "35 [D loss: 0.725047, acc.: 55.56%] [G loss: 1.831366]\n",
      "36 [D loss: 0.991029, acc.: 38.89%] [G loss: 1.441205]\n",
      "37 [D loss: 0.746611, acc.: 55.56%] [G loss: 0.854079]\n",
      "38 [D loss: 0.957142, acc.: 44.44%] [G loss: 1.853884]\n",
      "39 [D loss: 1.126674, acc.: 22.22%] [G loss: 1.432855]\n",
      "40 [D loss: 0.870051, acc.: 50.00%] [G loss: 1.005290]\n",
      "41 [D loss: 0.937452, acc.: 50.00%] [G loss: 1.084483]\n",
      "42 [D loss: 1.125099, acc.: 11.11%] [G loss: 0.911981]\n",
      "43 [D loss: 0.977755, acc.: 44.44%] [G loss: 1.139051]\n",
      "44 [D loss: 0.986032, acc.: 27.78%] [G loss: 1.269130]\n",
      "45 [D loss: 0.848751, acc.: 50.00%] [G loss: 1.050790]\n",
      "46 [D loss: 0.837420, acc.: 61.11%] [G loss: 1.214468]\n",
      "47 [D loss: 0.920114, acc.: 55.56%] [G loss: 1.225270]\n",
      "48 [D loss: 1.092298, acc.: 16.67%] [G loss: 1.308899]\n",
      "49 [D loss: 0.921939, acc.: 22.22%] [G loss: 1.576055]\n",
      "50 [D loss: 1.321740, acc.: 22.22%] [G loss: 1.229161]\n",
      "51 [D loss: 0.951058, acc.: 44.44%] [G loss: 1.550142]\n",
      "52 [D loss: 1.089322, acc.: 38.89%] [G loss: 1.509915]\n",
      "53 [D loss: 0.783750, acc.: 44.44%] [G loss: 0.901726]\n",
      "54 [D loss: 0.856396, acc.: 44.44%] [G loss: 1.985598]\n",
      "55 [D loss: 0.800491, acc.: 61.11%] [G loss: 1.556362]\n",
      "56 [D loss: 0.829244, acc.: 33.33%] [G loss: 0.998495]\n",
      "57 [D loss: 0.740919, acc.: 55.56%] [G loss: 1.440442]\n",
      "58 [D loss: 0.954467, acc.: 44.44%] [G loss: 1.681062]\n",
      "59 [D loss: 0.637219, acc.: 66.67%] [G loss: 1.792579]\n",
      "60 [D loss: 0.809090, acc.: 38.89%] [G loss: 1.409409]\n",
      "61 [D loss: 0.821827, acc.: 38.89%] [G loss: 0.964776]\n",
      "62 [D loss: 1.101654, acc.: 50.00%] [G loss: 0.965920]\n",
      "63 [D loss: 1.081613, acc.: 33.33%] [G loss: 1.185699]\n",
      "64 [D loss: 0.709065, acc.: 61.11%] [G loss: 2.051438]\n",
      "65 [D loss: 1.039694, acc.: 38.89%] [G loss: 1.175626]\n",
      "66 [D loss: 0.861188, acc.: 44.44%] [G loss: 1.042210]\n",
      "67 [D loss: 0.926252, acc.: 27.78%] [G loss: 0.969103]\n",
      "68 [D loss: 0.778778, acc.: 50.00%] [G loss: 1.397316]\n",
      "69 [D loss: 0.797752, acc.: 55.56%] [G loss: 1.490056]\n",
      "70 [D loss: 1.206113, acc.: 22.22%] [G loss: 1.679930]\n",
      "71 [D loss: 0.837718, acc.: 55.56%] [G loss: 1.275477]\n",
      "72 [D loss: 1.050444, acc.: 44.44%] [G loss: 1.645613]\n",
      "73 [D loss: 1.185287, acc.: 33.33%] [G loss: 1.103621]\n",
      "74 [D loss: 0.956968, acc.: 33.33%] [G loss: 1.371606]\n",
      "75 [D loss: 0.801808, acc.: 61.11%] [G loss: 1.447968]\n",
      "76 [D loss: 0.863458, acc.: 61.11%] [G loss: 0.747521]\n",
      "77 [D loss: 0.886215, acc.: 38.89%] [G loss: 0.902683]\n",
      "78 [D loss: 1.105314, acc.: 27.78%] [G loss: 1.348109]\n",
      "79 [D loss: 1.294299, acc.: 22.22%] [G loss: 1.068505]\n",
      "80 [D loss: 1.108543, acc.: 50.00%] [G loss: 1.007666]\n",
      "81 [D loss: 0.623485, acc.: 66.67%] [G loss: 1.119028]\n",
      "82 [D loss: 1.006963, acc.: 50.00%] [G loss: 1.351679]\n",
      "83 [D loss: 0.895152, acc.: 55.56%] [G loss: 1.053608]\n",
      "84 [D loss: 0.723225, acc.: 55.56%] [G loss: 0.661883]\n",
      "85 [D loss: 1.321854, acc.: 27.78%] [G loss: 0.631363]\n",
      "86 [D loss: 0.940650, acc.: 55.56%] [G loss: 1.910720]\n",
      "87 [D loss: 0.840913, acc.: 38.89%] [G loss: 1.386272]\n",
      "88 [D loss: 1.121109, acc.: 50.00%] [G loss: 1.008342]\n",
      "89 [D loss: 1.158138, acc.: 33.33%] [G loss: 0.841509]\n",
      "90 [D loss: 0.876895, acc.: 33.33%] [G loss: 1.170904]\n",
      "91 [D loss: 1.077547, acc.: 27.78%] [G loss: 1.461003]\n",
      "92 [D loss: 0.996623, acc.: 50.00%] [G loss: 1.263720]\n",
      "93 [D loss: 0.733326, acc.: 66.67%] [G loss: 1.741582]\n",
      "94 [D loss: 0.907611, acc.: 38.89%] [G loss: 1.209696]\n",
      "95 [D loss: 1.017260, acc.: 38.89%] [G loss: 0.856649]\n",
      "96 [D loss: 0.786148, acc.: 50.00%] [G loss: 0.904866]\n",
      "97 [D loss: 0.751573, acc.: 55.56%] [G loss: 1.330754]\n",
      "98 [D loss: 0.685408, acc.: 50.00%] [G loss: 0.965118]\n",
      "99 [D loss: 0.612051, acc.: 61.11%] [G loss: 1.061697]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [D loss: 0.845433, acc.: 50.00%] [G loss: 1.176494]\n",
      "101 [D loss: 0.788930, acc.: 55.56%] [G loss: 1.451260]\n",
      "102 [D loss: 0.952482, acc.: 61.11%] [G loss: 1.074226]\n",
      "103 [D loss: 1.049214, acc.: 44.44%] [G loss: 0.661225]\n",
      "104 [D loss: 0.894101, acc.: 44.44%] [G loss: 1.615635]\n",
      "105 [D loss: 0.782345, acc.: 61.11%] [G loss: 1.276914]\n",
      "106 [D loss: 0.883786, acc.: 50.00%] [G loss: 1.172078]\n",
      "107 [D loss: 0.860518, acc.: 44.44%] [G loss: 1.113612]\n",
      "108 [D loss: 0.624958, acc.: 66.67%] [G loss: 1.616206]\n",
      "109 [D loss: 0.684313, acc.: 66.67%] [G loss: 1.438591]\n",
      "110 [D loss: 0.631432, acc.: 55.56%] [G loss: 1.637309]\n",
      "111 [D loss: 0.720476, acc.: 72.22%] [G loss: 1.520622]\n",
      "112 [D loss: 0.614186, acc.: 55.56%] [G loss: 1.412775]\n",
      "113 [D loss: 0.906349, acc.: 50.00%] [G loss: 1.168801]\n",
      "114 [D loss: 0.785656, acc.: 55.56%] [G loss: 0.960615]\n",
      "115 [D loss: 0.662321, acc.: 55.56%] [G loss: 1.156406]\n",
      "116 [D loss: 0.763998, acc.: 55.56%] [G loss: 1.498067]\n",
      "117 [D loss: 0.625139, acc.: 83.33%] [G loss: 2.189833]\n",
      "118 [D loss: 0.831233, acc.: 38.89%] [G loss: 1.316714]\n",
      "119 [D loss: 0.955031, acc.: 38.89%] [G loss: 1.131478]\n",
      "120 [D loss: 0.841932, acc.: 61.11%] [G loss: 1.111174]\n",
      "121 [D loss: 0.727864, acc.: 66.67%] [G loss: 1.129182]\n",
      "122 [D loss: 0.693866, acc.: 55.56%] [G loss: 0.964549]\n",
      "123 [D loss: 1.052055, acc.: 44.44%] [G loss: 1.010629]\n",
      "124 [D loss: 0.774452, acc.: 50.00%] [G loss: 1.269252]\n",
      "125 [D loss: 0.616570, acc.: 66.67%] [G loss: 1.367303]\n",
      "126 [D loss: 0.707169, acc.: 61.11%] [G loss: 1.008464]\n",
      "127 [D loss: 1.573266, acc.: 22.22%] [G loss: 1.275286]\n",
      "128 [D loss: 0.928408, acc.: 44.44%] [G loss: 1.292626]\n",
      "129 [D loss: 0.694408, acc.: 55.56%] [G loss: 1.298988]\n",
      "130 [D loss: 0.915095, acc.: 55.56%] [G loss: 0.871758]\n",
      "131 [D loss: 0.555390, acc.: 61.11%] [G loss: 1.764419]\n",
      "132 [D loss: 0.475467, acc.: 77.78%] [G loss: 1.503565]\n",
      "133 [D loss: 0.766960, acc.: 61.11%] [G loss: 1.607896]\n",
      "134 [D loss: 0.893753, acc.: 38.89%] [G loss: 1.321417]\n",
      "135 [D loss: 0.697291, acc.: 61.11%] [G loss: 1.464682]\n",
      "136 [D loss: 0.927652, acc.: 55.56%] [G loss: 1.066873]\n",
      "137 [D loss: 0.924590, acc.: 50.00%] [G loss: 1.618116]\n",
      "138 [D loss: 0.624297, acc.: 72.22%] [G loss: 1.576691]\n",
      "139 [D loss: 0.637672, acc.: 61.11%] [G loss: 0.955511]\n",
      "140 [D loss: 0.510933, acc.: 77.78%] [G loss: 0.850582]\n",
      "141 [D loss: 0.696873, acc.: 50.00%] [G loss: 1.129470]\n",
      "142 [D loss: 0.647257, acc.: 66.67%] [G loss: 1.365941]\n",
      "143 [D loss: 1.048815, acc.: 44.44%] [G loss: 1.181937]\n",
      "144 [D loss: 0.609225, acc.: 66.67%] [G loss: 1.723996]\n",
      "145 [D loss: 0.777068, acc.: 55.56%] [G loss: 2.382358]\n",
      "146 [D loss: 0.484139, acc.: 77.78%] [G loss: 1.631496]\n",
      "147 [D loss: 0.718778, acc.: 55.56%] [G loss: 1.087056]\n",
      "148 [D loss: 0.616372, acc.: 72.22%] [G loss: 1.531173]\n",
      "149 [D loss: 0.568073, acc.: 66.67%] [G loss: 1.550527]\n",
      "150 [D loss: 1.185410, acc.: 27.78%] [G loss: 1.342916]\n",
      "151 [D loss: 0.529907, acc.: 72.22%] [G loss: 1.557693]\n",
      "152 [D loss: 0.523939, acc.: 72.22%] [G loss: 1.021138]\n",
      "153 [D loss: 0.609336, acc.: 72.22%] [G loss: 1.830896]\n",
      "154 [D loss: 0.712630, acc.: 55.56%] [G loss: 1.366408]\n",
      "155 [D loss: 0.728518, acc.: 61.11%] [G loss: 1.254792]\n",
      "156 [D loss: 0.742337, acc.: 61.11%] [G loss: 1.393445]\n",
      "157 [D loss: 1.088871, acc.: 50.00%] [G loss: 1.165100]\n",
      "158 [D loss: 1.485079, acc.: 33.33%] [G loss: 1.258178]\n",
      "159 [D loss: 0.906855, acc.: 61.11%] [G loss: 1.494235]\n",
      "160 [D loss: 0.721115, acc.: 61.11%] [G loss: 1.398684]\n",
      "161 [D loss: 0.769458, acc.: 61.11%] [G loss: 1.675756]\n",
      "162 [D loss: 0.605820, acc.: 55.56%] [G loss: 1.231624]\n",
      "163 [D loss: 0.579597, acc.: 66.67%] [G loss: 1.110966]\n",
      "164 [D loss: 0.755890, acc.: 61.11%] [G loss: 1.397096]\n",
      "165 [D loss: 0.887651, acc.: 33.33%] [G loss: 1.406122]\n",
      "166 [D loss: 0.813220, acc.: 66.67%] [G loss: 1.144846]\n",
      "167 [D loss: 0.812469, acc.: 66.67%] [G loss: 1.951348]\n",
      "168 [D loss: 1.268588, acc.: 38.89%] [G loss: 0.783138]\n",
      "169 [D loss: 0.689061, acc.: 77.78%] [G loss: 2.007259]\n",
      "170 [D loss: 0.559448, acc.: 72.22%] [G loss: 2.383056]\n",
      "171 [D loss: 0.608904, acc.: 55.56%] [G loss: 1.862422]\n",
      "172 [D loss: 0.595687, acc.: 61.11%] [G loss: 1.290228]\n",
      "173 [D loss: 0.472182, acc.: 77.78%] [G loss: 1.480977]\n",
      "174 [D loss: 0.493163, acc.: 66.67%] [G loss: 1.257176]\n",
      "175 [D loss: 0.817852, acc.: 61.11%] [G loss: 2.039597]\n",
      "176 [D loss: 0.520962, acc.: 72.22%] [G loss: 1.765107]\n",
      "177 [D loss: 0.512015, acc.: 83.33%] [G loss: 1.856750]\n",
      "178 [D loss: 0.354739, acc.: 77.78%] [G loss: 2.328713]\n",
      "179 [D loss: 0.864877, acc.: 66.67%] [G loss: 1.867367]\n",
      "180 [D loss: 0.585167, acc.: 72.22%] [G loss: 1.563958]\n",
      "181 [D loss: 0.924265, acc.: 38.89%] [G loss: 1.210351]\n",
      "182 [D loss: 0.389002, acc.: 88.89%] [G loss: 2.563303]\n",
      "183 [D loss: 0.781136, acc.: 61.11%] [G loss: 2.181373]\n",
      "184 [D loss: 0.583023, acc.: 72.22%] [G loss: 2.515199]\n",
      "185 [D loss: 0.940295, acc.: 61.11%] [G loss: 1.559184]\n",
      "186 [D loss: 0.257865, acc.: 94.44%] [G loss: 1.727646]\n",
      "187 [D loss: 1.081133, acc.: 44.44%] [G loss: 1.015215]\n",
      "188 [D loss: 0.506630, acc.: 83.33%] [G loss: 2.027426]\n",
      "189 [D loss: 0.393502, acc.: 83.33%] [G loss: 2.320972]\n",
      "190 [D loss: 0.685893, acc.: 55.56%] [G loss: 2.388633]\n",
      "191 [D loss: 0.910807, acc.: 44.44%] [G loss: 1.546019]\n",
      "192 [D loss: 0.705520, acc.: 66.67%] [G loss: 1.571861]\n",
      "193 [D loss: 0.700633, acc.: 61.11%] [G loss: 1.660370]\n",
      "194 [D loss: 1.013474, acc.: 50.00%] [G loss: 1.549975]\n",
      "195 [D loss: 0.629332, acc.: 61.11%] [G loss: 1.842437]\n",
      "196 [D loss: 0.771775, acc.: 55.56%] [G loss: 1.740638]\n",
      "197 [D loss: 0.739904, acc.: 55.56%] [G loss: 1.655931]\n",
      "198 [D loss: 0.514809, acc.: 72.22%] [G loss: 1.715576]\n",
      "199 [D loss: 1.155588, acc.: 38.89%] [G loss: 1.521139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 [D loss: 0.506576, acc.: 72.22%] [G loss: 2.384385]\n",
      "201 [D loss: 0.551524, acc.: 83.33%] [G loss: 1.727799]\n",
      "202 [D loss: 0.778060, acc.: 66.67%] [G loss: 2.130105]\n",
      "203 [D loss: 0.725451, acc.: 61.11%] [G loss: 2.088233]\n",
      "204 [D loss: 0.653426, acc.: 66.67%] [G loss: 1.297491]\n",
      "205 [D loss: 0.362336, acc.: 83.33%] [G loss: 2.113538]\n",
      "206 [D loss: 0.490341, acc.: 88.89%] [G loss: 2.227776]\n",
      "207 [D loss: 0.955367, acc.: 33.33%] [G loss: 1.309420]\n",
      "208 [D loss: 0.525461, acc.: 66.67%] [G loss: 1.336871]\n",
      "209 [D loss: 0.930421, acc.: 55.56%] [G loss: 1.825904]\n",
      "210 [D loss: 0.806819, acc.: 61.11%] [G loss: 1.252194]\n",
      "211 [D loss: 0.946715, acc.: 55.56%] [G loss: 1.469252]\n",
      "212 [D loss: 0.470497, acc.: 66.67%] [G loss: 1.175391]\n",
      "213 [D loss: 0.680853, acc.: 50.00%] [G loss: 1.799997]\n",
      "214 [D loss: 0.552538, acc.: 72.22%] [G loss: 1.628736]\n",
      "215 [D loss: 0.549604, acc.: 72.22%] [G loss: 2.060259]\n",
      "216 [D loss: 1.073797, acc.: 38.89%] [G loss: 1.488295]\n",
      "217 [D loss: 0.691857, acc.: 66.67%] [G loss: 1.698245]\n",
      "218 [D loss: 0.749823, acc.: 66.67%] [G loss: 2.719739]\n",
      "219 [D loss: 0.365564, acc.: 88.89%] [G loss: 2.647946]\n",
      "220 [D loss: 0.664328, acc.: 61.11%] [G loss: 1.555228]\n",
      "221 [D loss: 0.754072, acc.: 55.56%] [G loss: 1.280551]\n",
      "222 [D loss: 0.777203, acc.: 50.00%] [G loss: 1.460634]\n",
      "223 [D loss: 0.471203, acc.: 66.67%] [G loss: 2.057675]\n",
      "224 [D loss: 0.531955, acc.: 77.78%] [G loss: 1.614749]\n",
      "225 [D loss: 0.300484, acc.: 94.44%] [G loss: 1.802923]\n",
      "226 [D loss: 0.427845, acc.: 77.78%] [G loss: 1.647118]\n",
      "227 [D loss: 0.502177, acc.: 72.22%] [G loss: 1.489141]\n",
      "228 [D loss: 0.643194, acc.: 61.11%] [G loss: 1.451522]\n",
      "229 [D loss: 0.650736, acc.: 66.67%] [G loss: 2.353789]\n",
      "230 [D loss: 1.022661, acc.: 50.00%] [G loss: 2.268456]\n",
      "231 [D loss: 0.565731, acc.: 72.22%] [G loss: 1.715285]\n",
      "232 [D loss: 0.686666, acc.: 66.67%] [G loss: 1.778952]\n",
      "233 [D loss: 0.634308, acc.: 72.22%] [G loss: 2.313183]\n",
      "234 [D loss: 0.605019, acc.: 72.22%] [G loss: 1.812113]\n",
      "235 [D loss: 1.069464, acc.: 38.89%] [G loss: 1.391672]\n",
      "236 [D loss: 0.587785, acc.: 77.78%] [G loss: 1.824835]\n",
      "237 [D loss: 0.670146, acc.: 61.11%] [G loss: 2.153077]\n",
      "238 [D loss: 1.036061, acc.: 50.00%] [G loss: 1.832703]\n",
      "239 [D loss: 0.592281, acc.: 77.78%] [G loss: 1.930371]\n",
      "240 [D loss: 0.693727, acc.: 55.56%] [G loss: 1.703517]\n",
      "241 [D loss: 0.576178, acc.: 61.11%] [G loss: 2.092103]\n",
      "242 [D loss: 0.586389, acc.: 66.67%] [G loss: 2.488233]\n",
      "243 [D loss: 0.975874, acc.: 38.89%] [G loss: 1.527111]\n",
      "244 [D loss: 0.538100, acc.: 77.78%] [G loss: 2.065932]\n",
      "245 [D loss: 0.940876, acc.: 44.44%] [G loss: 1.714539]\n",
      "246 [D loss: 0.643148, acc.: 55.56%] [G loss: 1.608728]\n",
      "247 [D loss: 0.735982, acc.: 61.11%] [G loss: 1.959297]\n",
      "248 [D loss: 0.528242, acc.: 66.67%] [G loss: 2.247179]\n",
      "249 [D loss: 0.750340, acc.: 55.56%] [G loss: 2.035542]\n",
      "250 [D loss: 0.616561, acc.: 83.33%] [G loss: 2.445543]\n",
      "251 [D loss: 0.700067, acc.: 66.67%] [G loss: 1.958177]\n",
      "252 [D loss: 0.790889, acc.: 55.56%] [G loss: 1.686576]\n",
      "253 [D loss: 0.782433, acc.: 50.00%] [G loss: 1.233723]\n",
      "254 [D loss: 0.762906, acc.: 55.56%] [G loss: 1.635959]\n",
      "255 [D loss: 0.409362, acc.: 83.33%] [G loss: 2.150575]\n",
      "256 [D loss: 0.757855, acc.: 66.67%] [G loss: 2.502234]\n",
      "257 [D loss: 0.793428, acc.: 61.11%] [G loss: 1.916989]\n",
      "258 [D loss: 1.004842, acc.: 44.44%] [G loss: 1.701820]\n",
      "259 [D loss: 0.622699, acc.: 61.11%] [G loss: 1.856346]\n",
      "260 [D loss: 1.105528, acc.: 44.44%] [G loss: 1.417704]\n",
      "261 [D loss: 0.373933, acc.: 83.33%] [G loss: 3.041941]\n",
      "262 [D loss: 0.762261, acc.: 72.22%] [G loss: 3.029808]\n",
      "263 [D loss: 0.587878, acc.: 83.33%] [G loss: 2.633995]\n",
      "264 [D loss: 0.931687, acc.: 50.00%] [G loss: 1.371071]\n",
      "265 [D loss: 0.654761, acc.: 61.11%] [G loss: 1.766037]\n",
      "266 [D loss: 0.865249, acc.: 55.56%] [G loss: 2.015190]\n",
      "267 [D loss: 0.669237, acc.: 66.67%] [G loss: 2.695786]\n",
      "268 [D loss: 0.954934, acc.: 61.11%] [G loss: 1.520448]\n",
      "269 [D loss: 0.645123, acc.: 61.11%] [G loss: 2.378214]\n",
      "270 [D loss: 0.875286, acc.: 50.00%] [G loss: 1.514915]\n",
      "271 [D loss: 0.611676, acc.: 72.22%] [G loss: 1.855829]\n",
      "272 [D loss: 0.630657, acc.: 66.67%] [G loss: 2.703288]\n",
      "273 [D loss: 0.648146, acc.: 66.67%] [G loss: 1.790176]\n",
      "274 [D loss: 0.448169, acc.: 77.78%] [G loss: 2.247725]\n",
      "275 [D loss: 0.420294, acc.: 83.33%] [G loss: 2.518641]\n",
      "276 [D loss: 0.423028, acc.: 83.33%] [G loss: 2.224880]\n",
      "277 [D loss: 0.471108, acc.: 77.78%] [G loss: 1.910463]\n",
      "278 [D loss: 0.384667, acc.: 83.33%] [G loss: 2.188259]\n",
      "279 [D loss: 1.203595, acc.: 33.33%] [G loss: 1.161413]\n",
      "280 [D loss: 0.435062, acc.: 77.78%] [G loss: 2.107195]\n",
      "281 [D loss: 0.723754, acc.: 66.67%] [G loss: 1.998340]\n",
      "282 [D loss: 0.305461, acc.: 94.44%] [G loss: 2.662251]\n",
      "283 [D loss: 0.316838, acc.: 94.44%] [G loss: 3.158751]\n",
      "284 [D loss: 0.372083, acc.: 88.89%] [G loss: 1.797150]\n",
      "285 [D loss: 0.754525, acc.: 66.67%] [G loss: 1.493023]\n",
      "286 [D loss: 0.464792, acc.: 83.33%] [G loss: 1.710182]\n",
      "287 [D loss: 0.402318, acc.: 77.78%] [G loss: 2.199107]\n",
      "288 [D loss: 0.367216, acc.: 77.78%] [G loss: 2.136773]\n",
      "289 [D loss: 0.610666, acc.: 66.67%] [G loss: 1.367853]\n",
      "290 [D loss: 0.502342, acc.: 72.22%] [G loss: 2.204026]\n",
      "291 [D loss: 0.560950, acc.: 83.33%] [G loss: 2.124992]\n",
      "292 [D loss: 0.593545, acc.: 61.11%] [G loss: 2.644329]\n",
      "293 [D loss: 0.629930, acc.: 72.22%] [G loss: 1.918257]\n",
      "294 [D loss: 0.396780, acc.: 88.89%] [G loss: 2.555627]\n",
      "295 [D loss: 0.517934, acc.: 72.22%] [G loss: 1.482986]\n",
      "296 [D loss: 0.898809, acc.: 61.11%] [G loss: 1.747344]\n",
      "297 [D loss: 0.944104, acc.: 55.56%] [G loss: 1.994745]\n",
      "298 [D loss: 0.489415, acc.: 88.89%] [G loss: 1.873231]\n",
      "299 [D loss: 0.310812, acc.: 83.33%] [G loss: 1.981289]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 [D loss: 0.514149, acc.: 61.11%] [G loss: 2.392108]\n",
      "301 [D loss: 0.398424, acc.: 77.78%] [G loss: 1.555033]\n",
      "302 [D loss: 0.512275, acc.: 72.22%] [G loss: 2.287497]\n",
      "303 [D loss: 0.677725, acc.: 61.11%] [G loss: 1.612335]\n",
      "304 [D loss: 0.478175, acc.: 77.78%] [G loss: 2.248823]\n",
      "305 [D loss: 0.727622, acc.: 61.11%] [G loss: 2.051540]\n",
      "306 [D loss: 0.656498, acc.: 55.56%] [G loss: 2.412808]\n",
      "307 [D loss: 0.452266, acc.: 77.78%] [G loss: 2.955607]\n",
      "308 [D loss: 1.170876, acc.: 33.33%] [G loss: 1.516048]\n",
      "309 [D loss: 0.360153, acc.: 83.33%] [G loss: 1.813098]\n",
      "310 [D loss: 0.425824, acc.: 77.78%] [G loss: 2.822497]\n",
      "311 [D loss: 0.499733, acc.: 77.78%] [G loss: 2.194987]\n",
      "312 [D loss: 0.734565, acc.: 72.22%] [G loss: 1.090282]\n",
      "313 [D loss: 0.950397, acc.: 55.56%] [G loss: 1.069301]\n",
      "314 [D loss: 0.531640, acc.: 72.22%] [G loss: 1.877259]\n",
      "315 [D loss: 0.574820, acc.: 72.22%] [G loss: 2.639818]\n",
      "316 [D loss: 0.592834, acc.: 72.22%] [G loss: 1.462427]\n",
      "317 [D loss: 0.889891, acc.: 50.00%] [G loss: 1.678645]\n",
      "318 [D loss: 0.302175, acc.: 83.33%] [G loss: 2.348203]\n",
      "319 [D loss: 0.658982, acc.: 77.78%] [G loss: 2.701087]\n",
      "320 [D loss: 0.766732, acc.: 72.22%] [G loss: 1.800736]\n",
      "321 [D loss: 0.946846, acc.: 55.56%] [G loss: 0.877877]\n",
      "322 [D loss: 0.927937, acc.: 44.44%] [G loss: 1.668865]\n",
      "323 [D loss: 0.301033, acc.: 94.44%] [G loss: 2.975396]\n",
      "324 [D loss: 0.572395, acc.: 72.22%] [G loss: 1.942884]\n",
      "325 [D loss: 0.425481, acc.: 88.89%] [G loss: 2.329947]\n",
      "326 [D loss: 0.560915, acc.: 77.78%] [G loss: 1.713805]\n",
      "327 [D loss: 0.764320, acc.: 61.11%] [G loss: 2.125698]\n",
      "328 [D loss: 0.344001, acc.: 88.89%] [G loss: 2.397113]\n",
      "329 [D loss: 0.875167, acc.: 61.11%] [G loss: 1.925791]\n",
      "330 [D loss: 0.701535, acc.: 88.89%] [G loss: 2.135354]\n",
      "331 [D loss: 0.790952, acc.: 61.11%] [G loss: 1.625968]\n",
      "332 [D loss: 0.797203, acc.: 66.67%] [G loss: 1.846173]\n",
      "333 [D loss: 1.126161, acc.: 44.44%] [G loss: 1.181749]\n",
      "334 [D loss: 0.795447, acc.: 66.67%] [G loss: 2.013545]\n",
      "335 [D loss: 0.453388, acc.: 77.78%] [G loss: 1.812063]\n",
      "336 [D loss: 0.535499, acc.: 66.67%] [G loss: 2.168748]\n",
      "337 [D loss: 0.553371, acc.: 72.22%] [G loss: 1.747387]\n",
      "338 [D loss: 0.550671, acc.: 77.78%] [G loss: 1.580323]\n",
      "339 [D loss: 0.507099, acc.: 72.22%] [G loss: 1.614007]\n",
      "340 [D loss: 0.697318, acc.: 66.67%] [G loss: 1.735510]\n",
      "341 [D loss: 0.662964, acc.: 61.11%] [G loss: 2.505755]\n",
      "342 [D loss: 0.426569, acc.: 83.33%] [G loss: 2.747905]\n",
      "343 [D loss: 0.848208, acc.: 50.00%] [G loss: 1.690009]\n",
      "344 [D loss: 0.537023, acc.: 77.78%] [G loss: 1.141539]\n",
      "345 [D loss: 0.392239, acc.: 88.89%] [G loss: 2.383002]\n",
      "346 [D loss: 0.755876, acc.: 50.00%] [G loss: 2.479046]\n",
      "347 [D loss: 1.023970, acc.: 27.78%] [G loss: 2.418270]\n",
      "348 [D loss: 0.396964, acc.: 72.22%] [G loss: 4.207353]\n",
      "349 [D loss: 0.607939, acc.: 72.22%] [G loss: 2.036944]\n",
      "350 [D loss: 0.489349, acc.: 72.22%] [G loss: 2.504897]\n",
      "351 [D loss: 0.564486, acc.: 61.11%] [G loss: 2.527480]\n",
      "352 [D loss: 0.509994, acc.: 72.22%] [G loss: 1.807913]\n",
      "353 [D loss: 0.530550, acc.: 77.78%] [G loss: 2.377308]\n",
      "354 [D loss: 0.551817, acc.: 72.22%] [G loss: 1.910196]\n",
      "355 [D loss: 0.431754, acc.: 83.33%] [G loss: 1.893378]\n",
      "356 [D loss: 0.585939, acc.: 66.67%] [G loss: 2.478170]\n",
      "357 [D loss: 0.419781, acc.: 88.89%] [G loss: 2.429012]\n",
      "358 [D loss: 0.446440, acc.: 83.33%] [G loss: 2.899908]\n",
      "359 [D loss: 0.549614, acc.: 72.22%] [G loss: 2.145693]\n",
      "360 [D loss: 0.934168, acc.: 61.11%] [G loss: 1.057916]\n",
      "361 [D loss: 0.748488, acc.: 66.67%] [G loss: 2.211667]\n",
      "362 [D loss: 0.563854, acc.: 61.11%] [G loss: 1.696231]\n",
      "363 [D loss: 0.395301, acc.: 83.33%] [G loss: 1.844681]\n",
      "364 [D loss: 0.659797, acc.: 55.56%] [G loss: 2.141450]\n",
      "365 [D loss: 0.493947, acc.: 61.11%] [G loss: 2.821008]\n",
      "366 [D loss: 0.369253, acc.: 77.78%] [G loss: 2.466758]\n",
      "367 [D loss: 0.423322, acc.: 83.33%] [G loss: 2.762042]\n",
      "368 [D loss: 0.322121, acc.: 88.89%] [G loss: 2.398319]\n",
      "369 [D loss: 0.697834, acc.: 72.22%] [G loss: 2.496057]\n",
      "370 [D loss: 0.475107, acc.: 72.22%] [G loss: 2.218189]\n",
      "371 [D loss: 0.221972, acc.: 94.44%] [G loss: 2.459943]\n",
      "372 [D loss: 0.367154, acc.: 83.33%] [G loss: 2.155897]\n",
      "373 [D loss: 0.501792, acc.: 66.67%] [G loss: 2.284600]\n",
      "374 [D loss: 0.510622, acc.: 77.78%] [G loss: 2.384296]\n",
      "375 [D loss: 0.482785, acc.: 61.11%] [G loss: 1.819896]\n",
      "376 [D loss: 0.494166, acc.: 55.56%] [G loss: 2.655861]\n",
      "377 [D loss: 0.436730, acc.: 72.22%] [G loss: 2.566795]\n",
      "378 [D loss: 0.429823, acc.: 83.33%] [G loss: 2.191975]\n",
      "379 [D loss: 0.554324, acc.: 61.11%] [G loss: 2.126099]\n",
      "380 [D loss: 0.340491, acc.: 88.89%] [G loss: 2.203409]\n",
      "381 [D loss: 0.373992, acc.: 83.33%] [G loss: 2.597050]\n",
      "382 [D loss: 0.765852, acc.: 50.00%] [G loss: 1.863990]\n",
      "383 [D loss: 0.346847, acc.: 94.44%] [G loss: 2.158770]\n",
      "384 [D loss: 0.817724, acc.: 61.11%] [G loss: 1.779285]\n",
      "385 [D loss: 0.325878, acc.: 88.89%] [G loss: 2.322653]\n",
      "386 [D loss: 0.725100, acc.: 66.67%] [G loss: 2.554569]\n",
      "387 [D loss: 0.660083, acc.: 61.11%] [G loss: 1.709098]\n",
      "388 [D loss: 0.356512, acc.: 88.89%] [G loss: 1.866926]\n",
      "389 [D loss: 0.827974, acc.: 55.56%] [G loss: 1.392253]\n",
      "390 [D loss: 0.524935, acc.: 72.22%] [G loss: 2.271623]\n",
      "391 [D loss: 0.532063, acc.: 77.78%] [G loss: 2.961542]\n",
      "392 [D loss: 0.618332, acc.: 66.67%] [G loss: 1.750078]\n",
      "393 [D loss: 0.445359, acc.: 77.78%] [G loss: 1.222985]\n",
      "394 [D loss: 0.550109, acc.: 77.78%] [G loss: 1.516300]\n",
      "395 [D loss: 0.402326, acc.: 77.78%] [G loss: 2.259456]\n",
      "396 [D loss: 0.704592, acc.: 72.22%] [G loss: 1.739637]\n",
      "397 [D loss: 0.504247, acc.: 77.78%] [G loss: 2.201748]\n",
      "398 [D loss: 0.573847, acc.: 77.78%] [G loss: 2.001650]\n",
      "399 [D loss: 0.337066, acc.: 83.33%] [G loss: 2.092618]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 [D loss: 0.665029, acc.: 55.56%] [G loss: 2.613994]\n",
      "401 [D loss: 0.203486, acc.: 94.44%] [G loss: 3.619451]\n",
      "402 [D loss: 0.322541, acc.: 83.33%] [G loss: 2.967494]\n",
      "403 [D loss: 0.945417, acc.: 44.44%] [G loss: 1.878669]\n",
      "404 [D loss: 0.355490, acc.: 83.33%] [G loss: 2.793477]\n",
      "405 [D loss: 0.422739, acc.: 77.78%] [G loss: 3.076314]\n",
      "406 [D loss: 0.679702, acc.: 66.67%] [G loss: 2.545537]\n",
      "407 [D loss: 0.661282, acc.: 66.67%] [G loss: 1.544723]\n",
      "408 [D loss: 0.859289, acc.: 50.00%] [G loss: 1.729368]\n",
      "409 [D loss: 0.413131, acc.: 77.78%] [G loss: 2.464092]\n",
      "410 [D loss: 0.493857, acc.: 83.33%] [G loss: 3.080364]\n",
      "411 [D loss: 0.792719, acc.: 55.56%] [G loss: 1.568205]\n",
      "412 [D loss: 0.697256, acc.: 72.22%] [G loss: 2.409520]\n",
      "413 [D loss: 0.265765, acc.: 88.89%] [G loss: 2.888061]\n",
      "414 [D loss: 0.391893, acc.: 77.78%] [G loss: 2.621953]\n",
      "415 [D loss: 0.793024, acc.: 66.67%] [G loss: 1.427483]\n",
      "416 [D loss: 0.342717, acc.: 83.33%] [G loss: 2.990336]\n",
      "417 [D loss: 0.412564, acc.: 72.22%] [G loss: 3.664845]\n",
      "418 [D loss: 0.552006, acc.: 72.22%] [G loss: 2.261614]\n",
      "419 [D loss: 0.305822, acc.: 88.89%] [G loss: 2.958346]\n",
      "420 [D loss: 0.421608, acc.: 66.67%] [G loss: 1.109290]\n",
      "421 [D loss: 0.566215, acc.: 77.78%] [G loss: 2.083474]\n",
      "422 [D loss: 0.279654, acc.: 83.33%] [G loss: 4.114769]\n",
      "423 [D loss: 0.604509, acc.: 72.22%] [G loss: 2.325469]\n",
      "424 [D loss: 0.296549, acc.: 88.89%] [G loss: 2.579992]\n",
      "425 [D loss: 0.483909, acc.: 83.33%] [G loss: 2.753814]\n",
      "426 [D loss: 0.381208, acc.: 83.33%] [G loss: 2.339472]\n",
      "427 [D loss: 0.206475, acc.: 100.00%] [G loss: 1.933256]\n",
      "428 [D loss: 0.280267, acc.: 94.44%] [G loss: 3.782600]\n",
      "429 [D loss: 0.570458, acc.: 66.67%] [G loss: 3.953343]\n",
      "430 [D loss: 0.217175, acc.: 88.89%] [G loss: 1.958562]\n",
      "431 [D loss: 0.431291, acc.: 77.78%] [G loss: 2.734066]\n",
      "432 [D loss: 0.427287, acc.: 77.78%] [G loss: 2.989463]\n",
      "433 [D loss: 0.281390, acc.: 88.89%] [G loss: 3.464677]\n",
      "434 [D loss: 0.831536, acc.: 72.22%] [G loss: 2.138458]\n",
      "435 [D loss: 0.303673, acc.: 94.44%] [G loss: 4.525541]\n",
      "436 [D loss: 0.212912, acc.: 88.89%] [G loss: 3.233703]\n",
      "437 [D loss: 0.418575, acc.: 83.33%] [G loss: 2.527184]\n",
      "438 [D loss: 0.232610, acc.: 88.89%] [G loss: 2.485440]\n",
      "439 [D loss: 0.168612, acc.: 94.44%] [G loss: 2.555679]\n",
      "440 [D loss: 0.360327, acc.: 83.33%] [G loss: 2.603499]\n",
      "441 [D loss: 0.488933, acc.: 72.22%] [G loss: 3.459412]\n",
      "442 [D loss: 0.725353, acc.: 66.67%] [G loss: 2.115061]\n",
      "443 [D loss: 0.881400, acc.: 50.00%] [G loss: 3.012501]\n",
      "444 [D loss: 0.621531, acc.: 66.67%] [G loss: 3.147136]\n",
      "445 [D loss: 0.604861, acc.: 72.22%] [G loss: 1.771379]\n",
      "446 [D loss: 0.363431, acc.: 88.89%] [G loss: 2.551248]\n",
      "447 [D loss: 0.474406, acc.: 83.33%] [G loss: 3.188143]\n",
      "448 [D loss: 0.244618, acc.: 88.89%] [G loss: 2.430820]\n",
      "449 [D loss: 0.488529, acc.: 72.22%] [G loss: 1.499452]\n",
      "450 [D loss: 1.177490, acc.: 55.56%] [G loss: 1.970148]\n",
      "451 [D loss: 0.729383, acc.: 61.11%] [G loss: 2.235784]\n",
      "452 [D loss: 0.490628, acc.: 83.33%] [G loss: 3.408174]\n",
      "453 [D loss: 0.442017, acc.: 77.78%] [G loss: 1.954429]\n",
      "454 [D loss: 0.575658, acc.: 72.22%] [G loss: 1.895212]\n",
      "455 [D loss: 0.352691, acc.: 88.89%] [G loss: 2.507404]\n",
      "456 [D loss: 0.275863, acc.: 83.33%] [G loss: 4.066932]\n",
      "457 [D loss: 0.342746, acc.: 77.78%] [G loss: 3.267206]\n",
      "458 [D loss: 0.564189, acc.: 72.22%] [G loss: 2.486973]\n",
      "459 [D loss: 0.382859, acc.: 77.78%] [G loss: 2.264540]\n",
      "460 [D loss: 0.539952, acc.: 72.22%] [G loss: 1.921767]\n",
      "461 [D loss: 0.285392, acc.: 83.33%] [G loss: 3.278054]\n",
      "462 [D loss: 0.398487, acc.: 83.33%] [G loss: 2.849563]\n",
      "463 [D loss: 0.907198, acc.: 50.00%] [G loss: 2.155190]\n",
      "464 [D loss: 0.373525, acc.: 83.33%] [G loss: 1.642829]\n",
      "465 [D loss: 0.421138, acc.: 72.22%] [G loss: 2.082232]\n",
      "466 [D loss: 0.179621, acc.: 94.44%] [G loss: 4.132633]\n",
      "467 [D loss: 0.455219, acc.: 72.22%] [G loss: 2.615852]\n",
      "468 [D loss: 0.368593, acc.: 83.33%] [G loss: 2.992859]\n",
      "469 [D loss: 0.553123, acc.: 77.78%] [G loss: 3.637079]\n",
      "470 [D loss: 0.453807, acc.: 83.33%] [G loss: 2.090788]\n",
      "471 [D loss: 0.171167, acc.: 94.44%] [G loss: 2.305159]\n",
      "472 [D loss: 0.578989, acc.: 66.67%] [G loss: 2.472834]\n",
      "473 [D loss: 0.382702, acc.: 94.44%] [G loss: 2.077754]\n",
      "474 [D loss: 0.331008, acc.: 94.44%] [G loss: 2.192315]\n",
      "475 [D loss: 0.641548, acc.: 77.78%] [G loss: 2.285387]\n",
      "476 [D loss: 0.464888, acc.: 77.78%] [G loss: 4.469815]\n",
      "477 [D loss: 0.439274, acc.: 77.78%] [G loss: 2.825594]\n",
      "478 [D loss: 0.285908, acc.: 88.89%] [G loss: 2.903557]\n",
      "479 [D loss: 0.706205, acc.: 66.67%] [G loss: 2.289601]\n",
      "480 [D loss: 0.188529, acc.: 100.00%] [G loss: 1.735669]\n",
      "481 [D loss: 0.311867, acc.: 88.89%] [G loss: 2.175913]\n",
      "482 [D loss: 0.394712, acc.: 88.89%] [G loss: 1.773443]\n",
      "483 [D loss: 0.642325, acc.: 72.22%] [G loss: 1.950008]\n",
      "484 [D loss: 0.309925, acc.: 83.33%] [G loss: 2.322166]\n",
      "485 [D loss: 0.462392, acc.: 83.33%] [G loss: 2.096588]\n",
      "486 [D loss: 0.315036, acc.: 94.44%] [G loss: 3.070846]\n",
      "487 [D loss: 0.441845, acc.: 72.22%] [G loss: 3.528134]\n",
      "488 [D loss: 0.433183, acc.: 77.78%] [G loss: 2.738191]\n",
      "489 [D loss: 0.196503, acc.: 94.44%] [G loss: 3.954239]\n",
      "490 [D loss: 0.474466, acc.: 77.78%] [G loss: 1.912195]\n",
      "491 [D loss: 0.115907, acc.: 100.00%] [G loss: 4.410956]\n",
      "492 [D loss: 0.335483, acc.: 83.33%] [G loss: 3.452059]\n",
      "493 [D loss: 0.177662, acc.: 94.44%] [G loss: 3.317642]\n",
      "494 [D loss: 0.219785, acc.: 94.44%] [G loss: 3.351042]\n",
      "495 [D loss: 0.272369, acc.: 88.89%] [G loss: 2.754101]\n",
      "496 [D loss: 0.296604, acc.: 77.78%] [G loss: 2.698618]\n",
      "497 [D loss: 0.214444, acc.: 88.89%] [G loss: 2.932969]\n",
      "498 [D loss: 0.159929, acc.: 100.00%] [G loss: 3.098397]\n",
      "499 [D loss: 0.281614, acc.: 83.33%] [G loss: 2.819222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 [D loss: 0.218943, acc.: 88.89%] [G loss: 2.584067]\n",
      "501 [D loss: 0.470720, acc.: 77.78%] [G loss: 3.219355]\n",
      "502 [D loss: 0.283773, acc.: 94.44%] [G loss: 2.229155]\n",
      "503 [D loss: 0.415766, acc.: 77.78%] [G loss: 2.848803]\n",
      "504 [D loss: 0.273729, acc.: 94.44%] [G loss: 2.457383]\n",
      "505 [D loss: 0.394470, acc.: 77.78%] [G loss: 3.251402]\n",
      "506 [D loss: 0.503749, acc.: 77.78%] [G loss: 2.900763]\n",
      "507 [D loss: 0.390914, acc.: 77.78%] [G loss: 2.306825]\n",
      "508 [D loss: 0.190133, acc.: 100.00%] [G loss: 4.109754]\n",
      "509 [D loss: 0.170548, acc.: 88.89%] [G loss: 4.288164]\n",
      "510 [D loss: 0.404268, acc.: 83.33%] [G loss: 3.436151]\n",
      "511 [D loss: 0.299045, acc.: 94.44%] [G loss: 2.860145]\n",
      "512 [D loss: 0.483431, acc.: 83.33%] [G loss: 2.181329]\n",
      "513 [D loss: 0.428609, acc.: 77.78%] [G loss: 3.089915]\n",
      "514 [D loss: 0.371782, acc.: 83.33%] [G loss: 2.723996]\n",
      "515 [D loss: 0.590021, acc.: 55.56%] [G loss: 2.329841]\n",
      "516 [D loss: 0.287078, acc.: 94.44%] [G loss: 2.961492]\n",
      "517 [D loss: 0.343174, acc.: 77.78%] [G loss: 3.725898]\n",
      "518 [D loss: 0.432269, acc.: 77.78%] [G loss: 3.230570]\n",
      "519 [D loss: 0.787322, acc.: 77.78%] [G loss: 2.130980]\n",
      "520 [D loss: 0.350718, acc.: 83.33%] [G loss: 2.161903]\n",
      "521 [D loss: 0.695000, acc.: 61.11%] [G loss: 2.023561]\n",
      "522 [D loss: 0.212333, acc.: 94.44%] [G loss: 3.109551]\n",
      "523 [D loss: 0.218814, acc.: 88.89%] [G loss: 3.452088]\n",
      "524 [D loss: 0.635698, acc.: 77.78%] [G loss: 2.820637]\n",
      "525 [D loss: 0.685463, acc.: 55.56%] [G loss: 1.681553]\n",
      "526 [D loss: 0.894210, acc.: 61.11%] [G loss: 1.831495]\n",
      "527 [D loss: 0.151751, acc.: 94.44%] [G loss: 3.937376]\n",
      "528 [D loss: 0.318774, acc.: 88.89%] [G loss: 2.680585]\n",
      "529 [D loss: 0.234635, acc.: 88.89%] [G loss: 3.443837]\n",
      "530 [D loss: 0.450498, acc.: 66.67%] [G loss: 2.265708]\n",
      "531 [D loss: 0.351224, acc.: 88.89%] [G loss: 1.867675]\n",
      "532 [D loss: 0.417565, acc.: 83.33%] [G loss: 3.757943]\n",
      "533 [D loss: 0.633257, acc.: 61.11%] [G loss: 2.332451]\n",
      "534 [D loss: 0.280215, acc.: 83.33%] [G loss: 2.194062]\n",
      "535 [D loss: 0.174567, acc.: 88.89%] [G loss: 3.155519]\n",
      "536 [D loss: 0.337256, acc.: 83.33%] [G loss: 2.165505]\n",
      "537 [D loss: 0.256508, acc.: 83.33%] [G loss: 3.715968]\n",
      "538 [D loss: 0.687454, acc.: 66.67%] [G loss: 2.212496]\n",
      "539 [D loss: 0.441346, acc.: 61.11%] [G loss: 2.237428]\n",
      "540 [D loss: 0.228846, acc.: 94.44%] [G loss: 2.966938]\n",
      "541 [D loss: 0.369119, acc.: 83.33%] [G loss: 2.254783]\n",
      "542 [D loss: 0.386607, acc.: 88.89%] [G loss: 3.097365]\n",
      "543 [D loss: 0.590794, acc.: 66.67%] [G loss: 2.338475]\n",
      "544 [D loss: 1.144039, acc.: 44.44%] [G loss: 2.279452]\n",
      "545 [D loss: 0.532314, acc.: 66.67%] [G loss: 2.518146]\n",
      "546 [D loss: 0.433846, acc.: 77.78%] [G loss: 2.319482]\n",
      "547 [D loss: 0.193950, acc.: 94.44%] [G loss: 2.962989]\n",
      "548 [D loss: 0.305037, acc.: 94.44%] [G loss: 3.334213]\n",
      "549 [D loss: 0.396772, acc.: 83.33%] [G loss: 2.706569]\n",
      "550 [D loss: 0.225266, acc.: 94.44%] [G loss: 3.041174]\n",
      "551 [D loss: 0.212080, acc.: 94.44%] [G loss: 2.417799]\n",
      "552 [D loss: 0.337390, acc.: 83.33%] [G loss: 4.717119]\n",
      "553 [D loss: 0.491550, acc.: 72.22%] [G loss: 1.979442]\n",
      "554 [D loss: 0.213561, acc.: 88.89%] [G loss: 3.362516]\n",
      "555 [D loss: 0.329701, acc.: 88.89%] [G loss: 3.063022]\n",
      "556 [D loss: 0.334390, acc.: 83.33%] [G loss: 3.925409]\n",
      "557 [D loss: 0.207720, acc.: 88.89%] [G loss: 4.300899]\n",
      "558 [D loss: 0.407343, acc.: 83.33%] [G loss: 2.874705]\n",
      "559 [D loss: 0.883241, acc.: 61.11%] [G loss: 2.137643]\n",
      "560 [D loss: 0.329115, acc.: 88.89%] [G loss: 2.342902]\n",
      "561 [D loss: 0.501759, acc.: 66.67%] [G loss: 3.341173]\n",
      "562 [D loss: 0.229973, acc.: 88.89%] [G loss: 3.871993]\n",
      "563 [D loss: 0.450747, acc.: 77.78%] [G loss: 3.727414]\n",
      "564 [D loss: 0.549189, acc.: 66.67%] [G loss: 2.843263]\n",
      "565 [D loss: 0.424780, acc.: 88.89%] [G loss: 3.719246]\n",
      "566 [D loss: 0.140510, acc.: 100.00%] [G loss: 4.201087]\n",
      "567 [D loss: 0.384145, acc.: 77.78%] [G loss: 2.519463]\n",
      "568 [D loss: 0.422121, acc.: 72.22%] [G loss: 3.141228]\n",
      "569 [D loss: 0.296138, acc.: 83.33%] [G loss: 3.881155]\n",
      "570 [D loss: 0.123113, acc.: 94.44%] [G loss: 3.001053]\n",
      "571 [D loss: 0.498014, acc.: 83.33%] [G loss: 2.388854]\n",
      "572 [D loss: 0.430273, acc.: 83.33%] [G loss: 3.001095]\n",
      "573 [D loss: 0.267586, acc.: 83.33%] [G loss: 4.299955]\n",
      "574 [D loss: 0.397376, acc.: 77.78%] [G loss: 3.134045]\n",
      "575 [D loss: 0.770779, acc.: 55.56%] [G loss: 2.764462]\n",
      "576 [D loss: 0.244709, acc.: 88.89%] [G loss: 3.392949]\n",
      "577 [D loss: 0.451040, acc.: 66.67%] [G loss: 3.131845]\n",
      "578 [D loss: 0.354103, acc.: 83.33%] [G loss: 3.429512]\n",
      "579 [D loss: 0.195409, acc.: 94.44%] [G loss: 3.022694]\n",
      "580 [D loss: 0.453873, acc.: 83.33%] [G loss: 3.346208]\n",
      "581 [D loss: 0.265821, acc.: 94.44%] [G loss: 3.154873]\n",
      "582 [D loss: 0.226178, acc.: 94.44%] [G loss: 2.263257]\n",
      "583 [D loss: 0.276533, acc.: 88.89%] [G loss: 2.408758]\n",
      "584 [D loss: 0.175625, acc.: 94.44%] [G loss: 3.655805]\n",
      "585 [D loss: 0.194863, acc.: 100.00%] [G loss: 3.819091]\n",
      "586 [D loss: 0.372497, acc.: 72.22%] [G loss: 2.651541]\n",
      "587 [D loss: 0.384600, acc.: 83.33%] [G loss: 3.077405]\n",
      "588 [D loss: 0.238929, acc.: 94.44%] [G loss: 2.671465]\n",
      "589 [D loss: 0.129546, acc.: 100.00%] [G loss: 2.908022]\n",
      "590 [D loss: 0.198522, acc.: 94.44%] [G loss: 3.520115]\n",
      "591 [D loss: 0.270138, acc.: 88.89%] [G loss: 2.545018]\n",
      "592 [D loss: 0.239943, acc.: 94.44%] [G loss: 2.424987]\n",
      "593 [D loss: 0.280282, acc.: 88.89%] [G loss: 3.174782]\n",
      "594 [D loss: 0.317641, acc.: 88.89%] [G loss: 3.402693]\n",
      "595 [D loss: 0.764739, acc.: 61.11%] [G loss: 2.839714]\n",
      "596 [D loss: 0.458448, acc.: 77.78%] [G loss: 2.776262]\n",
      "597 [D loss: 0.521943, acc.: 61.11%] [G loss: 3.278172]\n",
      "598 [D loss: 0.579034, acc.: 66.67%] [G loss: 3.001597]\n",
      "599 [D loss: 0.150175, acc.: 94.44%] [G loss: 3.547762]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 [D loss: 0.212141, acc.: 94.44%] [G loss: 2.921654]\n",
      "601 [D loss: 0.226147, acc.: 88.89%] [G loss: 3.605945]\n",
      "602 [D loss: 0.476427, acc.: 77.78%] [G loss: 3.052449]\n",
      "603 [D loss: 0.558063, acc.: 77.78%] [G loss: 3.055341]\n",
      "604 [D loss: 0.127786, acc.: 94.44%] [G loss: 5.429693]\n",
      "605 [D loss: 0.351537, acc.: 83.33%] [G loss: 4.168012]\n",
      "606 [D loss: 0.264671, acc.: 83.33%] [G loss: 3.844837]\n",
      "607 [D loss: 0.225854, acc.: 94.44%] [G loss: 2.971597]\n",
      "608 [D loss: 0.445866, acc.: 77.78%] [G loss: 2.394321]\n",
      "609 [D loss: 0.522778, acc.: 66.67%] [G loss: 1.809708]\n",
      "610 [D loss: 0.533026, acc.: 66.67%] [G loss: 1.923564]\n",
      "611 [D loss: 0.072201, acc.: 100.00%] [G loss: 6.275158]\n",
      "612 [D loss: 0.131360, acc.: 100.00%] [G loss: 4.567188]\n",
      "613 [D loss: 0.203685, acc.: 88.89%] [G loss: 2.973198]\n",
      "614 [D loss: 0.165415, acc.: 94.44%] [G loss: 3.719324]\n",
      "615 [D loss: 0.691471, acc.: 61.11%] [G loss: 2.166740]\n",
      "616 [D loss: 0.394457, acc.: 83.33%] [G loss: 3.048748]\n",
      "617 [D loss: 0.233522, acc.: 88.89%] [G loss: 4.563744]\n",
      "618 [D loss: 0.500166, acc.: 72.22%] [G loss: 2.707259]\n",
      "619 [D loss: 0.300409, acc.: 83.33%] [G loss: 2.844191]\n",
      "620 [D loss: 0.211083, acc.: 100.00%] [G loss: 3.260696]\n",
      "621 [D loss: 0.202897, acc.: 94.44%] [G loss: 2.711528]\n",
      "622 [D loss: 0.448240, acc.: 77.78%] [G loss: 3.480994]\n",
      "623 [D loss: 0.440154, acc.: 77.78%] [G loss: 2.557790]\n",
      "624 [D loss: 0.269665, acc.: 94.44%] [G loss: 2.990123]\n",
      "625 [D loss: 0.354194, acc.: 77.78%] [G loss: 2.157947]\n",
      "626 [D loss: 0.940429, acc.: 61.11%] [G loss: 1.793821]\n",
      "627 [D loss: 0.164734, acc.: 94.44%] [G loss: 4.210383]\n",
      "628 [D loss: 0.428725, acc.: 88.89%] [G loss: 2.607651]\n",
      "629 [D loss: 0.210546, acc.: 88.89%] [G loss: 3.968445]\n",
      "630 [D loss: 0.270189, acc.: 94.44%] [G loss: 4.503244]\n",
      "631 [D loss: 0.343444, acc.: 83.33%] [G loss: 1.968105]\n",
      "632 [D loss: 0.803339, acc.: 61.11%] [G loss: 3.500093]\n",
      "633 [D loss: 0.085868, acc.: 100.00%] [G loss: 5.073123]\n",
      "634 [D loss: 0.230539, acc.: 88.89%] [G loss: 3.637874]\n",
      "635 [D loss: 0.396467, acc.: 77.78%] [G loss: 3.247367]\n",
      "636 [D loss: 0.475103, acc.: 77.78%] [G loss: 3.017567]\n",
      "637 [D loss: 0.163840, acc.: 94.44%] [G loss: 2.979817]\n",
      "638 [D loss: 0.323335, acc.: 88.89%] [G loss: 2.534629]\n",
      "639 [D loss: 0.133649, acc.: 100.00%] [G loss: 2.804373]\n",
      "640 [D loss: 0.281208, acc.: 94.44%] [G loss: 2.022679]\n",
      "641 [D loss: 0.314376, acc.: 83.33%] [G loss: 3.830628]\n",
      "642 [D loss: 0.398626, acc.: 72.22%] [G loss: 2.071123]\n",
      "643 [D loss: 0.298180, acc.: 77.78%] [G loss: 3.079457]\n",
      "644 [D loss: 0.349025, acc.: 83.33%] [G loss: 3.252479]\n",
      "645 [D loss: 0.290648, acc.: 83.33%] [G loss: 3.630652]\n",
      "646 [D loss: 0.615119, acc.: 66.67%] [G loss: 3.193089]\n",
      "647 [D loss: 0.462339, acc.: 77.78%] [G loss: 2.869385]\n",
      "648 [D loss: 0.236623, acc.: 88.89%] [G loss: 2.280625]\n",
      "649 [D loss: 0.386649, acc.: 83.33%] [G loss: 2.925568]\n",
      "650 [D loss: 0.182110, acc.: 100.00%] [G loss: 3.894557]\n",
      "651 [D loss: 0.148290, acc.: 94.44%] [G loss: 4.532798]\n",
      "652 [D loss: 0.400049, acc.: 72.22%] [G loss: 2.880319]\n",
      "653 [D loss: 0.318912, acc.: 88.89%] [G loss: 2.024409]\n",
      "654 [D loss: 0.333276, acc.: 83.33%] [G loss: 2.821974]\n",
      "655 [D loss: 0.159657, acc.: 94.44%] [G loss: 3.573357]\n",
      "656 [D loss: 0.457308, acc.: 83.33%] [G loss: 2.867410]\n",
      "657 [D loss: 0.480844, acc.: 77.78%] [G loss: 2.255066]\n",
      "658 [D loss: 0.145451, acc.: 94.44%] [G loss: 3.908412]\n",
      "659 [D loss: 0.412014, acc.: 88.89%] [G loss: 2.460199]\n",
      "660 [D loss: 0.179437, acc.: 100.00%] [G loss: 3.655150]\n",
      "661 [D loss: 0.372268, acc.: 72.22%] [G loss: 6.560233]\n",
      "662 [D loss: 0.284856, acc.: 83.33%] [G loss: 3.276863]\n",
      "663 [D loss: 0.154060, acc.: 100.00%] [G loss: 3.516499]\n",
      "664 [D loss: 0.304371, acc.: 83.33%] [G loss: 1.684321]\n",
      "665 [D loss: 0.342215, acc.: 88.89%] [G loss: 2.989923]\n",
      "666 [D loss: 0.297380, acc.: 88.89%] [G loss: 2.358759]\n",
      "667 [D loss: 0.367962, acc.: 83.33%] [G loss: 3.285988]\n",
      "668 [D loss: 0.278631, acc.: 94.44%] [G loss: 2.606741]\n",
      "669 [D loss: 0.395956, acc.: 77.78%] [G loss: 3.728373]\n",
      "670 [D loss: 0.182047, acc.: 88.89%] [G loss: 3.683170]\n",
      "671 [D loss: 0.568709, acc.: 83.33%] [G loss: 2.696656]\n",
      "672 [D loss: 0.769160, acc.: 66.67%] [G loss: 2.994466]\n",
      "673 [D loss: 0.166926, acc.: 94.44%] [G loss: 3.980342]\n",
      "674 [D loss: 0.819171, acc.: 77.78%] [G loss: 3.122061]\n",
      "675 [D loss: 0.661467, acc.: 61.11%] [G loss: 2.425101]\n",
      "676 [D loss: 0.249217, acc.: 94.44%] [G loss: 2.763147]\n",
      "677 [D loss: 0.422245, acc.: 77.78%] [G loss: 3.157640]\n",
      "678 [D loss: 0.242619, acc.: 83.33%] [G loss: 1.511180]\n",
      "679 [D loss: 0.453493, acc.: 66.67%] [G loss: 3.891493]\n",
      "680 [D loss: 0.700006, acc.: 61.11%] [G loss: 3.304455]\n",
      "681 [D loss: 0.494062, acc.: 72.22%] [G loss: 3.353460]\n",
      "682 [D loss: 0.488818, acc.: 72.22%] [G loss: 2.636625]\n",
      "683 [D loss: 0.430718, acc.: 83.33%] [G loss: 3.001460]\n",
      "684 [D loss: 0.840592, acc.: 61.11%] [G loss: 2.184209]\n",
      "685 [D loss: 0.413195, acc.: 88.89%] [G loss: 2.768662]\n",
      "686 [D loss: 0.183608, acc.: 100.00%] [G loss: 3.912326]\n",
      "687 [D loss: 0.410668, acc.: 88.89%] [G loss: 3.923156]\n",
      "688 [D loss: 0.389582, acc.: 72.22%] [G loss: 5.267339]\n",
      "689 [D loss: 0.162319, acc.: 94.44%] [G loss: 3.149362]\n",
      "690 [D loss: 0.285048, acc.: 88.89%] [G loss: 3.669824]\n",
      "691 [D loss: 0.308521, acc.: 88.89%] [G loss: 2.729007]\n",
      "692 [D loss: 0.180942, acc.: 88.89%] [G loss: 6.774529]\n",
      "693 [D loss: 0.113661, acc.: 94.44%] [G loss: 6.119570]\n",
      "694 [D loss: 0.491699, acc.: 77.78%] [G loss: 2.634894]\n",
      "695 [D loss: 0.146133, acc.: 94.44%] [G loss: 4.666616]\n",
      "696 [D loss: 0.173327, acc.: 94.44%] [G loss: 3.856918]\n",
      "697 [D loss: 0.471655, acc.: 77.78%] [G loss: 3.786308]\n",
      "698 [D loss: 0.209675, acc.: 94.44%] [G loss: 3.014617]\n",
      "699 [D loss: 0.087014, acc.: 100.00%] [G loss: 2.996005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 [D loss: 0.444202, acc.: 83.33%] [G loss: 3.049485]\n",
      "701 [D loss: 0.195831, acc.: 100.00%] [G loss: 3.814106]\n",
      "702 [D loss: 0.440523, acc.: 88.89%] [G loss: 2.715956]\n",
      "703 [D loss: 0.224900, acc.: 94.44%] [G loss: 3.278102]\n",
      "704 [D loss: 0.482145, acc.: 72.22%] [G loss: 3.707405]\n",
      "705 [D loss: 0.477984, acc.: 66.67%] [G loss: 5.771758]\n",
      "706 [D loss: 0.166576, acc.: 94.44%] [G loss: 3.265233]\n",
      "707 [D loss: 0.579527, acc.: 55.56%] [G loss: 2.882868]\n",
      "708 [D loss: 0.237418, acc.: 88.89%] [G loss: 3.765021]\n",
      "709 [D loss: 0.439605, acc.: 66.67%] [G loss: 4.023810]\n",
      "710 [D loss: 0.369200, acc.: 83.33%] [G loss: 2.759064]\n",
      "711 [D loss: 0.242002, acc.: 88.89%] [G loss: 3.525344]\n",
      "712 [D loss: 0.285169, acc.: 88.89%] [G loss: 3.023397]\n",
      "713 [D loss: 0.310850, acc.: 83.33%] [G loss: 3.916223]\n",
      "714 [D loss: 0.372813, acc.: 83.33%] [G loss: 2.270947]\n",
      "715 [D loss: 0.633788, acc.: 72.22%] [G loss: 2.870862]\n",
      "716 [D loss: 0.480047, acc.: 83.33%] [G loss: 3.197387]\n",
      "717 [D loss: 0.635690, acc.: 61.11%] [G loss: 3.307065]\n",
      "718 [D loss: 0.321364, acc.: 83.33%] [G loss: 4.181748]\n",
      "719 [D loss: 0.700953, acc.: 72.22%] [G loss: 2.810219]\n",
      "720 [D loss: 0.209040, acc.: 88.89%] [G loss: 2.845761]\n",
      "721 [D loss: 0.068775, acc.: 100.00%] [G loss: 3.802387]\n",
      "722 [D loss: 0.319663, acc.: 83.33%] [G loss: 2.940058]\n",
      "723 [D loss: 0.136922, acc.: 94.44%] [G loss: 3.868762]\n",
      "724 [D loss: 0.375805, acc.: 77.78%] [G loss: 4.699398]\n",
      "725 [D loss: 0.198296, acc.: 100.00%] [G loss: 2.937754]\n",
      "726 [D loss: 0.268693, acc.: 88.89%] [G loss: 3.799072]\n",
      "727 [D loss: 0.369368, acc.: 77.78%] [G loss: 3.589912]\n",
      "728 [D loss: 1.057663, acc.: 38.89%] [G loss: 1.903091]\n",
      "729 [D loss: 0.352192, acc.: 77.78%] [G loss: 3.525467]\n",
      "730 [D loss: 0.279767, acc.: 83.33%] [G loss: 4.075785]\n",
      "731 [D loss: 0.283851, acc.: 88.89%] [G loss: 3.754549]\n",
      "732 [D loss: 0.194447, acc.: 94.44%] [G loss: 3.216873]\n",
      "733 [D loss: 0.557465, acc.: 72.22%] [G loss: 4.372478]\n",
      "734 [D loss: 0.262761, acc.: 94.44%] [G loss: 4.422127]\n",
      "735 [D loss: 0.409824, acc.: 88.89%] [G loss: 3.874759]\n",
      "736 [D loss: 0.391514, acc.: 88.89%] [G loss: 3.040891]\n",
      "737 [D loss: 0.216080, acc.: 94.44%] [G loss: 3.215997]\n",
      "738 [D loss: 0.370282, acc.: 83.33%] [G loss: 4.333701]\n",
      "739 [D loss: 0.181504, acc.: 94.44%] [G loss: 3.739278]\n",
      "740 [D loss: 0.153674, acc.: 94.44%] [G loss: 3.987994]\n",
      "741 [D loss: 0.123887, acc.: 100.00%] [G loss: 3.644892]\n",
      "742 [D loss: 0.380452, acc.: 77.78%] [G loss: 2.469827]\n",
      "743 [D loss: 0.275296, acc.: 83.33%] [G loss: 2.433420]\n",
      "744 [D loss: 0.464494, acc.: 83.33%] [G loss: 3.164971]\n",
      "745 [D loss: 0.093672, acc.: 100.00%] [G loss: 3.927783]\n",
      "746 [D loss: 0.178824, acc.: 94.44%] [G loss: 3.520492]\n",
      "747 [D loss: 0.236767, acc.: 88.89%] [G loss: 2.013054]\n",
      "748 [D loss: 0.240459, acc.: 88.89%] [G loss: 2.611829]\n",
      "749 [D loss: 0.272916, acc.: 88.89%] [G loss: 4.125447]\n",
      "750 [D loss: 0.258118, acc.: 88.89%] [G loss: 3.266761]\n",
      "751 [D loss: 0.214821, acc.: 88.89%] [G loss: 2.399597]\n",
      "752 [D loss: 0.168244, acc.: 94.44%] [G loss: 3.464997]\n",
      "753 [D loss: 0.259680, acc.: 88.89%] [G loss: 2.695305]\n",
      "754 [D loss: 1.328740, acc.: 44.44%] [G loss: 2.183743]\n",
      "755 [D loss: 0.167485, acc.: 94.44%] [G loss: 3.442267]\n",
      "756 [D loss: 0.283339, acc.: 88.89%] [G loss: 2.328231]\n",
      "757 [D loss: 0.451805, acc.: 72.22%] [G loss: 2.580369]\n",
      "758 [D loss: 0.230725, acc.: 94.44%] [G loss: 3.256354]\n",
      "759 [D loss: 0.237889, acc.: 88.89%] [G loss: 3.312329]\n",
      "760 [D loss: 0.443293, acc.: 77.78%] [G loss: 4.427413]\n",
      "761 [D loss: 0.178029, acc.: 94.44%] [G loss: 3.517902]\n",
      "762 [D loss: 0.433715, acc.: 77.78%] [G loss: 3.461874]\n",
      "763 [D loss: 0.446206, acc.: 83.33%] [G loss: 3.405508]\n",
      "764 [D loss: 0.452101, acc.: 83.33%] [G loss: 3.232310]\n",
      "765 [D loss: 0.148913, acc.: 100.00%] [G loss: 3.436856]\n",
      "766 [D loss: 0.519557, acc.: 66.67%] [G loss: 2.555690]\n",
      "767 [D loss: 0.226259, acc.: 88.89%] [G loss: 3.430340]\n",
      "768 [D loss: 0.379048, acc.: 83.33%] [G loss: 3.504150]\n",
      "769 [D loss: 0.401470, acc.: 77.78%] [G loss: 4.613368]\n",
      "770 [D loss: 0.312254, acc.: 83.33%] [G loss: 4.091579]\n",
      "771 [D loss: 0.416557, acc.: 88.89%] [G loss: 2.455321]\n",
      "772 [D loss: 0.329254, acc.: 83.33%] [G loss: 3.095857]\n",
      "773 [D loss: 0.555261, acc.: 77.78%] [G loss: 2.811700]\n",
      "774 [D loss: 0.228516, acc.: 94.44%] [G loss: 4.065541]\n",
      "775 [D loss: 0.357966, acc.: 83.33%] [G loss: 2.815082]\n",
      "776 [D loss: 0.380777, acc.: 83.33%] [G loss: 3.050085]\n",
      "777 [D loss: 0.379277, acc.: 77.78%] [G loss: 3.775845]\n",
      "778 [D loss: 0.119361, acc.: 94.44%] [G loss: 4.380022]\n",
      "779 [D loss: 0.123814, acc.: 94.44%] [G loss: 4.068722]\n",
      "780 [D loss: 0.235733, acc.: 88.89%] [G loss: 5.122214]\n",
      "781 [D loss: 0.352659, acc.: 77.78%] [G loss: 3.883188]\n",
      "782 [D loss: 0.256588, acc.: 88.89%] [G loss: 2.936657]\n",
      "783 [D loss: 0.308038, acc.: 88.89%] [G loss: 4.265887]\n",
      "784 [D loss: 0.318584, acc.: 83.33%] [G loss: 3.565791]\n",
      "785 [D loss: 0.315660, acc.: 88.89%] [G loss: 3.398189]\n",
      "786 [D loss: 0.555436, acc.: 72.22%] [G loss: 6.167154]\n",
      "787 [D loss: 0.648731, acc.: 72.22%] [G loss: 4.049961]\n",
      "788 [D loss: 0.191409, acc.: 88.89%] [G loss: 3.894098]\n",
      "789 [D loss: 0.563320, acc.: 88.89%] [G loss: 2.264213]\n",
      "790 [D loss: 0.581766, acc.: 66.67%] [G loss: 3.557349]\n",
      "791 [D loss: 0.193388, acc.: 88.89%] [G loss: 4.376844]\n",
      "792 [D loss: 0.538208, acc.: 66.67%] [G loss: 2.147571]\n",
      "793 [D loss: 0.602963, acc.: 66.67%] [G loss: 2.184158]\n",
      "794 [D loss: 0.523672, acc.: 77.78%] [G loss: 2.687260]\n",
      "795 [D loss: 0.244308, acc.: 88.89%] [G loss: 3.391382]\n",
      "796 [D loss: 0.159410, acc.: 94.44%] [G loss: 3.592969]\n",
      "797 [D loss: 0.420976, acc.: 66.67%] [G loss: 3.589694]\n",
      "798 [D loss: 0.370039, acc.: 94.44%] [G loss: 3.348543]\n",
      "799 [D loss: 0.386281, acc.: 83.33%] [G loss: 3.195768]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 [D loss: 0.352640, acc.: 88.89%] [G loss: 4.614653]\n",
      "801 [D loss: 0.430093, acc.: 77.78%] [G loss: 4.010678]\n",
      "802 [D loss: 0.142959, acc.: 94.44%] [G loss: 4.115537]\n",
      "803 [D loss: 0.704966, acc.: 66.67%] [G loss: 3.561701]\n",
      "804 [D loss: 0.301025, acc.: 94.44%] [G loss: 3.190505]\n",
      "805 [D loss: 0.696748, acc.: 66.67%] [G loss: 2.904872]\n",
      "806 [D loss: 0.273271, acc.: 94.44%] [G loss: 6.414054]\n",
      "807 [D loss: 0.095210, acc.: 100.00%] [G loss: 4.338353]\n",
      "808 [D loss: 0.177660, acc.: 88.89%] [G loss: 3.605632]\n",
      "809 [D loss: 0.221342, acc.: 88.89%] [G loss: 3.727369]\n",
      "810 [D loss: 0.193735, acc.: 88.89%] [G loss: 3.014974]\n",
      "811 [D loss: 0.168379, acc.: 88.89%] [G loss: 4.317545]\n",
      "812 [D loss: 0.121234, acc.: 100.00%] [G loss: 3.693025]\n",
      "813 [D loss: 0.340419, acc.: 72.22%] [G loss: 3.289204]\n",
      "814 [D loss: 0.138806, acc.: 100.00%] [G loss: 4.167163]\n",
      "815 [D loss: 0.303860, acc.: 94.44%] [G loss: 4.101501]\n",
      "816 [D loss: 0.096390, acc.: 100.00%] [G loss: 2.489885]\n",
      "817 [D loss: 0.727421, acc.: 66.67%] [G loss: 2.591678]\n",
      "818 [D loss: 0.422301, acc.: 83.33%] [G loss: 2.855770]\n",
      "819 [D loss: 0.291345, acc.: 88.89%] [G loss: 3.382695]\n",
      "820 [D loss: 0.288996, acc.: 88.89%] [G loss: 3.212053]\n",
      "821 [D loss: 0.360732, acc.: 83.33%] [G loss: 1.609740]\n",
      "822 [D loss: 0.188858, acc.: 88.89%] [G loss: 3.103555]\n",
      "823 [D loss: 0.223912, acc.: 94.44%] [G loss: 3.326210]\n",
      "824 [D loss: 0.278201, acc.: 83.33%] [G loss: 3.110814]\n",
      "825 [D loss: 0.099867, acc.: 100.00%] [G loss: 3.758120]\n",
      "826 [D loss: 0.235056, acc.: 88.89%] [G loss: 3.817290]\n",
      "827 [D loss: 0.143463, acc.: 100.00%] [G loss: 3.028621]\n",
      "828 [D loss: 0.152946, acc.: 88.89%] [G loss: 3.547801]\n",
      "829 [D loss: 0.535632, acc.: 72.22%] [G loss: 3.928683]\n",
      "830 [D loss: 0.210332, acc.: 88.89%] [G loss: 3.376511]\n",
      "831 [D loss: 0.095305, acc.: 100.00%] [G loss: 3.823539]\n",
      "832 [D loss: 0.294501, acc.: 88.89%] [G loss: 2.848504]\n",
      "833 [D loss: 0.142408, acc.: 100.00%] [G loss: 2.876425]\n",
      "834 [D loss: 0.156537, acc.: 88.89%] [G loss: 3.759603]\n",
      "835 [D loss: 0.280900, acc.: 88.89%] [G loss: 4.045666]\n",
      "836 [D loss: 0.251664, acc.: 94.44%] [G loss: 4.036975]\n",
      "837 [D loss: 0.254304, acc.: 88.89%] [G loss: 2.766653]\n",
      "838 [D loss: 0.631656, acc.: 72.22%] [G loss: 1.833825]\n",
      "839 [D loss: 0.390298, acc.: 83.33%] [G loss: 3.844903]\n",
      "840 [D loss: 0.307969, acc.: 88.89%] [G loss: 2.846160]\n",
      "841 [D loss: 0.689008, acc.: 66.67%] [G loss: 3.577400]\n",
      "842 [D loss: 0.228971, acc.: 88.89%] [G loss: 3.893265]\n",
      "843 [D loss: 0.407495, acc.: 88.89%] [G loss: 4.011765]\n",
      "844 [D loss: 0.256655, acc.: 88.89%] [G loss: 2.658243]\n",
      "845 [D loss: 0.126237, acc.: 100.00%] [G loss: 3.401224]\n",
      "846 [D loss: 0.308132, acc.: 88.89%] [G loss: 2.695604]\n",
      "847 [D loss: 0.735712, acc.: 61.11%] [G loss: 2.137373]\n",
      "848 [D loss: 0.283114, acc.: 88.89%] [G loss: 2.375422]\n",
      "849 [D loss: 0.090255, acc.: 100.00%] [G loss: 4.066942]\n",
      "850 [D loss: 0.194850, acc.: 94.44%] [G loss: 3.042446]\n",
      "851 [D loss: 0.161844, acc.: 94.44%] [G loss: 3.776202]\n",
      "852 [D loss: 0.233429, acc.: 94.44%] [G loss: 4.177802]\n",
      "853 [D loss: 0.366733, acc.: 77.78%] [G loss: 3.100544]\n",
      "854 [D loss: 0.381322, acc.: 88.89%] [G loss: 2.411182]\n",
      "855 [D loss: 0.427545, acc.: 72.22%] [G loss: 5.326409]\n",
      "856 [D loss: 0.262631, acc.: 83.33%] [G loss: 5.049244]\n",
      "857 [D loss: 1.375759, acc.: 44.44%] [G loss: 4.581893]\n",
      "858 [D loss: 0.204704, acc.: 94.44%] [G loss: 4.324982]\n",
      "859 [D loss: 0.120770, acc.: 100.00%] [G loss: 3.762810]\n",
      "860 [D loss: 0.217705, acc.: 94.44%] [G loss: 3.404216]\n",
      "861 [D loss: 0.210769, acc.: 88.89%] [G loss: 2.928468]\n",
      "862 [D loss: 0.631924, acc.: 77.78%] [G loss: 3.877440]\n",
      "863 [D loss: 0.156701, acc.: 94.44%] [G loss: 4.175788]\n",
      "864 [D loss: 0.137999, acc.: 94.44%] [G loss: 3.793185]\n",
      "865 [D loss: 0.081743, acc.: 100.00%] [G loss: 3.647296]\n",
      "866 [D loss: 0.291969, acc.: 88.89%] [G loss: 2.220068]\n",
      "867 [D loss: 0.107239, acc.: 100.00%] [G loss: 3.783619]\n",
      "868 [D loss: 0.212435, acc.: 88.89%] [G loss: 3.961317]\n",
      "869 [D loss: 0.544560, acc.: 77.78%] [G loss: 3.798447]\n",
      "870 [D loss: 0.174726, acc.: 88.89%] [G loss: 3.100865]\n",
      "871 [D loss: 0.747814, acc.: 72.22%] [G loss: 1.724931]\n",
      "872 [D loss: 0.547120, acc.: 66.67%] [G loss: 3.204741]\n",
      "873 [D loss: 0.393108, acc.: 83.33%] [G loss: 3.745541]\n",
      "874 [D loss: 0.208663, acc.: 88.89%] [G loss: 2.656767]\n",
      "875 [D loss: 0.135092, acc.: 100.00%] [G loss: 3.376614]\n",
      "876 [D loss: 0.124630, acc.: 94.44%] [G loss: 3.596872]\n",
      "877 [D loss: 0.507415, acc.: 83.33%] [G loss: 2.769845]\n",
      "878 [D loss: 0.036957, acc.: 100.00%] [G loss: 7.857775]\n",
      "879 [D loss: 0.168429, acc.: 94.44%] [G loss: 5.530265]\n",
      "880 [D loss: 0.463292, acc.: 72.22%] [G loss: 3.411864]\n",
      "881 [D loss: 0.259501, acc.: 83.33%] [G loss: 4.867308]\n",
      "882 [D loss: 0.299488, acc.: 88.89%] [G loss: 3.217458]\n",
      "883 [D loss: 0.070055, acc.: 100.00%] [G loss: 4.159220]\n",
      "884 [D loss: 0.496555, acc.: 77.78%] [G loss: 3.367946]\n",
      "885 [D loss: 0.172818, acc.: 94.44%] [G loss: 4.553261]\n",
      "886 [D loss: 0.093595, acc.: 94.44%] [G loss: 5.282114]\n",
      "887 [D loss: 0.228541, acc.: 88.89%] [G loss: 3.293078]\n",
      "888 [D loss: 0.413747, acc.: 83.33%] [G loss: 2.335780]\n",
      "889 [D loss: 0.281116, acc.: 83.33%] [G loss: 3.078425]\n",
      "890 [D loss: 0.206486, acc.: 83.33%] [G loss: 3.498019]\n",
      "891 [D loss: 0.827363, acc.: 77.78%] [G loss: 3.451022]\n",
      "892 [D loss: 0.183606, acc.: 94.44%] [G loss: 2.547980]\n",
      "893 [D loss: 0.277044, acc.: 88.89%] [G loss: 3.888351]\n",
      "894 [D loss: 0.439845, acc.: 88.89%] [G loss: 2.605967]\n",
      "895 [D loss: 0.279403, acc.: 88.89%] [G loss: 2.292134]\n",
      "896 [D loss: 0.261926, acc.: 88.89%] [G loss: 2.836466]\n",
      "897 [D loss: 0.234055, acc.: 88.89%] [G loss: 3.946328]\n",
      "898 [D loss: 0.234716, acc.: 94.44%] [G loss: 4.499100]\n",
      "899 [D loss: 0.692426, acc.: 66.67%] [G loss: 3.357429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 [D loss: 0.314044, acc.: 88.89%] [G loss: 3.122023]\n",
      "901 [D loss: 0.229258, acc.: 94.44%] [G loss: 3.023267]\n",
      "902 [D loss: 0.420093, acc.: 77.78%] [G loss: 3.229737]\n",
      "903 [D loss: 0.290533, acc.: 94.44%] [G loss: 3.484895]\n",
      "904 [D loss: 0.349939, acc.: 83.33%] [G loss: 3.381642]\n",
      "905 [D loss: 0.262739, acc.: 83.33%] [G loss: 3.021090]\n",
      "906 [D loss: 0.348396, acc.: 88.89%] [G loss: 3.442520]\n",
      "907 [D loss: 0.242157, acc.: 83.33%] [G loss: 3.197563]\n",
      "908 [D loss: 0.083607, acc.: 100.00%] [G loss: 4.239623]\n",
      "909 [D loss: 0.320737, acc.: 88.89%] [G loss: 4.683199]\n",
      "910 [D loss: 0.208477, acc.: 100.00%] [G loss: 4.064389]\n",
      "911 [D loss: 0.249313, acc.: 88.89%] [G loss: 3.898331]\n",
      "912 [D loss: 0.419648, acc.: 72.22%] [G loss: 3.285321]\n",
      "913 [D loss: 0.182348, acc.: 88.89%] [G loss: 4.432075]\n",
      "914 [D loss: 0.573034, acc.: 77.78%] [G loss: 3.089323]\n",
      "915 [D loss: 0.262680, acc.: 88.89%] [G loss: 3.878629]\n",
      "916 [D loss: 0.210237, acc.: 94.44%] [G loss: 3.434016]\n",
      "917 [D loss: 0.283577, acc.: 88.89%] [G loss: 3.989398]\n",
      "918 [D loss: 0.241276, acc.: 83.33%] [G loss: 3.573734]\n",
      "919 [D loss: 0.649161, acc.: 83.33%] [G loss: 2.458207]\n",
      "920 [D loss: 0.239560, acc.: 94.44%] [G loss: 4.328509]\n",
      "921 [D loss: 0.069543, acc.: 100.00%] [G loss: 6.335568]\n",
      "922 [D loss: 0.258331, acc.: 83.33%] [G loss: 3.368207]\n",
      "923 [D loss: 0.249988, acc.: 88.89%] [G loss: 4.062388]\n",
      "924 [D loss: 0.354472, acc.: 83.33%] [G loss: 3.674764]\n",
      "925 [D loss: 0.403252, acc.: 72.22%] [G loss: 2.305835]\n",
      "926 [D loss: 0.139042, acc.: 100.00%] [G loss: 3.145169]\n",
      "927 [D loss: 0.200045, acc.: 94.44%] [G loss: 3.723267]\n",
      "928 [D loss: 0.364068, acc.: 94.44%] [G loss: 3.824272]\n",
      "929 [D loss: 0.768181, acc.: 61.11%] [G loss: 3.302869]\n",
      "930 [D loss: 0.416430, acc.: 83.33%] [G loss: 1.983566]\n",
      "931 [D loss: 0.592063, acc.: 72.22%] [G loss: 3.702469]\n",
      "932 [D loss: 0.118923, acc.: 100.00%] [G loss: 5.355451]\n",
      "933 [D loss: 1.818347, acc.: 33.33%] [G loss: 2.320637]\n",
      "934 [D loss: 0.327022, acc.: 83.33%] [G loss: 3.125877]\n",
      "935 [D loss: 0.134767, acc.: 94.44%] [G loss: 5.511937]\n",
      "936 [D loss: 0.256621, acc.: 83.33%] [G loss: 4.699984]\n",
      "937 [D loss: 0.041912, acc.: 100.00%] [G loss: 5.578980]\n",
      "938 [D loss: 0.088024, acc.: 100.00%] [G loss: 3.887210]\n",
      "939 [D loss: 0.264354, acc.: 88.89%] [G loss: 3.877558]\n",
      "940 [D loss: 0.083357, acc.: 100.00%] [G loss: 4.834911]\n",
      "941 [D loss: 0.392980, acc.: 83.33%] [G loss: 3.364663]\n",
      "942 [D loss: 0.283343, acc.: 88.89%] [G loss: 3.464737]\n",
      "943 [D loss: 0.203270, acc.: 88.89%] [G loss: 4.089442]\n",
      "944 [D loss: 0.148379, acc.: 100.00%] [G loss: 3.718909]\n",
      "945 [D loss: 0.353565, acc.: 94.44%] [G loss: 2.443725]\n",
      "946 [D loss: 0.155323, acc.: 94.44%] [G loss: 4.087510]\n",
      "947 [D loss: 0.236069, acc.: 88.89%] [G loss: 3.865776]\n",
      "948 [D loss: 0.319366, acc.: 77.78%] [G loss: 3.332896]\n",
      "949 [D loss: 0.232346, acc.: 88.89%] [G loss: 3.673432]\n",
      "950 [D loss: 0.183411, acc.: 94.44%] [G loss: 4.494390]\n",
      "951 [D loss: 0.331057, acc.: 88.89%] [G loss: 2.989313]\n",
      "952 [D loss: 0.158448, acc.: 100.00%] [G loss: 3.454783]\n",
      "953 [D loss: 0.311611, acc.: 88.89%] [G loss: 3.869258]\n",
      "954 [D loss: 0.280611, acc.: 83.33%] [G loss: 2.994911]\n",
      "955 [D loss: 0.276249, acc.: 77.78%] [G loss: 3.966471]\n",
      "956 [D loss: 0.059122, acc.: 100.00%] [G loss: 4.532358]\n",
      "957 [D loss: 0.181417, acc.: 100.00%] [G loss: 3.072638]\n",
      "958 [D loss: 0.199962, acc.: 88.89%] [G loss: 3.710218]\n",
      "959 [D loss: 0.229168, acc.: 83.33%] [G loss: 3.401142]\n",
      "960 [D loss: 0.210117, acc.: 88.89%] [G loss: 3.372482]\n",
      "961 [D loss: 0.598079, acc.: 77.78%] [G loss: 2.686780]\n",
      "962 [D loss: 0.318605, acc.: 83.33%] [G loss: 5.028854]\n",
      "963 [D loss: 0.163243, acc.: 94.44%] [G loss: 3.531102]\n",
      "964 [D loss: 0.473067, acc.: 77.78%] [G loss: 2.532437]\n",
      "965 [D loss: 0.224543, acc.: 94.44%] [G loss: 3.612494]\n",
      "966 [D loss: 0.555633, acc.: 77.78%] [G loss: 3.377892]\n",
      "967 [D loss: 0.208638, acc.: 94.44%] [G loss: 3.696631]\n",
      "968 [D loss: 0.277077, acc.: 94.44%] [G loss: 2.587927]\n",
      "969 [D loss: 0.151087, acc.: 100.00%] [G loss: 4.427768]\n",
      "970 [D loss: 0.189578, acc.: 94.44%] [G loss: 4.099045]\n",
      "971 [D loss: 0.228920, acc.: 88.89%] [G loss: 4.134150]\n",
      "972 [D loss: 0.295147, acc.: 83.33%] [G loss: 4.572701]\n",
      "973 [D loss: 0.209693, acc.: 94.44%] [G loss: 3.123734]\n",
      "974 [D loss: 0.229284, acc.: 83.33%] [G loss: 3.589539]\n",
      "975 [D loss: 0.222736, acc.: 88.89%] [G loss: 3.262049]\n",
      "976 [D loss: 0.231128, acc.: 88.89%] [G loss: 2.770439]\n",
      "977 [D loss: 0.230775, acc.: 94.44%] [G loss: 3.201694]\n",
      "978 [D loss: 0.298538, acc.: 83.33%] [G loss: 3.373137]\n",
      "979 [D loss: 0.289860, acc.: 83.33%] [G loss: 2.688285]\n",
      "980 [D loss: 0.350084, acc.: 88.89%] [G loss: 3.073019]\n",
      "981 [D loss: 0.251264, acc.: 88.89%] [G loss: 2.946222]\n",
      "982 [D loss: 0.256228, acc.: 88.89%] [G loss: 4.083815]\n",
      "983 [D loss: 0.211833, acc.: 88.89%] [G loss: 3.207226]\n",
      "984 [D loss: 0.481659, acc.: 83.33%] [G loss: 3.410017]\n",
      "985 [D loss: 0.100521, acc.: 100.00%] [G loss: 5.248190]\n",
      "986 [D loss: 0.185779, acc.: 94.44%] [G loss: 5.167830]\n",
      "987 [D loss: 0.145204, acc.: 88.89%] [G loss: 3.710977]\n",
      "988 [D loss: 0.241266, acc.: 83.33%] [G loss: 4.162444]\n",
      "989 [D loss: 0.153373, acc.: 94.44%] [G loss: 3.832857]\n",
      "990 [D loss: 0.720116, acc.: 72.22%] [G loss: 3.202352]\n",
      "991 [D loss: 0.449599, acc.: 77.78%] [G loss: 1.992669]\n",
      "992 [D loss: 0.233662, acc.: 88.89%] [G loss: 3.338748]\n",
      "993 [D loss: 0.087047, acc.: 100.00%] [G loss: 4.394210]\n",
      "994 [D loss: 0.428783, acc.: 77.78%] [G loss: 3.449877]\n",
      "995 [D loss: 0.060475, acc.: 100.00%] [G loss: 3.183617]\n",
      "996 [D loss: 0.226203, acc.: 94.44%] [G loss: 3.054116]\n",
      "997 [D loss: 0.225112, acc.: 88.89%] [G loss: 5.060363]\n",
      "998 [D loss: 0.273431, acc.: 88.89%] [G loss: 3.581428]\n",
      "999 [D loss: 0.158248, acc.: 100.00%] [G loss: 3.223516]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [D loss: 0.452220, acc.: 72.22%] [G loss: 3.122812]\n",
      "1001 [D loss: 0.209741, acc.: 100.00%] [G loss: 4.829573]\n",
      "1002 [D loss: 0.115421, acc.: 100.00%] [G loss: 4.162968]\n",
      "1003 [D loss: 0.209558, acc.: 94.44%] [G loss: 3.518390]\n",
      "1004 [D loss: 0.412858, acc.: 77.78%] [G loss: 2.507092]\n",
      "1005 [D loss: 0.403736, acc.: 83.33%] [G loss: 3.791083]\n",
      "1006 [D loss: 0.765026, acc.: 72.22%] [G loss: 2.776090]\n",
      "1007 [D loss: 0.186886, acc.: 94.44%] [G loss: 4.835129]\n",
      "1008 [D loss: 0.392715, acc.: 72.22%] [G loss: 3.176051]\n",
      "1009 [D loss: 0.493751, acc.: 88.89%] [G loss: 3.704169]\n",
      "1010 [D loss: 0.333866, acc.: 77.78%] [G loss: 5.368428]\n",
      "1011 [D loss: 0.184188, acc.: 94.44%] [G loss: 5.368769]\n",
      "1012 [D loss: 0.264439, acc.: 94.44%] [G loss: 4.104811]\n",
      "1013 [D loss: 0.362957, acc.: 88.89%] [G loss: 3.030785]\n",
      "1014 [D loss: 0.136994, acc.: 100.00%] [G loss: 2.656787]\n",
      "1015 [D loss: 0.358348, acc.: 83.33%] [G loss: 3.800783]\n",
      "1016 [D loss: 0.471835, acc.: 77.78%] [G loss: 3.071492]\n",
      "1017 [D loss: 0.104641, acc.: 100.00%] [G loss: 4.271963]\n",
      "1018 [D loss: 0.578830, acc.: 72.22%] [G loss: 3.251167]\n",
      "1019 [D loss: 0.181713, acc.: 94.44%] [G loss: 6.761869]\n",
      "1020 [D loss: 0.129547, acc.: 94.44%] [G loss: 5.151300]\n",
      "1021 [D loss: 0.308314, acc.: 94.44%] [G loss: 3.210688]\n",
      "1022 [D loss: 0.200602, acc.: 94.44%] [G loss: 2.946932]\n",
      "1023 [D loss: 0.137550, acc.: 88.89%] [G loss: 3.953728]\n",
      "1024 [D loss: 0.196288, acc.: 94.44%] [G loss: 3.862936]\n",
      "1025 [D loss: 0.242227, acc.: 94.44%] [G loss: 4.291533]\n",
      "1026 [D loss: 0.204532, acc.: 94.44%] [G loss: 2.762913]\n",
      "1027 [D loss: 0.259199, acc.: 88.89%] [G loss: 2.937128]\n",
      "1028 [D loss: 0.156276, acc.: 94.44%] [G loss: 3.975524]\n",
      "1029 [D loss: 0.241551, acc.: 83.33%] [G loss: 4.203141]\n",
      "1030 [D loss: 0.363741, acc.: 77.78%] [G loss: 3.732658]\n",
      "1031 [D loss: 0.582178, acc.: 77.78%] [G loss: 3.717555]\n",
      "1032 [D loss: 0.408320, acc.: 72.22%] [G loss: 2.693519]\n",
      "1033 [D loss: 0.379527, acc.: 83.33%] [G loss: 4.448591]\n",
      "1034 [D loss: 0.516562, acc.: 88.89%] [G loss: 3.891454]\n",
      "1035 [D loss: 0.214065, acc.: 88.89%] [G loss: 4.699860]\n",
      "1036 [D loss: 0.161208, acc.: 94.44%] [G loss: 5.398153]\n",
      "1037 [D loss: 0.092382, acc.: 100.00%] [G loss: 4.752531]\n",
      "1038 [D loss: 0.203222, acc.: 94.44%] [G loss: 2.445282]\n",
      "1039 [D loss: 0.092629, acc.: 100.00%] [G loss: 3.927472]\n",
      "1040 [D loss: 0.086036, acc.: 100.00%] [G loss: 3.421541]\n",
      "1041 [D loss: 0.298828, acc.: 88.89%] [G loss: 3.196959]\n",
      "1042 [D loss: 0.253566, acc.: 88.89%] [G loss: 3.576621]\n",
      "1043 [D loss: 0.204537, acc.: 88.89%] [G loss: 3.456267]\n",
      "1044 [D loss: 0.320586, acc.: 83.33%] [G loss: 3.575826]\n",
      "1045 [D loss: 0.315681, acc.: 88.89%] [G loss: 3.166088]\n",
      "1046 [D loss: 0.341524, acc.: 83.33%] [G loss: 3.790482]\n",
      "1047 [D loss: 0.498031, acc.: 72.22%] [G loss: 5.090215]\n",
      "1048 [D loss: 0.118308, acc.: 100.00%] [G loss: 4.202102]\n",
      "1049 [D loss: 0.081675, acc.: 94.44%] [G loss: 5.109176]\n",
      "1050 [D loss: 0.786627, acc.: 66.67%] [G loss: 2.154942]\n",
      "1051 [D loss: 0.697996, acc.: 72.22%] [G loss: 3.891633]\n",
      "1052 [D loss: 0.176095, acc.: 88.89%] [G loss: 5.089511]\n",
      "1053 [D loss: 0.646547, acc.: 66.67%] [G loss: 3.560742]\n",
      "1054 [D loss: 0.355205, acc.: 83.33%] [G loss: 4.060754]\n",
      "1055 [D loss: 0.113064, acc.: 94.44%] [G loss: 5.281572]\n",
      "1056 [D loss: 0.575764, acc.: 66.67%] [G loss: 4.664903]\n",
      "1057 [D loss: 0.234723, acc.: 88.89%] [G loss: 3.773139]\n",
      "1058 [D loss: 0.094106, acc.: 100.00%] [G loss: 3.587232]\n",
      "1059 [D loss: 0.187946, acc.: 94.44%] [G loss: 3.783181]\n",
      "1060 [D loss: 0.129960, acc.: 94.44%] [G loss: 3.738992]\n",
      "1061 [D loss: 0.524260, acc.: 72.22%] [G loss: 4.887397]\n",
      "1062 [D loss: 0.152843, acc.: 94.44%] [G loss: 4.679892]\n",
      "1063 [D loss: 0.367296, acc.: 72.22%] [G loss: 3.587827]\n",
      "1064 [D loss: 0.166642, acc.: 94.44%] [G loss: 4.106854]\n",
      "1065 [D loss: 0.312508, acc.: 83.33%] [G loss: 2.251948]\n",
      "1066 [D loss: 0.449889, acc.: 72.22%] [G loss: 3.325594]\n",
      "1067 [D loss: 0.410151, acc.: 83.33%] [G loss: 3.832392]\n",
      "1068 [D loss: 0.087211, acc.: 100.00%] [G loss: 4.832702]\n",
      "1069 [D loss: 0.280858, acc.: 94.44%] [G loss: 4.046846]\n",
      "1070 [D loss: 0.085187, acc.: 100.00%] [G loss: 3.435700]\n",
      "1071 [D loss: 0.078669, acc.: 100.00%] [G loss: 3.419444]\n",
      "1072 [D loss: 0.188484, acc.: 88.89%] [G loss: 3.931360]\n",
      "1073 [D loss: 0.156352, acc.: 100.00%] [G loss: 5.219975]\n",
      "1074 [D loss: 0.128365, acc.: 100.00%] [G loss: 3.332312]\n",
      "1075 [D loss: 0.073628, acc.: 100.00%] [G loss: 2.941217]\n",
      "1076 [D loss: 0.284555, acc.: 88.89%] [G loss: 3.638304]\n",
      "1077 [D loss: 0.366919, acc.: 83.33%] [G loss: 3.274731]\n",
      "1078 [D loss: 0.174061, acc.: 88.89%] [G loss: 3.773108]\n",
      "1079 [D loss: 0.107598, acc.: 100.00%] [G loss: 4.141024]\n",
      "1080 [D loss: 0.207856, acc.: 94.44%] [G loss: 2.445116]\n",
      "1081 [D loss: 0.207717, acc.: 88.89%] [G loss: 2.576346]\n",
      "1082 [D loss: 0.098117, acc.: 100.00%] [G loss: 4.876062]\n",
      "1083 [D loss: 0.233443, acc.: 94.44%] [G loss: 3.624833]\n",
      "1084 [D loss: 0.130473, acc.: 100.00%] [G loss: 4.119954]\n",
      "1085 [D loss: 0.233091, acc.: 88.89%] [G loss: 4.176276]\n",
      "1086 [D loss: 0.468008, acc.: 77.78%] [G loss: 3.623218]\n",
      "1087 [D loss: 0.127477, acc.: 100.00%] [G loss: 2.720922]\n",
      "1088 [D loss: 0.150807, acc.: 100.00%] [G loss: 4.150280]\n",
      "1089 [D loss: 0.309897, acc.: 83.33%] [G loss: 2.944093]\n",
      "1090 [D loss: 0.260088, acc.: 88.89%] [G loss: 3.743997]\n",
      "1091 [D loss: 0.158891, acc.: 94.44%] [G loss: 3.742686]\n",
      "1092 [D loss: 0.174616, acc.: 94.44%] [G loss: 3.966351]\n",
      "1093 [D loss: 0.120649, acc.: 100.00%] [G loss: 5.284521]\n",
      "1094 [D loss: 0.102491, acc.: 100.00%] [G loss: 3.920314]\n",
      "1095 [D loss: 0.489061, acc.: 77.78%] [G loss: 3.311141]\n",
      "1096 [D loss: 0.053591, acc.: 100.00%] [G loss: 3.597605]\n",
      "1097 [D loss: 0.174925, acc.: 94.44%] [G loss: 4.004644]\n",
      "1098 [D loss: 0.083038, acc.: 100.00%] [G loss: 4.298987]\n",
      "1099 [D loss: 0.259003, acc.: 77.78%] [G loss: 3.343299]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 [D loss: 0.321917, acc.: 88.89%] [G loss: 3.518692]\n",
      "1101 [D loss: 0.131205, acc.: 94.44%] [G loss: 3.056726]\n",
      "1102 [D loss: 0.138364, acc.: 100.00%] [G loss: 2.812349]\n",
      "1103 [D loss: 0.711129, acc.: 55.56%] [G loss: 3.588577]\n",
      "1104 [D loss: 0.426295, acc.: 83.33%] [G loss: 4.373881]\n",
      "1105 [D loss: 0.197468, acc.: 88.89%] [G loss: 2.651173]\n",
      "1106 [D loss: 0.240629, acc.: 83.33%] [G loss: 5.101686]\n",
      "1107 [D loss: 0.775840, acc.: 55.56%] [G loss: 2.814190]\n",
      "1108 [D loss: 0.396640, acc.: 83.33%] [G loss: 3.396830]\n",
      "1109 [D loss: 0.450956, acc.: 77.78%] [G loss: 3.786723]\n",
      "1110 [D loss: 0.149060, acc.: 100.00%] [G loss: 4.678980]\n",
      "1111 [D loss: 0.152324, acc.: 100.00%] [G loss: 3.262179]\n",
      "1112 [D loss: 0.154977, acc.: 100.00%] [G loss: 3.709638]\n",
      "1113 [D loss: 0.249746, acc.: 88.89%] [G loss: 4.013389]\n",
      "1114 [D loss: 0.174239, acc.: 94.44%] [G loss: 7.061094]\n",
      "1115 [D loss: 0.306564, acc.: 83.33%] [G loss: 4.396746]\n",
      "1116 [D loss: 0.254820, acc.: 83.33%] [G loss: 3.827367]\n",
      "1117 [D loss: 0.038412, acc.: 100.00%] [G loss: 5.124659]\n",
      "1118 [D loss: 0.269724, acc.: 94.44%] [G loss: 3.340364]\n",
      "1119 [D loss: 0.337841, acc.: 88.89%] [G loss: 3.759135]\n",
      "1120 [D loss: 0.095084, acc.: 100.00%] [G loss: 6.125019]\n",
      "1121 [D loss: 0.070545, acc.: 100.00%] [G loss: 5.466455]\n",
      "1122 [D loss: 0.332596, acc.: 77.78%] [G loss: 3.083382]\n",
      "1123 [D loss: 0.270180, acc.: 94.44%] [G loss: 3.541929]\n",
      "1124 [D loss: 0.074695, acc.: 100.00%] [G loss: 4.935357]\n",
      "1125 [D loss: 0.420687, acc.: 77.78%] [G loss: 3.644346]\n",
      "1126 [D loss: 0.108383, acc.: 94.44%] [G loss: 3.608548]\n",
      "1127 [D loss: 0.179477, acc.: 94.44%] [G loss: 2.552228]\n",
      "1128 [D loss: 0.141525, acc.: 100.00%] [G loss: 4.106956]\n",
      "1129 [D loss: 0.128887, acc.: 100.00%] [G loss: 3.390105]\n",
      "1130 [D loss: 0.118533, acc.: 100.00%] [G loss: 3.916373]\n",
      "1131 [D loss: 0.319478, acc.: 83.33%] [G loss: 3.094826]\n",
      "1132 [D loss: 0.224477, acc.: 94.44%] [G loss: 3.926261]\n",
      "1133 [D loss: 0.539581, acc.: 77.78%] [G loss: 2.646250]\n",
      "1134 [D loss: 0.125265, acc.: 94.44%] [G loss: 4.418276]\n",
      "1135 [D loss: 0.137561, acc.: 100.00%] [G loss: 3.216035]\n",
      "1136 [D loss: 0.433951, acc.: 77.78%] [G loss: 3.425968]\n",
      "1137 [D loss: 0.572614, acc.: 66.67%] [G loss: 3.191365]\n",
      "1138 [D loss: 0.483896, acc.: 77.78%] [G loss: 3.285344]\n",
      "1139 [D loss: 0.077387, acc.: 100.00%] [G loss: 3.756153]\n",
      "1140 [D loss: 0.245184, acc.: 88.89%] [G loss: 4.953786]\n",
      "1141 [D loss: 0.383924, acc.: 77.78%] [G loss: 4.133270]\n",
      "1142 [D loss: 0.197777, acc.: 83.33%] [G loss: 6.080698]\n",
      "1143 [D loss: 0.334037, acc.: 83.33%] [G loss: 2.646571]\n",
      "1144 [D loss: 0.383264, acc.: 83.33%] [G loss: 3.883727]\n",
      "1145 [D loss: 0.076773, acc.: 100.00%] [G loss: 4.740445]\n",
      "1146 [D loss: 0.113864, acc.: 94.44%] [G loss: 5.282674]\n",
      "1147 [D loss: 0.066300, acc.: 100.00%] [G loss: 5.038032]\n",
      "1148 [D loss: 0.263062, acc.: 83.33%] [G loss: 3.115957]\n",
      "1149 [D loss: 0.129172, acc.: 100.00%] [G loss: 3.727437]\n",
      "1150 [D loss: 0.295266, acc.: 88.89%] [G loss: 3.454276]\n",
      "1151 [D loss: 0.216899, acc.: 88.89%] [G loss: 3.557476]\n",
      "1152 [D loss: 0.139169, acc.: 94.44%] [G loss: 4.366552]\n",
      "1153 [D loss: 0.352698, acc.: 83.33%] [G loss: 3.809300]\n",
      "1154 [D loss: 0.351936, acc.: 83.33%] [G loss: 3.822923]\n",
      "1155 [D loss: 0.173982, acc.: 88.89%] [G loss: 4.159140]\n",
      "1156 [D loss: 0.197898, acc.: 88.89%] [G loss: 3.892009]\n",
      "1157 [D loss: 0.190192, acc.: 94.44%] [G loss: 3.965420]\n",
      "1158 [D loss: 0.289039, acc.: 83.33%] [G loss: 3.437385]\n",
      "1159 [D loss: 0.233758, acc.: 88.89%] [G loss: 5.936142]\n",
      "1160 [D loss: 0.089802, acc.: 94.44%] [G loss: 3.817784]\n",
      "1161 [D loss: 0.229432, acc.: 88.89%] [G loss: 3.468714]\n",
      "1162 [D loss: 0.145691, acc.: 88.89%] [G loss: 4.962856]\n",
      "1163 [D loss: 0.864080, acc.: 83.33%] [G loss: 2.032731]\n",
      "1164 [D loss: 0.348984, acc.: 94.44%] [G loss: 2.697710]\n",
      "1165 [D loss: 0.147265, acc.: 94.44%] [G loss: 6.958776]\n",
      "1166 [D loss: 0.317433, acc.: 88.89%] [G loss: 2.835658]\n",
      "1167 [D loss: 0.082457, acc.: 100.00%] [G loss: 4.482555]\n",
      "1168 [D loss: 0.427270, acc.: 77.78%] [G loss: 2.662026]\n",
      "1169 [D loss: 0.248853, acc.: 88.89%] [G loss: 3.085432]\n",
      "1170 [D loss: 0.151863, acc.: 94.44%] [G loss: 4.539945]\n",
      "1171 [D loss: 0.181869, acc.: 88.89%] [G loss: 4.615183]\n",
      "1172 [D loss: 0.319608, acc.: 88.89%] [G loss: 2.745021]\n",
      "1173 [D loss: 0.249776, acc.: 88.89%] [G loss: 3.658116]\n",
      "1174 [D loss: 0.204399, acc.: 88.89%] [G loss: 4.585563]\n",
      "1175 [D loss: 0.170677, acc.: 94.44%] [G loss: 4.890402]\n",
      "1176 [D loss: 0.323895, acc.: 83.33%] [G loss: 4.086229]\n",
      "1177 [D loss: 0.316225, acc.: 83.33%] [G loss: 4.291227]\n",
      "1178 [D loss: 0.158811, acc.: 88.89%] [G loss: 4.596239]\n",
      "1179 [D loss: 0.303702, acc.: 94.44%] [G loss: 2.938831]\n",
      "1180 [D loss: 0.291284, acc.: 88.89%] [G loss: 3.910064]\n",
      "1181 [D loss: 0.210531, acc.: 94.44%] [G loss: 4.483597]\n",
      "1182 [D loss: 0.117399, acc.: 100.00%] [G loss: 3.432266]\n",
      "1183 [D loss: 0.178414, acc.: 94.44%] [G loss: 3.982131]\n",
      "1184 [D loss: 0.165297, acc.: 88.89%] [G loss: 5.462107]\n",
      "1185 [D loss: 0.130144, acc.: 94.44%] [G loss: 5.190948]\n",
      "1186 [D loss: 0.176572, acc.: 88.89%] [G loss: 3.101326]\n",
      "1187 [D loss: 0.135461, acc.: 100.00%] [G loss: 6.384428]\n",
      "1188 [D loss: 0.062684, acc.: 100.00%] [G loss: 3.578671]\n",
      "1189 [D loss: 0.142133, acc.: 94.44%] [G loss: 3.938004]\n",
      "1190 [D loss: 0.121096, acc.: 94.44%] [G loss: 5.843420]\n",
      "1191 [D loss: 0.114496, acc.: 100.00%] [G loss: 3.387775]\n",
      "1192 [D loss: 0.212835, acc.: 88.89%] [G loss: 3.290153]\n",
      "1193 [D loss: 0.134149, acc.: 94.44%] [G loss: 4.118684]\n",
      "1194 [D loss: 0.392809, acc.: 83.33%] [G loss: 3.590625]\n",
      "1195 [D loss: 0.211553, acc.: 94.44%] [G loss: 3.249768]\n",
      "1196 [D loss: 0.139290, acc.: 94.44%] [G loss: 4.907344]\n",
      "1197 [D loss: 0.351796, acc.: 83.33%] [G loss: 3.980891]\n",
      "1198 [D loss: 0.266058, acc.: 83.33%] [G loss: 3.215214]\n",
      "1199 [D loss: 0.255957, acc.: 94.44%] [G loss: 2.953932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 [D loss: 0.087327, acc.: 94.44%] [G loss: 5.084364]\n",
      "1201 [D loss: 0.272247, acc.: 83.33%] [G loss: 3.521309]\n",
      "1202 [D loss: 0.100473, acc.: 100.00%] [G loss: 3.945991]\n",
      "1203 [D loss: 0.246377, acc.: 88.89%] [G loss: 4.021953]\n",
      "1204 [D loss: 0.299503, acc.: 77.78%] [G loss: 3.370839]\n",
      "1205 [D loss: 0.200459, acc.: 94.44%] [G loss: 3.111192]\n",
      "1206 [D loss: 0.175689, acc.: 94.44%] [G loss: 4.480767]\n",
      "1207 [D loss: 0.259906, acc.: 83.33%] [G loss: 4.947989]\n",
      "1208 [D loss: 0.142974, acc.: 94.44%] [G loss: 3.806485]\n",
      "1209 [D loss: 0.194790, acc.: 88.89%] [G loss: 4.353445]\n",
      "1210 [D loss: 0.382124, acc.: 88.89%] [G loss: 3.090583]\n",
      "1211 [D loss: 0.126508, acc.: 100.00%] [G loss: 3.261236]\n",
      "1212 [D loss: 0.149111, acc.: 94.44%] [G loss: 4.763447]\n",
      "1213 [D loss: 0.277292, acc.: 94.44%] [G loss: 4.060834]\n",
      "1214 [D loss: 0.075479, acc.: 100.00%] [G loss: 4.121832]\n",
      "1215 [D loss: 0.097944, acc.: 94.44%] [G loss: 7.812780]\n",
      "1216 [D loss: 0.049178, acc.: 100.00%] [G loss: 4.990737]\n",
      "1217 [D loss: 0.126910, acc.: 94.44%] [G loss: 4.261003]\n",
      "1218 [D loss: 0.244965, acc.: 83.33%] [G loss: 4.319448]\n",
      "1219 [D loss: 0.045543, acc.: 100.00%] [G loss: 4.842036]\n",
      "1220 [D loss: 0.069863, acc.: 100.00%] [G loss: 7.016943]\n",
      "1221 [D loss: 0.122306, acc.: 94.44%] [G loss: 5.424244]\n",
      "1222 [D loss: 0.135158, acc.: 94.44%] [G loss: 3.800707]\n",
      "1223 [D loss: 0.131145, acc.: 100.00%] [G loss: 4.254335]\n",
      "1224 [D loss: 0.290169, acc.: 83.33%] [G loss: 5.999491]\n",
      "1225 [D loss: 0.502006, acc.: 66.67%] [G loss: 3.564858]\n",
      "1226 [D loss: 0.126063, acc.: 94.44%] [G loss: 3.817065]\n",
      "1227 [D loss: 0.039455, acc.: 100.00%] [G loss: 3.844839]\n",
      "1228 [D loss: 0.112314, acc.: 94.44%] [G loss: 2.777460]\n",
      "1229 [D loss: 0.137126, acc.: 88.89%] [G loss: 5.958112]\n",
      "1230 [D loss: 0.297547, acc.: 88.89%] [G loss: 4.674303]\n",
      "1231 [D loss: 0.087144, acc.: 100.00%] [G loss: 4.604804]\n",
      "1232 [D loss: 0.175034, acc.: 94.44%] [G loss: 4.141598]\n",
      "1233 [D loss: 0.135422, acc.: 100.00%] [G loss: 5.168833]\n",
      "1234 [D loss: 0.061245, acc.: 100.00%] [G loss: 5.352134]\n",
      "1235 [D loss: 0.118486, acc.: 100.00%] [G loss: 3.384822]\n",
      "1236 [D loss: 0.038109, acc.: 100.00%] [G loss: 3.760745]\n",
      "1237 [D loss: 0.174849, acc.: 100.00%] [G loss: 3.701533]\n",
      "1238 [D loss: 0.075875, acc.: 100.00%] [G loss: 3.023644]\n",
      "1239 [D loss: 0.570071, acc.: 72.22%] [G loss: 2.584720]\n",
      "1240 [D loss: 0.111320, acc.: 94.44%] [G loss: 3.581541]\n",
      "1241 [D loss: 0.202018, acc.: 94.44%] [G loss: 3.901197]\n",
      "1242 [D loss: 0.074381, acc.: 100.00%] [G loss: 5.040951]\n",
      "1243 [D loss: 0.162193, acc.: 88.89%] [G loss: 4.103683]\n",
      "1244 [D loss: 0.107732, acc.: 100.00%] [G loss: 6.023276]\n",
      "1245 [D loss: 0.039177, acc.: 100.00%] [G loss: 3.661858]\n",
      "1246 [D loss: 0.399426, acc.: 77.78%] [G loss: 4.063977]\n",
      "1247 [D loss: 0.110553, acc.: 100.00%] [G loss: 4.092798]\n",
      "1248 [D loss: 0.051153, acc.: 100.00%] [G loss: 4.366792]\n",
      "1249 [D loss: 0.098580, acc.: 94.44%] [G loss: 3.607850]\n",
      "1250 [D loss: 0.101523, acc.: 100.00%] [G loss: 3.897498]\n",
      "1251 [D loss: 0.174197, acc.: 94.44%] [G loss: 4.611821]\n",
      "1252 [D loss: 0.454271, acc.: 77.78%] [G loss: 3.878606]\n",
      "1253 [D loss: 0.283690, acc.: 83.33%] [G loss: 3.607940]\n",
      "1254 [D loss: 0.065900, acc.: 100.00%] [G loss: 3.408236]\n",
      "1255 [D loss: 0.070099, acc.: 100.00%] [G loss: 3.542452]\n",
      "1256 [D loss: 0.160935, acc.: 94.44%] [G loss: 2.929768]\n",
      "1257 [D loss: 0.115730, acc.: 94.44%] [G loss: 4.332276]\n",
      "1258 [D loss: 0.105345, acc.: 100.00%] [G loss: 4.698950]\n",
      "1259 [D loss: 0.388716, acc.: 83.33%] [G loss: 3.814267]\n",
      "1260 [D loss: 0.105008, acc.: 94.44%] [G loss: 5.627459]\n",
      "1261 [D loss: 0.167994, acc.: 94.44%] [G loss: 4.457787]\n",
      "1262 [D loss: 0.051172, acc.: 100.00%] [G loss: 5.952341]\n",
      "1263 [D loss: 0.072600, acc.: 100.00%] [G loss: 3.935232]\n",
      "1264 [D loss: 0.311588, acc.: 83.33%] [G loss: 2.897691]\n",
      "1265 [D loss: 0.076627, acc.: 100.00%] [G loss: 4.606066]\n",
      "1266 [D loss: 0.128934, acc.: 94.44%] [G loss: 3.057387]\n",
      "1267 [D loss: 0.238771, acc.: 94.44%] [G loss: 3.680064]\n",
      "1268 [D loss: 0.255359, acc.: 94.44%] [G loss: 3.420861]\n",
      "1269 [D loss: 0.161047, acc.: 94.44%] [G loss: 5.266961]\n",
      "1270 [D loss: 0.203686, acc.: 88.89%] [G loss: 3.686389]\n",
      "1271 [D loss: 0.195438, acc.: 88.89%] [G loss: 3.623506]\n",
      "1272 [D loss: 0.123433, acc.: 100.00%] [G loss: 3.360439]\n",
      "1273 [D loss: 0.067057, acc.: 100.00%] [G loss: 4.144871]\n",
      "1274 [D loss: 0.108455, acc.: 94.44%] [G loss: 3.453851]\n",
      "1275 [D loss: 0.232760, acc.: 88.89%] [G loss: 5.141706]\n",
      "1276 [D loss: 0.210689, acc.: 88.89%] [G loss: 4.977650]\n",
      "1277 [D loss: 0.282544, acc.: 88.89%] [G loss: 4.442463]\n",
      "1278 [D loss: 0.273514, acc.: 88.89%] [G loss: 4.395936]\n",
      "1279 [D loss: 0.588130, acc.: 72.22%] [G loss: 4.068267]\n",
      "1280 [D loss: 0.143790, acc.: 94.44%] [G loss: 5.884181]\n",
      "1281 [D loss: 0.513319, acc.: 77.78%] [G loss: 3.388485]\n",
      "1282 [D loss: 0.371664, acc.: 94.44%] [G loss: 3.317648]\n",
      "1283 [D loss: 0.308778, acc.: 83.33%] [G loss: 4.233870]\n",
      "1284 [D loss: 0.249403, acc.: 88.89%] [G loss: 4.451004]\n",
      "1285 [D loss: 0.147871, acc.: 94.44%] [G loss: 5.567585]\n",
      "1286 [D loss: 0.191469, acc.: 88.89%] [G loss: 3.899059]\n",
      "1287 [D loss: 0.140959, acc.: 88.89%] [G loss: 3.746175]\n",
      "1288 [D loss: 0.126559, acc.: 94.44%] [G loss: 3.623677]\n",
      "1289 [D loss: 0.179000, acc.: 94.44%] [G loss: 3.380980]\n",
      "1290 [D loss: 0.071250, acc.: 100.00%] [G loss: 2.869786]\n",
      "1291 [D loss: 0.266306, acc.: 88.89%] [G loss: 4.194154]\n",
      "1292 [D loss: 0.074512, acc.: 100.00%] [G loss: 3.773495]\n",
      "1293 [D loss: 0.078857, acc.: 100.00%] [G loss: 3.627229]\n",
      "1294 [D loss: 0.101035, acc.: 100.00%] [G loss: 3.188577]\n",
      "1295 [D loss: 0.102894, acc.: 100.00%] [G loss: 3.605768]\n",
      "1296 [D loss: 0.114782, acc.: 94.44%] [G loss: 4.186357]\n",
      "1297 [D loss: 0.443062, acc.: 77.78%] [G loss: 3.665057]\n",
      "1298 [D loss: 0.041471, acc.: 100.00%] [G loss: 7.441519]\n",
      "1299 [D loss: 0.421435, acc.: 88.89%] [G loss: 3.842336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 [D loss: 0.145229, acc.: 94.44%] [G loss: 5.371818]\n",
      "1301 [D loss: 0.094991, acc.: 100.00%] [G loss: 4.080634]\n",
      "1302 [D loss: 0.114298, acc.: 94.44%] [G loss: 4.002409]\n",
      "1303 [D loss: 0.081587, acc.: 100.00%] [G loss: 3.362592]\n",
      "1304 [D loss: 0.075180, acc.: 100.00%] [G loss: 3.080921]\n",
      "1305 [D loss: 0.406200, acc.: 88.89%] [G loss: 3.764904]\n",
      "1306 [D loss: 0.140038, acc.: 94.44%] [G loss: 5.653429]\n",
      "1307 [D loss: 0.123498, acc.: 94.44%] [G loss: 5.769724]\n",
      "1308 [D loss: 0.063506, acc.: 100.00%] [G loss: 5.039098]\n",
      "1309 [D loss: 0.208500, acc.: 94.44%] [G loss: 3.864274]\n",
      "1310 [D loss: 0.055296, acc.: 100.00%] [G loss: 4.428357]\n",
      "1311 [D loss: 0.055602, acc.: 100.00%] [G loss: 5.510683]\n",
      "1312 [D loss: 0.112198, acc.: 94.44%] [G loss: 3.246765]\n",
      "1313 [D loss: 0.473677, acc.: 72.22%] [G loss: 3.969012]\n",
      "1314 [D loss: 0.066794, acc.: 100.00%] [G loss: 7.533705]\n",
      "1315 [D loss: 0.137446, acc.: 94.44%] [G loss: 4.507889]\n",
      "1316 [D loss: 0.290359, acc.: 83.33%] [G loss: 3.580961]\n",
      "1317 [D loss: 0.310149, acc.: 83.33%] [G loss: 3.923931]\n",
      "1318 [D loss: 0.265063, acc.: 88.89%] [G loss: 3.026864]\n",
      "1319 [D loss: 0.091856, acc.: 100.00%] [G loss: 3.804606]\n",
      "1320 [D loss: 0.121531, acc.: 100.00%] [G loss: 4.092035]\n",
      "1321 [D loss: 0.422818, acc.: 83.33%] [G loss: 6.046912]\n",
      "1322 [D loss: 0.256093, acc.: 94.44%] [G loss: 3.562368]\n",
      "1323 [D loss: 0.140006, acc.: 100.00%] [G loss: 2.448588]\n",
      "1324 [D loss: 0.202028, acc.: 94.44%] [G loss: 2.779657]\n",
      "1325 [D loss: 0.066327, acc.: 100.00%] [G loss: 3.778194]\n",
      "1326 [D loss: 0.231367, acc.: 88.89%] [G loss: 4.389009]\n",
      "1327 [D loss: 0.378412, acc.: 88.89%] [G loss: 4.058951]\n",
      "1328 [D loss: 0.268120, acc.: 88.89%] [G loss: 3.864962]\n",
      "1329 [D loss: 0.561617, acc.: 72.22%] [G loss: 4.874904]\n",
      "1330 [D loss: 0.298494, acc.: 83.33%] [G loss: 5.336071]\n",
      "1331 [D loss: 0.231856, acc.: 88.89%] [G loss: 4.888779]\n",
      "1332 [D loss: 0.070552, acc.: 100.00%] [G loss: 4.874032]\n",
      "1333 [D loss: 0.135543, acc.: 100.00%] [G loss: 4.347178]\n",
      "1334 [D loss: 0.195128, acc.: 94.44%] [G loss: 4.098951]\n",
      "1335 [D loss: 0.110637, acc.: 94.44%] [G loss: 3.913228]\n",
      "1336 [D loss: 0.102871, acc.: 94.44%] [G loss: 5.102786]\n",
      "1337 [D loss: 0.119510, acc.: 94.44%] [G loss: 4.130106]\n",
      "1338 [D loss: 0.091305, acc.: 94.44%] [G loss: 3.672886]\n",
      "1339 [D loss: 0.110562, acc.: 94.44%] [G loss: 3.974021]\n",
      "1340 [D loss: 0.115148, acc.: 100.00%] [G loss: 2.851334]\n",
      "1341 [D loss: 0.075553, acc.: 100.00%] [G loss: 3.449485]\n",
      "1342 [D loss: 0.065594, acc.: 100.00%] [G loss: 3.679659]\n",
      "1343 [D loss: 0.317748, acc.: 77.78%] [G loss: 2.664938]\n",
      "1344 [D loss: 0.135291, acc.: 94.44%] [G loss: 4.741944]\n",
      "1345 [D loss: 0.336722, acc.: 83.33%] [G loss: 3.131802]\n",
      "1346 [D loss: 0.145187, acc.: 94.44%] [G loss: 3.998953]\n",
      "1347 [D loss: 0.449609, acc.: 72.22%] [G loss: 3.807738]\n",
      "1348 [D loss: 0.180728, acc.: 88.89%] [G loss: 5.665399]\n",
      "1349 [D loss: 0.311787, acc.: 77.78%] [G loss: 4.945858]\n",
      "1350 [D loss: 0.128248, acc.: 94.44%] [G loss: 4.849359]\n",
      "1351 [D loss: 0.194885, acc.: 94.44%] [G loss: 3.084816]\n",
      "1352 [D loss: 0.455802, acc.: 88.89%] [G loss: 3.685243]\n",
      "1353 [D loss: 0.119673, acc.: 94.44%] [G loss: 4.601895]\n",
      "1354 [D loss: 0.388878, acc.: 83.33%] [G loss: 4.149240]\n",
      "1355 [D loss: 0.332580, acc.: 88.89%] [G loss: 3.523397]\n",
      "1356 [D loss: 0.167205, acc.: 94.44%] [G loss: 4.628254]\n",
      "1357 [D loss: 0.014346, acc.: 100.00%] [G loss: 8.001156]\n",
      "1358 [D loss: 0.155009, acc.: 88.89%] [G loss: 4.942731]\n",
      "1359 [D loss: 0.046039, acc.: 100.00%] [G loss: 5.149084]\n",
      "1360 [D loss: 0.159785, acc.: 100.00%] [G loss: 3.969486]\n",
      "1361 [D loss: 0.690288, acc.: 72.22%] [G loss: 5.647089]\n",
      "1362 [D loss: 0.404360, acc.: 77.78%] [G loss: 4.628533]\n",
      "1363 [D loss: 0.314696, acc.: 77.78%] [G loss: 4.946183]\n",
      "1364 [D loss: 0.447382, acc.: 88.89%] [G loss: 4.244416]\n",
      "1365 [D loss: 0.043312, acc.: 100.00%] [G loss: 5.072724]\n",
      "1366 [D loss: 0.433883, acc.: 77.78%] [G loss: 3.630071]\n",
      "1367 [D loss: 0.225063, acc.: 94.44%] [G loss: 3.977066]\n",
      "1368 [D loss: 0.305324, acc.: 77.78%] [G loss: 4.929886]\n",
      "1369 [D loss: 0.034030, acc.: 100.00%] [G loss: 5.444361]\n",
      "1370 [D loss: 0.476465, acc.: 72.22%] [G loss: 3.569089]\n",
      "1371 [D loss: 0.122714, acc.: 94.44%] [G loss: 3.211199]\n",
      "1372 [D loss: 0.535976, acc.: 83.33%] [G loss: 4.102693]\n",
      "1373 [D loss: 0.054598, acc.: 100.00%] [G loss: 4.449763]\n",
      "1374 [D loss: 0.257671, acc.: 83.33%] [G loss: 4.963181]\n",
      "1375 [D loss: 0.426622, acc.: 83.33%] [G loss: 3.644257]\n",
      "1376 [D loss: 0.390677, acc.: 94.44%] [G loss: 3.363591]\n",
      "1377 [D loss: 0.303013, acc.: 77.78%] [G loss: 4.857097]\n",
      "1378 [D loss: 0.388247, acc.: 88.89%] [G loss: 3.096791]\n",
      "1379 [D loss: 0.213842, acc.: 94.44%] [G loss: 4.389724]\n",
      "1380 [D loss: 0.291347, acc.: 88.89%] [G loss: 4.075377]\n",
      "1381 [D loss: 0.236055, acc.: 94.44%] [G loss: 4.537591]\n",
      "1382 [D loss: 0.197490, acc.: 94.44%] [G loss: 3.335326]\n",
      "1383 [D loss: 0.301030, acc.: 94.44%] [G loss: 3.756630]\n",
      "1384 [D loss: 0.161633, acc.: 88.89%] [G loss: 4.575315]\n",
      "1385 [D loss: 0.285083, acc.: 88.89%] [G loss: 3.818501]\n",
      "1386 [D loss: 0.280277, acc.: 88.89%] [G loss: 4.159478]\n",
      "1387 [D loss: 0.104255, acc.: 94.44%] [G loss: 4.920040]\n",
      "1388 [D loss: 0.105766, acc.: 94.44%] [G loss: 4.072728]\n",
      "1389 [D loss: 0.164306, acc.: 94.44%] [G loss: 3.650173]\n",
      "1390 [D loss: 0.335778, acc.: 83.33%] [G loss: 2.945747]\n",
      "1391 [D loss: 0.136290, acc.: 100.00%] [G loss: 2.407321]\n",
      "1392 [D loss: 0.204007, acc.: 88.89%] [G loss: 3.289208]\n",
      "1393 [D loss: 0.156360, acc.: 100.00%] [G loss: 4.296517]\n",
      "1394 [D loss: 0.127530, acc.: 94.44%] [G loss: 3.829098]\n",
      "1395 [D loss: 0.098200, acc.: 100.00%] [G loss: 4.433425]\n",
      "1396 [D loss: 0.044567, acc.: 100.00%] [G loss: 4.149233]\n",
      "1397 [D loss: 0.020400, acc.: 100.00%] [G loss: 3.911565]\n",
      "1398 [D loss: 0.354341, acc.: 83.33%] [G loss: 5.089331]\n",
      "1399 [D loss: 0.059552, acc.: 100.00%] [G loss: 4.434014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 [D loss: 0.198035, acc.: 94.44%] [G loss: 3.878544]\n",
      "1401 [D loss: 0.208508, acc.: 94.44%] [G loss: 4.335548]\n",
      "1402 [D loss: 0.239942, acc.: 88.89%] [G loss: 3.748135]\n",
      "1403 [D loss: 0.146851, acc.: 94.44%] [G loss: 4.825326]\n",
      "1404 [D loss: 0.054903, acc.: 100.00%] [G loss: 4.937404]\n",
      "1405 [D loss: 0.108609, acc.: 94.44%] [G loss: 3.883502]\n",
      "1406 [D loss: 0.092942, acc.: 100.00%] [G loss: 5.169753]\n",
      "1407 [D loss: 0.239536, acc.: 88.89%] [G loss: 3.397105]\n",
      "1408 [D loss: 0.194815, acc.: 94.44%] [G loss: 2.420625]\n",
      "1409 [D loss: 0.212229, acc.: 94.44%] [G loss: 4.163517]\n",
      "1410 [D loss: 0.247683, acc.: 88.89%] [G loss: 4.155607]\n",
      "1411 [D loss: 0.471747, acc.: 83.33%] [G loss: 4.746031]\n",
      "1412 [D loss: 0.259847, acc.: 83.33%] [G loss: 3.880937]\n",
      "1413 [D loss: 0.269558, acc.: 88.89%] [G loss: 3.166800]\n",
      "1414 [D loss: 0.021127, acc.: 100.00%] [G loss: 7.009809]\n",
      "1415 [D loss: 0.021426, acc.: 100.00%] [G loss: 5.216573]\n",
      "1416 [D loss: 0.056595, acc.: 100.00%] [G loss: 5.180703]\n",
      "1417 [D loss: 0.121870, acc.: 100.00%] [G loss: 4.372149]\n",
      "1418 [D loss: 0.041297, acc.: 100.00%] [G loss: 4.690382]\n",
      "1419 [D loss: 0.172700, acc.: 94.44%] [G loss: 2.835463]\n",
      "1420 [D loss: 0.205065, acc.: 88.89%] [G loss: 4.435615]\n",
      "1421 [D loss: 0.107370, acc.: 94.44%] [G loss: 4.668703]\n",
      "1422 [D loss: 0.642280, acc.: 61.11%] [G loss: 2.850454]\n",
      "1423 [D loss: 0.079903, acc.: 100.00%] [G loss: 2.747589]\n",
      "1424 [D loss: 0.202507, acc.: 94.44%] [G loss: 4.864817]\n",
      "1425 [D loss: 0.236182, acc.: 88.89%] [G loss: 4.196636]\n",
      "1426 [D loss: 0.656942, acc.: 66.67%] [G loss: 4.066580]\n",
      "1427 [D loss: 0.163622, acc.: 94.44%] [G loss: 5.432410]\n",
      "1428 [D loss: 0.087364, acc.: 100.00%] [G loss: 5.244305]\n",
      "1429 [D loss: 0.263170, acc.: 88.89%] [G loss: 3.736353]\n",
      "1430 [D loss: 0.351911, acc.: 83.33%] [G loss: 3.811584]\n",
      "1431 [D loss: 0.307631, acc.: 88.89%] [G loss: 4.011101]\n",
      "1432 [D loss: 0.164997, acc.: 94.44%] [G loss: 4.676744]\n",
      "1433 [D loss: 0.261343, acc.: 88.89%] [G loss: 4.024170]\n",
      "1434 [D loss: 0.110705, acc.: 100.00%] [G loss: 3.003821]\n",
      "1435 [D loss: 0.608631, acc.: 77.78%] [G loss: 5.050637]\n",
      "1436 [D loss: 0.169650, acc.: 94.44%] [G loss: 6.493756]\n",
      "1437 [D loss: 0.379669, acc.: 83.33%] [G loss: 2.765987]\n",
      "1438 [D loss: 0.189386, acc.: 88.89%] [G loss: 3.325770]\n",
      "1439 [D loss: 0.091974, acc.: 100.00%] [G loss: 5.475780]\n",
      "1440 [D loss: 0.174801, acc.: 88.89%] [G loss: 4.829262]\n",
      "1441 [D loss: 0.345052, acc.: 88.89%] [G loss: 3.440168]\n",
      "1442 [D loss: 0.100568, acc.: 100.00%] [G loss: 4.298218]\n",
      "1443 [D loss: 0.124227, acc.: 100.00%] [G loss: 3.904926]\n",
      "1444 [D loss: 0.047215, acc.: 100.00%] [G loss: 6.940149]\n",
      "1445 [D loss: 0.076335, acc.: 100.00%] [G loss: 5.648476]\n",
      "1446 [D loss: 0.230306, acc.: 94.44%] [G loss: 5.538891]\n",
      "1447 [D loss: 0.123403, acc.: 100.00%] [G loss: 4.145165]\n",
      "1448 [D loss: 0.042187, acc.: 100.00%] [G loss: 5.709192]\n",
      "1449 [D loss: 0.101529, acc.: 94.44%] [G loss: 3.868749]\n",
      "1450 [D loss: 0.091960, acc.: 100.00%] [G loss: 3.112417]\n",
      "1451 [D loss: 0.140080, acc.: 94.44%] [G loss: 5.258776]\n",
      "1452 [D loss: 0.030040, acc.: 100.00%] [G loss: 4.395067]\n",
      "1453 [D loss: 0.248025, acc.: 94.44%] [G loss: 3.069781]\n",
      "1454 [D loss: 0.246118, acc.: 83.33%] [G loss: 4.138826]\n",
      "1455 [D loss: 0.131299, acc.: 88.89%] [G loss: 4.259910]\n",
      "1456 [D loss: 0.137782, acc.: 100.00%] [G loss: 3.859445]\n",
      "1457 [D loss: 0.177524, acc.: 94.44%] [G loss: 5.233616]\n",
      "1458 [D loss: 0.084736, acc.: 100.00%] [G loss: 3.927448]\n",
      "1459 [D loss: 0.418733, acc.: 88.89%] [G loss: 5.630281]\n",
      "1460 [D loss: 0.261185, acc.: 83.33%] [G loss: 5.088326]\n",
      "1461 [D loss: 0.601184, acc.: 61.11%] [G loss: 4.213773]\n",
      "1462 [D loss: 0.072459, acc.: 100.00%] [G loss: 3.996316]\n",
      "1463 [D loss: 0.177261, acc.: 100.00%] [G loss: 3.862718]\n",
      "1464 [D loss: 0.108194, acc.: 94.44%] [G loss: 4.708154]\n",
      "1465 [D loss: 0.122530, acc.: 94.44%] [G loss: 3.686055]\n",
      "1466 [D loss: 0.097008, acc.: 100.00%] [G loss: 3.390389]\n",
      "1467 [D loss: 0.094562, acc.: 94.44%] [G loss: 4.588324]\n",
      "1468 [D loss: 0.125841, acc.: 94.44%] [G loss: 3.902572]\n",
      "1469 [D loss: 0.270778, acc.: 83.33%] [G loss: 4.636571]\n",
      "1470 [D loss: 0.048312, acc.: 100.00%] [G loss: 5.465572]\n",
      "1471 [D loss: 0.072410, acc.: 94.44%] [G loss: 3.628175]\n",
      "1472 [D loss: 0.235989, acc.: 83.33%] [G loss: 4.433830]\n",
      "1473 [D loss: 0.022463, acc.: 100.00%] [G loss: 4.674073]\n",
      "1474 [D loss: 0.300229, acc.: 88.89%] [G loss: 3.910647]\n",
      "1475 [D loss: 0.115324, acc.: 94.44%] [G loss: 3.583940]\n",
      "1476 [D loss: 0.164645, acc.: 100.00%] [G loss: 4.624664]\n",
      "1477 [D loss: 0.044289, acc.: 100.00%] [G loss: 4.049382]\n",
      "1478 [D loss: 0.116339, acc.: 88.89%] [G loss: 3.426393]\n",
      "1479 [D loss: 0.084207, acc.: 100.00%] [G loss: 3.266741]\n",
      "1480 [D loss: 0.347547, acc.: 88.89%] [G loss: 4.568756]\n",
      "1481 [D loss: 0.223024, acc.: 94.44%] [G loss: 5.313753]\n",
      "1482 [D loss: 0.555042, acc.: 77.78%] [G loss: 2.778615]\n",
      "1483 [D loss: 0.297524, acc.: 77.78%] [G loss: 4.722862]\n",
      "1484 [D loss: 0.068751, acc.: 94.44%] [G loss: 3.989056]\n",
      "1485 [D loss: 0.201417, acc.: 94.44%] [G loss: 4.689177]\n",
      "1486 [D loss: 0.264426, acc.: 88.89%] [G loss: 4.041460]\n",
      "1487 [D loss: 0.034429, acc.: 100.00%] [G loss: 3.349748]\n",
      "1488 [D loss: 0.188839, acc.: 88.89%] [G loss: 3.573018]\n",
      "1489 [D loss: 0.027002, acc.: 100.00%] [G loss: 4.345283]\n",
      "1490 [D loss: 0.536484, acc.: 88.89%] [G loss: 3.359260]\n",
      "1491 [D loss: 0.125545, acc.: 94.44%] [G loss: 5.273242]\n",
      "1492 [D loss: 0.174777, acc.: 88.89%] [G loss: 2.889112]\n",
      "1493 [D loss: 0.094265, acc.: 100.00%] [G loss: 3.787870]\n",
      "1494 [D loss: 0.106262, acc.: 100.00%] [G loss: 3.627062]\n",
      "1495 [D loss: 0.147437, acc.: 88.89%] [G loss: 4.282952]\n",
      "1496 [D loss: 0.144898, acc.: 94.44%] [G loss: 3.200862]\n",
      "1497 [D loss: 0.109217, acc.: 100.00%] [G loss: 3.288382]\n",
      "1498 [D loss: 0.068698, acc.: 100.00%] [G loss: 3.860004]\n",
      "1499 [D loss: 0.388244, acc.: 83.33%] [G loss: 3.377872]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 [D loss: 0.049332, acc.: 100.00%] [G loss: 4.391334]\n",
      "1501 [D loss: 0.128788, acc.: 100.00%] [G loss: 3.817545]\n",
      "1502 [D loss: 0.100167, acc.: 94.44%] [G loss: 9.076250]\n",
      "1503 [D loss: 0.132366, acc.: 94.44%] [G loss: 3.692663]\n",
      "1504 [D loss: 0.142004, acc.: 94.44%] [G loss: 3.544457]\n",
      "1505 [D loss: 0.117179, acc.: 100.00%] [G loss: 4.345073]\n",
      "1506 [D loss: 0.222381, acc.: 88.89%] [G loss: 5.416145]\n",
      "1507 [D loss: 0.176291, acc.: 94.44%] [G loss: 3.893618]\n",
      "1508 [D loss: 0.133180, acc.: 94.44%] [G loss: 5.116639]\n",
      "1509 [D loss: 0.069408, acc.: 100.00%] [G loss: 4.604788]\n",
      "1510 [D loss: 0.213741, acc.: 88.89%] [G loss: 2.986737]\n",
      "1511 [D loss: 0.087977, acc.: 100.00%] [G loss: 4.663445]\n",
      "1512 [D loss: 0.409325, acc.: 88.89%] [G loss: 4.993076]\n",
      "1513 [D loss: 0.350532, acc.: 83.33%] [G loss: 4.595837]\n",
      "1514 [D loss: 0.562686, acc.: 77.78%] [G loss: 3.361796]\n",
      "1515 [D loss: 0.196847, acc.: 100.00%] [G loss: 3.606833]\n",
      "1516 [D loss: 0.287424, acc.: 88.89%] [G loss: 5.043151]\n",
      "1517 [D loss: 0.181556, acc.: 94.44%] [G loss: 6.313020]\n",
      "1518 [D loss: 0.147310, acc.: 100.00%] [G loss: 5.897797]\n",
      "1519 [D loss: 0.426368, acc.: 83.33%] [G loss: 4.803428]\n",
      "1520 [D loss: 0.304143, acc.: 83.33%] [G loss: 3.592177]\n",
      "1521 [D loss: 0.045836, acc.: 100.00%] [G loss: 5.303774]\n",
      "1522 [D loss: 0.062446, acc.: 100.00%] [G loss: 9.164440]\n",
      "1523 [D loss: 0.225570, acc.: 88.89%] [G loss: 4.769759]\n",
      "1524 [D loss: 0.054806, acc.: 100.00%] [G loss: 5.679115]\n",
      "1525 [D loss: 0.110726, acc.: 94.44%] [G loss: 4.642546]\n",
      "1526 [D loss: 0.318734, acc.: 88.89%] [G loss: 5.531856]\n",
      "1527 [D loss: 0.174437, acc.: 88.89%] [G loss: 3.731339]\n",
      "1528 [D loss: 0.232168, acc.: 94.44%] [G loss: 4.725888]\n",
      "1529 [D loss: 0.130278, acc.: 94.44%] [G loss: 4.666089]\n",
      "1530 [D loss: 0.155066, acc.: 94.44%] [G loss: 4.849173]\n",
      "1531 [D loss: 0.240405, acc.: 88.89%] [G loss: 2.385253]\n",
      "1532 [D loss: 0.053347, acc.: 100.00%] [G loss: 4.715127]\n",
      "1533 [D loss: 0.202103, acc.: 83.33%] [G loss: 3.701329]\n",
      "1534 [D loss: 0.094993, acc.: 94.44%] [G loss: 5.322195]\n",
      "1535 [D loss: 0.099021, acc.: 94.44%] [G loss: 3.776508]\n",
      "1536 [D loss: 0.156234, acc.: 94.44%] [G loss: 4.085515]\n",
      "1537 [D loss: 0.155568, acc.: 94.44%] [G loss: 4.477589]\n",
      "1538 [D loss: 0.052700, acc.: 100.00%] [G loss: 4.109757]\n",
      "1539 [D loss: 0.158575, acc.: 94.44%] [G loss: 2.743026]\n",
      "1540 [D loss: 0.212616, acc.: 94.44%] [G loss: 3.149129]\n",
      "1541 [D loss: 0.368716, acc.: 83.33%] [G loss: 4.012046]\n",
      "1542 [D loss: 0.222330, acc.: 88.89%] [G loss: 4.713827]\n",
      "1543 [D loss: 0.140353, acc.: 100.00%] [G loss: 4.568178]\n",
      "1544 [D loss: 0.125595, acc.: 94.44%] [G loss: 3.832747]\n",
      "1545 [D loss: 0.175527, acc.: 88.89%] [G loss: 6.475940]\n",
      "1546 [D loss: 0.121203, acc.: 94.44%] [G loss: 7.610002]\n",
      "1547 [D loss: 0.297461, acc.: 77.78%] [G loss: 4.284649]\n",
      "1548 [D loss: 0.149446, acc.: 94.44%] [G loss: 3.704044]\n",
      "1549 [D loss: 0.159317, acc.: 94.44%] [G loss: 4.799774]\n",
      "1550 [D loss: 0.118012, acc.: 94.44%] [G loss: 5.465256]\n",
      "1551 [D loss: 0.036660, acc.: 100.00%] [G loss: 4.176259]\n",
      "1552 [D loss: 0.122598, acc.: 94.44%] [G loss: 5.213124]\n",
      "1553 [D loss: 0.103095, acc.: 94.44%] [G loss: 5.079100]\n",
      "1554 [D loss: 0.132516, acc.: 100.00%] [G loss: 4.569818]\n",
      "1555 [D loss: 0.061313, acc.: 100.00%] [G loss: 4.317318]\n",
      "1556 [D loss: 0.148342, acc.: 94.44%] [G loss: 2.939380]\n",
      "1557 [D loss: 0.047409, acc.: 100.00%] [G loss: 5.224278]\n",
      "1558 [D loss: 0.167027, acc.: 88.89%] [G loss: 5.326484]\n",
      "1559 [D loss: 0.174088, acc.: 94.44%] [G loss: 5.561861]\n",
      "1560 [D loss: 0.391798, acc.: 77.78%] [G loss: 4.687287]\n",
      "1561 [D loss: 0.162230, acc.: 94.44%] [G loss: 5.557051]\n",
      "1562 [D loss: 0.361076, acc.: 77.78%] [G loss: 4.225183]\n",
      "1563 [D loss: 0.051091, acc.: 100.00%] [G loss: 3.357234]\n",
      "1564 [D loss: 0.573340, acc.: 77.78%] [G loss: 4.169060]\n",
      "1565 [D loss: 0.143584, acc.: 94.44%] [G loss: 7.404434]\n",
      "1566 [D loss: 0.141996, acc.: 88.89%] [G loss: 4.328362]\n",
      "1567 [D loss: 0.027340, acc.: 100.00%] [G loss: 4.881303]\n",
      "1568 [D loss: 0.069594, acc.: 100.00%] [G loss: 4.360956]\n",
      "1569 [D loss: 0.116030, acc.: 100.00%] [G loss: 4.011051]\n",
      "1570 [D loss: 0.269325, acc.: 88.89%] [G loss: 4.932696]\n",
      "1571 [D loss: 0.087647, acc.: 100.00%] [G loss: 4.778291]\n",
      "1572 [D loss: 0.056961, acc.: 100.00%] [G loss: 5.975184]\n",
      "1573 [D loss: 0.108975, acc.: 94.44%] [G loss: 5.871729]\n",
      "1574 [D loss: 0.020938, acc.: 100.00%] [G loss: 5.167446]\n",
      "1575 [D loss: 0.021310, acc.: 100.00%] [G loss: 6.329710]\n",
      "1576 [D loss: 0.196548, acc.: 94.44%] [G loss: 3.818357]\n",
      "1577 [D loss: 0.144672, acc.: 94.44%] [G loss: 5.655427]\n",
      "1578 [D loss: 0.240266, acc.: 88.89%] [G loss: 3.460299]\n",
      "1579 [D loss: 0.136418, acc.: 94.44%] [G loss: 3.955122]\n",
      "1580 [D loss: 0.202557, acc.: 94.44%] [G loss: 4.683491]\n",
      "1581 [D loss: 0.083776, acc.: 94.44%] [G loss: 4.539874]\n",
      "1582 [D loss: 0.131193, acc.: 94.44%] [G loss: 4.650105]\n",
      "1583 [D loss: 0.071714, acc.: 100.00%] [G loss: 5.058969]\n",
      "1584 [D loss: 0.119988, acc.: 100.00%] [G loss: 4.128002]\n",
      "1585 [D loss: 0.333250, acc.: 83.33%] [G loss: 2.365275]\n",
      "1586 [D loss: 0.272966, acc.: 88.89%] [G loss: 5.216575]\n",
      "1587 [D loss: 0.102923, acc.: 94.44%] [G loss: 5.054640]\n",
      "1588 [D loss: 0.220448, acc.: 88.89%] [G loss: 3.996882]\n",
      "1589 [D loss: 0.181573, acc.: 100.00%] [G loss: 4.440657]\n",
      "1590 [D loss: 0.169233, acc.: 94.44%] [G loss: 3.488909]\n",
      "1591 [D loss: 0.223581, acc.: 88.89%] [G loss: 4.776472]\n",
      "1592 [D loss: 0.753506, acc.: 72.22%] [G loss: 5.416134]\n",
      "1593 [D loss: 0.267030, acc.: 88.89%] [G loss: 5.669608]\n",
      "1594 [D loss: 0.479326, acc.: 83.33%] [G loss: 3.334680]\n",
      "1595 [D loss: 0.103192, acc.: 94.44%] [G loss: 4.996781]\n",
      "1596 [D loss: 0.394870, acc.: 83.33%] [G loss: 3.560779]\n",
      "1597 [D loss: 0.045626, acc.: 100.00%] [G loss: 6.083212]\n",
      "1598 [D loss: 0.102181, acc.: 100.00%] [G loss: 4.705454]\n",
      "1599 [D loss: 0.197376, acc.: 94.44%] [G loss: 3.348889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 [D loss: 0.064402, acc.: 100.00%] [G loss: 3.371189]\n",
      "1601 [D loss: 0.051194, acc.: 100.00%] [G loss: 5.116452]\n",
      "1602 [D loss: 0.133962, acc.: 94.44%] [G loss: 3.365166]\n",
      "1603 [D loss: 0.123181, acc.: 94.44%] [G loss: 3.944594]\n",
      "1604 [D loss: 0.135637, acc.: 100.00%] [G loss: 4.011644]\n",
      "1605 [D loss: 0.068987, acc.: 100.00%] [G loss: 4.761407]\n",
      "1606 [D loss: 0.133035, acc.: 94.44%] [G loss: 2.750260]\n",
      "1607 [D loss: 0.083387, acc.: 100.00%] [G loss: 4.931442]\n",
      "1608 [D loss: 0.124168, acc.: 94.44%] [G loss: 5.432798]\n",
      "1609 [D loss: 0.216803, acc.: 88.89%] [G loss: 7.038465]\n",
      "1610 [D loss: 0.226423, acc.: 88.89%] [G loss: 4.186529]\n",
      "1611 [D loss: 0.301482, acc.: 83.33%] [G loss: 3.098155]\n",
      "1612 [D loss: 0.235101, acc.: 83.33%] [G loss: 4.614759]\n",
      "1613 [D loss: 0.217197, acc.: 94.44%] [G loss: 5.319612]\n",
      "1614 [D loss: 0.158585, acc.: 94.44%] [G loss: 4.226538]\n",
      "1615 [D loss: 0.135326, acc.: 100.00%] [G loss: 4.606957]\n",
      "1616 [D loss: 0.036988, acc.: 100.00%] [G loss: 4.888142]\n",
      "1617 [D loss: 0.365996, acc.: 88.89%] [G loss: 3.816159]\n",
      "1618 [D loss: 0.074221, acc.: 100.00%] [G loss: 4.590372]\n",
      "1619 [D loss: 0.025971, acc.: 100.00%] [G loss: 5.268802]\n",
      "1620 [D loss: 0.094403, acc.: 100.00%] [G loss: 4.339883]\n",
      "1621 [D loss: 0.040719, acc.: 100.00%] [G loss: 5.164832]\n",
      "1622 [D loss: 0.124152, acc.: 100.00%] [G loss: 3.484585]\n",
      "1623 [D loss: 0.029703, acc.: 100.00%] [G loss: 4.116266]\n",
      "1624 [D loss: 0.051689, acc.: 100.00%] [G loss: 4.175084]\n",
      "1625 [D loss: 0.191039, acc.: 94.44%] [G loss: 4.316939]\n",
      "1626 [D loss: 0.079889, acc.: 100.00%] [G loss: 4.599023]\n",
      "1627 [D loss: 0.694164, acc.: 66.67%] [G loss: 2.209241]\n",
      "1628 [D loss: 0.747959, acc.: 72.22%] [G loss: 5.230543]\n",
      "1629 [D loss: 0.048943, acc.: 100.00%] [G loss: 5.518890]\n",
      "1630 [D loss: 0.177684, acc.: 88.89%] [G loss: 6.681910]\n",
      "1631 [D loss: 0.066474, acc.: 100.00%] [G loss: 3.790166]\n",
      "1632 [D loss: 0.047657, acc.: 100.00%] [G loss: 4.352584]\n",
      "1633 [D loss: 0.120649, acc.: 100.00%] [G loss: 4.497613]\n",
      "1634 [D loss: 0.123810, acc.: 100.00%] [G loss: 4.405553]\n",
      "1635 [D loss: 0.157096, acc.: 94.44%] [G loss: 3.328710]\n",
      "1636 [D loss: 0.115739, acc.: 94.44%] [G loss: 4.911227]\n",
      "1637 [D loss: 0.084222, acc.: 100.00%] [G loss: 3.403461]\n",
      "1638 [D loss: 0.155661, acc.: 100.00%] [G loss: 3.382968]\n",
      "1639 [D loss: 0.143214, acc.: 88.89%] [G loss: 6.032810]\n",
      "1640 [D loss: 0.225002, acc.: 88.89%] [G loss: 4.489600]\n",
      "1641 [D loss: 0.204874, acc.: 94.44%] [G loss: 3.813654]\n",
      "1642 [D loss: 0.356712, acc.: 77.78%] [G loss: 5.077675]\n",
      "1643 [D loss: 0.113253, acc.: 100.00%] [G loss: 5.121553]\n",
      "1644 [D loss: 0.253692, acc.: 88.89%] [G loss: 3.178624]\n",
      "1645 [D loss: 0.176532, acc.: 94.44%] [G loss: 3.474135]\n",
      "1646 [D loss: 0.293643, acc.: 83.33%] [G loss: 4.624438]\n",
      "1647 [D loss: 0.105832, acc.: 100.00%] [G loss: 4.762640]\n",
      "1648 [D loss: 0.197028, acc.: 83.33%] [G loss: 3.695266]\n",
      "1649 [D loss: 0.042992, acc.: 100.00%] [G loss: 4.614160]\n",
      "1650 [D loss: 0.137028, acc.: 100.00%] [G loss: 3.811794]\n",
      "1651 [D loss: 0.040865, acc.: 100.00%] [G loss: 4.953785]\n",
      "1652 [D loss: 0.049540, acc.: 100.00%] [G loss: 4.171221]\n",
      "1653 [D loss: 0.037423, acc.: 100.00%] [G loss: 5.011510]\n",
      "1654 [D loss: 0.172395, acc.: 100.00%] [G loss: 3.688503]\n",
      "1655 [D loss: 0.138713, acc.: 88.89%] [G loss: 5.172306]\n",
      "1656 [D loss: 0.170446, acc.: 94.44%] [G loss: 5.629194]\n",
      "1657 [D loss: 0.071909, acc.: 100.00%] [G loss: 6.193569]\n",
      "1658 [D loss: 0.230495, acc.: 88.89%] [G loss: 5.568014]\n",
      "1659 [D loss: 0.817790, acc.: 72.22%] [G loss: 2.214452]\n",
      "1660 [D loss: 0.255345, acc.: 94.44%] [G loss: 3.969172]\n",
      "1661 [D loss: 0.262293, acc.: 88.89%] [G loss: 3.920821]\n",
      "1662 [D loss: 0.245968, acc.: 88.89%] [G loss: 4.688455]\n",
      "1663 [D loss: 0.030215, acc.: 100.00%] [G loss: 4.937887]\n",
      "1664 [D loss: 0.061258, acc.: 100.00%] [G loss: 4.721287]\n",
      "1665 [D loss: 0.075108, acc.: 100.00%] [G loss: 5.105057]\n",
      "1666 [D loss: 0.061390, acc.: 100.00%] [G loss: 4.086168]\n",
      "1667 [D loss: 0.082614, acc.: 100.00%] [G loss: 4.344402]\n",
      "1668 [D loss: 0.340756, acc.: 88.89%] [G loss: 3.953314]\n",
      "1669 [D loss: 0.146245, acc.: 94.44%] [G loss: 3.532821]\n",
      "1670 [D loss: 0.088021, acc.: 100.00%] [G loss: 4.252665]\n",
      "1671 [D loss: 0.094800, acc.: 94.44%] [G loss: 3.694833]\n",
      "1672 [D loss: 0.114046, acc.: 100.00%] [G loss: 4.131589]\n",
      "1673 [D loss: 0.106881, acc.: 100.00%] [G loss: 4.004716]\n",
      "1674 [D loss: 0.125686, acc.: 100.00%] [G loss: 2.645652]\n",
      "1675 [D loss: 0.127094, acc.: 100.00%] [G loss: 3.078696]\n",
      "1676 [D loss: 0.198763, acc.: 88.89%] [G loss: 5.759745]\n",
      "1677 [D loss: 0.180553, acc.: 94.44%] [G loss: 4.675077]\n",
      "1678 [D loss: 0.275978, acc.: 83.33%] [G loss: 4.532477]\n",
      "1679 [D loss: 0.151191, acc.: 88.89%] [G loss: 4.558363]\n",
      "1680 [D loss: 0.080289, acc.: 100.00%] [G loss: 5.890852]\n",
      "1681 [D loss: 0.041827, acc.: 100.00%] [G loss: 5.173091]\n",
      "1682 [D loss: 0.536464, acc.: 83.33%] [G loss: 4.176905]\n",
      "1683 [D loss: 0.133799, acc.: 94.44%] [G loss: 4.138765]\n",
      "1684 [D loss: 0.228769, acc.: 94.44%] [G loss: 4.471764]\n",
      "1685 [D loss: 0.043786, acc.: 100.00%] [G loss: 6.242113]\n",
      "1686 [D loss: 0.077878, acc.: 100.00%] [G loss: 2.749644]\n",
      "1687 [D loss: 0.157099, acc.: 94.44%] [G loss: 5.123775]\n",
      "1688 [D loss: 0.141399, acc.: 94.44%] [G loss: 6.496804]\n",
      "1689 [D loss: 0.541378, acc.: 72.22%] [G loss: 3.861376]\n",
      "1690 [D loss: 0.066597, acc.: 100.00%] [G loss: 7.881501]\n",
      "1691 [D loss: 0.021208, acc.: 100.00%] [G loss: 5.361013]\n",
      "1692 [D loss: 0.054391, acc.: 100.00%] [G loss: 4.836913]\n",
      "1693 [D loss: 0.031602, acc.: 100.00%] [G loss: 3.910131]\n",
      "1694 [D loss: 0.049977, acc.: 100.00%] [G loss: 5.298368]\n",
      "1695 [D loss: 0.155869, acc.: 94.44%] [G loss: 3.693825]\n",
      "1696 [D loss: 0.329047, acc.: 83.33%] [G loss: 3.058684]\n",
      "1697 [D loss: 0.022129, acc.: 100.00%] [G loss: 12.723417]\n",
      "1698 [D loss: 0.343106, acc.: 83.33%] [G loss: 8.865405]\n",
      "1699 [D loss: 0.290641, acc.: 88.89%] [G loss: 5.969381]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 [D loss: 0.011600, acc.: 100.00%] [G loss: 11.358815]\n",
      "1701 [D loss: 0.029067, acc.: 100.00%] [G loss: 8.366506]\n",
      "1702 [D loss: 0.036241, acc.: 100.00%] [G loss: 6.239955]\n",
      "1703 [D loss: 0.055410, acc.: 100.00%] [G loss: 4.662549]\n",
      "1704 [D loss: 0.061744, acc.: 94.44%] [G loss: 5.568052]\n",
      "1705 [D loss: 0.050493, acc.: 100.00%] [G loss: 5.896834]\n",
      "1706 [D loss: 0.087826, acc.: 100.00%] [G loss: 5.467977]\n",
      "1707 [D loss: 0.017780, acc.: 100.00%] [G loss: 5.377062]\n",
      "1708 [D loss: 0.038724, acc.: 100.00%] [G loss: 4.769343]\n",
      "1709 [D loss: 0.015747, acc.: 100.00%] [G loss: 5.425634]\n",
      "1710 [D loss: 0.054926, acc.: 100.00%] [G loss: 3.691505]\n",
      "1711 [D loss: 0.022701, acc.: 100.00%] [G loss: 5.899806]\n",
      "1712 [D loss: 0.043108, acc.: 100.00%] [G loss: 3.757397]\n",
      "1713 [D loss: 0.034338, acc.: 100.00%] [G loss: 6.850864]\n",
      "1714 [D loss: 0.072140, acc.: 100.00%] [G loss: 5.988570]\n",
      "1715 [D loss: 0.191379, acc.: 94.44%] [G loss: 4.781188]\n",
      "1716 [D loss: 0.135036, acc.: 100.00%] [G loss: 3.901286]\n",
      "1717 [D loss: 0.156300, acc.: 94.44%] [G loss: 5.131842]\n",
      "1718 [D loss: 0.082335, acc.: 100.00%] [G loss: 5.725592]\n",
      "1719 [D loss: 0.050648, acc.: 100.00%] [G loss: 4.075972]\n",
      "1720 [D loss: 0.223952, acc.: 88.89%] [G loss: 4.474794]\n",
      "1721 [D loss: 0.076221, acc.: 100.00%] [G loss: 4.316133]\n",
      "1722 [D loss: 0.049630, acc.: 100.00%] [G loss: 3.836954]\n",
      "1723 [D loss: 0.089935, acc.: 100.00%] [G loss: 5.060952]\n",
      "1724 [D loss: 0.379038, acc.: 66.67%] [G loss: 3.278357]\n",
      "1725 [D loss: 0.034038, acc.: 100.00%] [G loss: 4.341402]\n",
      "1726 [D loss: 0.044268, acc.: 100.00%] [G loss: 4.718141]\n",
      "1727 [D loss: 0.121023, acc.: 88.89%] [G loss: 5.248270]\n",
      "1728 [D loss: 0.019350, acc.: 100.00%] [G loss: 4.510599]\n",
      "1729 [D loss: 0.358804, acc.: 72.22%] [G loss: 4.059422]\n",
      "1730 [D loss: 0.162166, acc.: 94.44%] [G loss: 5.093439]\n",
      "1731 [D loss: 0.132294, acc.: 94.44%] [G loss: 5.128875]\n",
      "1732 [D loss: 0.220239, acc.: 94.44%] [G loss: 3.998106]\n",
      "1733 [D loss: 0.060872, acc.: 100.00%] [G loss: 4.838156]\n",
      "1734 [D loss: 0.205162, acc.: 94.44%] [G loss: 3.777986]\n",
      "1735 [D loss: 0.141413, acc.: 94.44%] [G loss: 4.601927]\n",
      "1736 [D loss: 0.080852, acc.: 94.44%] [G loss: 4.343132]\n",
      "1737 [D loss: 0.176339, acc.: 100.00%] [G loss: 3.829483]\n",
      "1738 [D loss: 0.424503, acc.: 72.22%] [G loss: 5.272493]\n",
      "1739 [D loss: 0.192800, acc.: 94.44%] [G loss: 4.327988]\n",
      "1740 [D loss: 0.211868, acc.: 88.89%] [G loss: 5.297226]\n",
      "1741 [D loss: 0.481495, acc.: 83.33%] [G loss: 5.092721]\n",
      "1742 [D loss: 0.061104, acc.: 100.00%] [G loss: 4.380941]\n",
      "1743 [D loss: 0.041320, acc.: 100.00%] [G loss: 5.682956]\n",
      "1744 [D loss: 0.189172, acc.: 94.44%] [G loss: 4.312933]\n",
      "1745 [D loss: 0.045519, acc.: 100.00%] [G loss: 4.189228]\n",
      "1746 [D loss: 0.087647, acc.: 100.00%] [G loss: 3.550377]\n",
      "1747 [D loss: 0.200698, acc.: 94.44%] [G loss: 4.214619]\n",
      "1748 [D loss: 0.134626, acc.: 94.44%] [G loss: 4.254489]\n",
      "1749 [D loss: 0.034349, acc.: 100.00%] [G loss: 5.771589]\n",
      "1750 [D loss: 0.145299, acc.: 94.44%] [G loss: 3.398984]\n",
      "1751 [D loss: 0.142132, acc.: 94.44%] [G loss: 3.945900]\n",
      "1752 [D loss: 0.113534, acc.: 100.00%] [G loss: 4.371817]\n",
      "1753 [D loss: 0.120576, acc.: 94.44%] [G loss: 3.970140]\n",
      "1754 [D loss: 0.083124, acc.: 94.44%] [G loss: 4.027464]\n",
      "1755 [D loss: 0.067877, acc.: 100.00%] [G loss: 3.884171]\n",
      "1756 [D loss: 0.268558, acc.: 88.89%] [G loss: 3.894016]\n",
      "1757 [D loss: 0.195187, acc.: 88.89%] [G loss: 6.017024]\n",
      "1758 [D loss: 0.237622, acc.: 83.33%] [G loss: 3.227301]\n",
      "1759 [D loss: 0.132895, acc.: 94.44%] [G loss: 5.284681]\n",
      "1760 [D loss: 0.117780, acc.: 94.44%] [G loss: 5.769882]\n",
      "1761 [D loss: 0.117271, acc.: 100.00%] [G loss: 6.368316]\n",
      "1762 [D loss: 0.128014, acc.: 94.44%] [G loss: 4.335314]\n",
      "1763 [D loss: 0.150278, acc.: 88.89%] [G loss: 4.118558]\n",
      "1764 [D loss: 0.392839, acc.: 88.89%] [G loss: 4.622002]\n",
      "1765 [D loss: 0.100187, acc.: 100.00%] [G loss: 4.155317]\n",
      "1766 [D loss: 0.192398, acc.: 94.44%] [G loss: 4.327976]\n",
      "1767 [D loss: 0.262254, acc.: 83.33%] [G loss: 7.357003]\n",
      "1768 [D loss: 0.229801, acc.: 94.44%] [G loss: 4.115352]\n",
      "1769 [D loss: 0.319208, acc.: 83.33%] [G loss: 3.099559]\n",
      "1770 [D loss: 0.205532, acc.: 94.44%] [G loss: 4.799075]\n",
      "1771 [D loss: 0.293781, acc.: 94.44%] [G loss: 3.724884]\n",
      "1772 [D loss: 0.225456, acc.: 94.44%] [G loss: 3.366082]\n",
      "1773 [D loss: 0.185209, acc.: 88.89%] [G loss: 4.641376]\n",
      "1774 [D loss: 0.326721, acc.: 77.78%] [G loss: 3.652722]\n",
      "1775 [D loss: 0.687410, acc.: 61.11%] [G loss: 5.007202]\n",
      "1776 [D loss: 0.176975, acc.: 88.89%] [G loss: 6.256079]\n",
      "1777 [D loss: 0.472690, acc.: 83.33%] [G loss: 2.269710]\n",
      "1778 [D loss: 0.267124, acc.: 77.78%] [G loss: 4.418484]\n",
      "1779 [D loss: 0.101158, acc.: 94.44%] [G loss: 5.087513]\n",
      "1780 [D loss: 0.096612, acc.: 94.44%] [G loss: 4.163614]\n",
      "1781 [D loss: 0.426941, acc.: 83.33%] [G loss: 4.716984]\n",
      "1782 [D loss: 0.151923, acc.: 94.44%] [G loss: 4.917373]\n",
      "1783 [D loss: 0.050413, acc.: 100.00%] [G loss: 3.642300]\n",
      "1784 [D loss: 0.114953, acc.: 88.89%] [G loss: 5.025325]\n",
      "1785 [D loss: 0.083575, acc.: 94.44%] [G loss: 5.470305]\n",
      "1786 [D loss: 0.117537, acc.: 94.44%] [G loss: 4.818246]\n",
      "1787 [D loss: 0.138948, acc.: 94.44%] [G loss: 4.743347]\n",
      "1788 [D loss: 0.838523, acc.: 61.11%] [G loss: 3.541518]\n",
      "1789 [D loss: 0.326507, acc.: 88.89%] [G loss: 4.224691]\n",
      "1790 [D loss: 0.446065, acc.: 72.22%] [G loss: 4.900740]\n",
      "1791 [D loss: 0.411525, acc.: 77.78%] [G loss: 4.091859]\n",
      "1792 [D loss: 0.177456, acc.: 94.44%] [G loss: 3.958564]\n",
      "1793 [D loss: 0.164419, acc.: 88.89%] [G loss: 5.051218]\n",
      "1794 [D loss: 0.118338, acc.: 100.00%] [G loss: 4.636398]\n",
      "1795 [D loss: 0.078415, acc.: 100.00%] [G loss: 3.814205]\n",
      "1796 [D loss: 0.158577, acc.: 94.44%] [G loss: 5.834333]\n",
      "1797 [D loss: 0.024848, acc.: 100.00%] [G loss: 5.954268]\n",
      "1798 [D loss: 0.161421, acc.: 94.44%] [G loss: 4.685486]\n",
      "1799 [D loss: 0.173245, acc.: 88.89%] [G loss: 3.967521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 [D loss: 0.327986, acc.: 83.33%] [G loss: 5.241206]\n",
      "1801 [D loss: 0.058314, acc.: 100.00%] [G loss: 5.912024]\n",
      "1802 [D loss: 0.329465, acc.: 77.78%] [G loss: 4.286034]\n",
      "1803 [D loss: 0.331621, acc.: 77.78%] [G loss: 4.797560]\n",
      "1804 [D loss: 0.145068, acc.: 94.44%] [G loss: 4.879407]\n",
      "1805 [D loss: 0.126820, acc.: 94.44%] [G loss: 4.202691]\n",
      "1806 [D loss: 0.140041, acc.: 100.00%] [G loss: 3.781734]\n",
      "1807 [D loss: 0.072840, acc.: 100.00%] [G loss: 4.245709]\n",
      "1808 [D loss: 0.428043, acc.: 72.22%] [G loss: 4.780935]\n",
      "1809 [D loss: 0.400872, acc.: 83.33%] [G loss: 3.772995]\n",
      "1810 [D loss: 0.124719, acc.: 88.89%] [G loss: 5.637849]\n",
      "1811 [D loss: 0.028467, acc.: 100.00%] [G loss: 6.114218]\n",
      "1812 [D loss: 0.378133, acc.: 88.89%] [G loss: 2.820712]\n",
      "1813 [D loss: 0.315416, acc.: 83.33%] [G loss: 6.077487]\n",
      "1814 [D loss: 0.021254, acc.: 100.00%] [G loss: 6.861482]\n",
      "1815 [D loss: 0.121652, acc.: 88.89%] [G loss: 7.012539]\n",
      "1816 [D loss: 0.042017, acc.: 100.00%] [G loss: 4.369589]\n",
      "1817 [D loss: 0.124222, acc.: 94.44%] [G loss: 4.093006]\n",
      "1818 [D loss: 0.095274, acc.: 100.00%] [G loss: 3.831913]\n",
      "1819 [D loss: 0.048847, acc.: 100.00%] [G loss: 5.104228]\n",
      "1820 [D loss: 0.037501, acc.: 100.00%] [G loss: 5.074255]\n",
      "1821 [D loss: 0.109593, acc.: 94.44%] [G loss: 4.002176]\n",
      "1822 [D loss: 0.068624, acc.: 100.00%] [G loss: 4.397700]\n",
      "1823 [D loss: 0.062250, acc.: 100.00%] [G loss: 6.265543]\n",
      "1824 [D loss: 0.088988, acc.: 100.00%] [G loss: 6.474444]\n",
      "1825 [D loss: 0.028271, acc.: 100.00%] [G loss: 5.646918]\n",
      "1826 [D loss: 0.075253, acc.: 100.00%] [G loss: 5.731315]\n",
      "1827 [D loss: 0.156466, acc.: 94.44%] [G loss: 5.563047]\n",
      "1828 [D loss: 0.042118, acc.: 100.00%] [G loss: 4.367175]\n",
      "1829 [D loss: 0.048936, acc.: 100.00%] [G loss: 4.487125]\n",
      "1830 [D loss: 0.038978, acc.: 100.00%] [G loss: 5.104367]\n",
      "1831 [D loss: 0.049592, acc.: 100.00%] [G loss: 4.694540]\n",
      "1832 [D loss: 0.069184, acc.: 100.00%] [G loss: 5.072920]\n",
      "1833 [D loss: 0.098188, acc.: 94.44%] [G loss: 5.142743]\n",
      "1834 [D loss: 0.238607, acc.: 88.89%] [G loss: 4.127028]\n",
      "1835 [D loss: 0.170031, acc.: 94.44%] [G loss: 3.918413]\n",
      "1836 [D loss: 0.076381, acc.: 100.00%] [G loss: 5.432040]\n",
      "1837 [D loss: 0.017390, acc.: 100.00%] [G loss: 5.120241]\n",
      "1838 [D loss: 0.059285, acc.: 100.00%] [G loss: 4.873218]\n",
      "1839 [D loss: 0.326530, acc.: 83.33%] [G loss: 4.236624]\n",
      "1840 [D loss: 0.034555, acc.: 100.00%] [G loss: 4.997240]\n",
      "1841 [D loss: 0.462045, acc.: 77.78%] [G loss: 4.139474]\n",
      "1842 [D loss: 0.397298, acc.: 83.33%] [G loss: 6.271330]\n",
      "1843 [D loss: 0.194567, acc.: 88.89%] [G loss: 4.007784]\n",
      "1844 [D loss: 0.230677, acc.: 88.89%] [G loss: 4.959182]\n",
      "1845 [D loss: 0.192846, acc.: 94.44%] [G loss: 3.987265]\n",
      "1846 [D loss: 0.416337, acc.: 72.22%] [G loss: 3.622391]\n",
      "1847 [D loss: 0.290654, acc.: 88.89%] [G loss: 3.208263]\n",
      "1848 [D loss: 0.099448, acc.: 100.00%] [G loss: 4.824769]\n",
      "1849 [D loss: 0.037980, acc.: 100.00%] [G loss: 9.658950]\n",
      "1850 [D loss: 0.223592, acc.: 88.89%] [G loss: 5.799817]\n",
      "1851 [D loss: 0.185537, acc.: 94.44%] [G loss: 5.801693]\n",
      "1852 [D loss: 0.159654, acc.: 94.44%] [G loss: 4.226117]\n",
      "1853 [D loss: 0.128623, acc.: 100.00%] [G loss: 3.669310]\n",
      "1854 [D loss: 0.153379, acc.: 94.44%] [G loss: 3.815888]\n",
      "1855 [D loss: 0.078035, acc.: 94.44%] [G loss: 4.677284]\n",
      "1856 [D loss: 0.054506, acc.: 100.00%] [G loss: 5.041234]\n",
      "1857 [D loss: 0.018064, acc.: 100.00%] [G loss: 5.654881]\n",
      "1858 [D loss: 0.058417, acc.: 100.00%] [G loss: 5.254832]\n",
      "1859 [D loss: 0.048814, acc.: 100.00%] [G loss: 5.683599]\n",
      "1860 [D loss: 0.112604, acc.: 94.44%] [G loss: 3.478541]\n",
      "1861 [D loss: 0.048729, acc.: 100.00%] [G loss: 4.746929]\n",
      "1862 [D loss: 0.057900, acc.: 100.00%] [G loss: 5.098634]\n",
      "1863 [D loss: 0.212229, acc.: 88.89%] [G loss: 6.469084]\n",
      "1864 [D loss: 0.335688, acc.: 88.89%] [G loss: 6.204375]\n",
      "1865 [D loss: 0.106475, acc.: 100.00%] [G loss: 6.369467]\n",
      "1866 [D loss: 0.083147, acc.: 100.00%] [G loss: 4.255579]\n",
      "1867 [D loss: 0.197085, acc.: 88.89%] [G loss: 4.658047]\n",
      "1868 [D loss: 0.087896, acc.: 100.00%] [G loss: 5.750151]\n",
      "1869 [D loss: 0.187713, acc.: 94.44%] [G loss: 4.745431]\n",
      "1870 [D loss: 0.129600, acc.: 94.44%] [G loss: 3.417823]\n",
      "1871 [D loss: 0.147496, acc.: 94.44%] [G loss: 4.135240]\n",
      "1872 [D loss: 0.093590, acc.: 100.00%] [G loss: 3.308324]\n",
      "1873 [D loss: 0.169601, acc.: 94.44%] [G loss: 5.314041]\n",
      "1874 [D loss: 0.209494, acc.: 88.89%] [G loss: 3.897089]\n",
      "1875 [D loss: 0.415681, acc.: 72.22%] [G loss: 4.140031]\n",
      "1876 [D loss: 0.008560, acc.: 100.00%] [G loss: 5.936872]\n",
      "1877 [D loss: 0.218782, acc.: 88.89%] [G loss: 5.134480]\n",
      "1878 [D loss: 0.147851, acc.: 100.00%] [G loss: 4.542160]\n",
      "1879 [D loss: 0.357112, acc.: 77.78%] [G loss: 4.601310]\n",
      "1880 [D loss: 0.104255, acc.: 100.00%] [G loss: 4.913962]\n",
      "1881 [D loss: 0.340420, acc.: 88.89%] [G loss: 4.689424]\n",
      "1882 [D loss: 0.259440, acc.: 88.89%] [G loss: 5.066929]\n",
      "1883 [D loss: 0.077467, acc.: 94.44%] [G loss: 5.549517]\n",
      "1884 [D loss: 0.410285, acc.: 72.22%] [G loss: 3.296166]\n",
      "1885 [D loss: 0.143915, acc.: 88.89%] [G loss: 4.271514]\n",
      "1886 [D loss: 0.137827, acc.: 94.44%] [G loss: 6.113544]\n",
      "1887 [D loss: 0.176769, acc.: 88.89%] [G loss: 4.456086]\n",
      "1888 [D loss: 0.139890, acc.: 100.00%] [G loss: 4.713110]\n",
      "1889 [D loss: 0.133621, acc.: 100.00%] [G loss: 4.497605]\n",
      "1890 [D loss: 0.057500, acc.: 100.00%] [G loss: 7.444775]\n",
      "1891 [D loss: 0.132150, acc.: 94.44%] [G loss: 5.450186]\n",
      "1892 [D loss: 0.218310, acc.: 88.89%] [G loss: 4.340260]\n",
      "1893 [D loss: 0.093400, acc.: 100.00%] [G loss: 6.934496]\n",
      "1894 [D loss: 0.047708, acc.: 100.00%] [G loss: 5.804881]\n",
      "1895 [D loss: 0.149366, acc.: 94.44%] [G loss: 4.296139]\n",
      "1896 [D loss: 0.159859, acc.: 83.33%] [G loss: 5.474597]\n",
      "1897 [D loss: 0.041756, acc.: 100.00%] [G loss: 5.212597]\n",
      "1898 [D loss: 0.096063, acc.: 94.44%] [G loss: 4.288659]\n",
      "1899 [D loss: 0.020550, acc.: 100.00%] [G loss: 4.942342]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 [D loss: 0.464460, acc.: 83.33%] [G loss: 4.129149]\n",
      "1901 [D loss: 0.053319, acc.: 100.00%] [G loss: 4.849894]\n",
      "1902 [D loss: 0.015097, acc.: 100.00%] [G loss: 6.240722]\n",
      "1903 [D loss: 0.127792, acc.: 100.00%] [G loss: 4.100309]\n",
      "1904 [D loss: 0.144995, acc.: 100.00%] [G loss: 4.657164]\n",
      "1905 [D loss: 0.147333, acc.: 94.44%] [G loss: 3.382421]\n",
      "1906 [D loss: 0.294288, acc.: 88.89%] [G loss: 5.519886]\n",
      "1907 [D loss: 0.101396, acc.: 100.00%] [G loss: 5.187476]\n",
      "1908 [D loss: 0.127107, acc.: 100.00%] [G loss: 5.238614]\n",
      "1909 [D loss: 0.119934, acc.: 94.44%] [G loss: 4.382220]\n",
      "1910 [D loss: 0.075732, acc.: 100.00%] [G loss: 4.122726]\n",
      "1911 [D loss: 0.025168, acc.: 100.00%] [G loss: 5.283263]\n",
      "1912 [D loss: 0.067833, acc.: 100.00%] [G loss: 2.928054]\n",
      "1913 [D loss: 0.105740, acc.: 100.00%] [G loss: 3.184575]\n",
      "1914 [D loss: 0.083283, acc.: 100.00%] [G loss: 4.918610]\n",
      "1915 [D loss: 0.087476, acc.: 100.00%] [G loss: 4.221887]\n",
      "1916 [D loss: 0.095462, acc.: 94.44%] [G loss: 5.739021]\n",
      "1917 [D loss: 0.041903, acc.: 100.00%] [G loss: 5.074141]\n",
      "1918 [D loss: 0.086196, acc.: 100.00%] [G loss: 4.253499]\n",
      "1919 [D loss: 0.194411, acc.: 94.44%] [G loss: 4.096217]\n",
      "1920 [D loss: 0.365659, acc.: 88.89%] [G loss: 4.190138]\n",
      "1921 [D loss: 0.228621, acc.: 94.44%] [G loss: 3.838831]\n",
      "1922 [D loss: 0.192707, acc.: 94.44%] [G loss: 4.776190]\n",
      "1923 [D loss: 0.030620, acc.: 100.00%] [G loss: 5.455562]\n",
      "1924 [D loss: 0.058498, acc.: 100.00%] [G loss: 6.463953]\n",
      "1925 [D loss: 0.097322, acc.: 94.44%] [G loss: 5.441488]\n",
      "1926 [D loss: 0.053557, acc.: 100.00%] [G loss: 5.782096]\n",
      "1927 [D loss: 0.206510, acc.: 83.33%] [G loss: 4.840915]\n",
      "1928 [D loss: 0.231991, acc.: 88.89%] [G loss: 3.885114]\n",
      "1929 [D loss: 0.146529, acc.: 88.89%] [G loss: 5.280172]\n",
      "1930 [D loss: 0.167215, acc.: 94.44%] [G loss: 4.704689]\n",
      "1931 [D loss: 0.140448, acc.: 94.44%] [G loss: 4.478312]\n",
      "1932 [D loss: 0.018984, acc.: 100.00%] [G loss: 5.794020]\n",
      "1933 [D loss: 0.065814, acc.: 100.00%] [G loss: 5.687236]\n",
      "1934 [D loss: 0.059706, acc.: 100.00%] [G loss: 3.768586]\n",
      "1935 [D loss: 0.029553, acc.: 100.00%] [G loss: 6.117712]\n",
      "1936 [D loss: 0.077196, acc.: 94.44%] [G loss: 4.542955]\n",
      "1937 [D loss: 0.024790, acc.: 100.00%] [G loss: 5.460413]\n",
      "1938 [D loss: 0.087644, acc.: 100.00%] [G loss: 4.249001]\n",
      "1939 [D loss: 0.058801, acc.: 100.00%] [G loss: 5.302028]\n",
      "1940 [D loss: 0.101832, acc.: 100.00%] [G loss: 4.983781]\n",
      "1941 [D loss: 0.161125, acc.: 94.44%] [G loss: 3.016986]\n",
      "1942 [D loss: 0.388446, acc.: 77.78%] [G loss: 4.020330]\n",
      "1943 [D loss: 0.067306, acc.: 100.00%] [G loss: 5.608591]\n",
      "1944 [D loss: 0.326963, acc.: 88.89%] [G loss: 3.443116]\n",
      "1945 [D loss: 0.195242, acc.: 94.44%] [G loss: 3.879122]\n",
      "1946 [D loss: 0.219398, acc.: 88.89%] [G loss: 4.485894]\n",
      "1947 [D loss: 0.267770, acc.: 83.33%] [G loss: 6.571665]\n",
      "1948 [D loss: 0.094486, acc.: 100.00%] [G loss: 5.675192]\n",
      "1949 [D loss: 0.433336, acc.: 77.78%] [G loss: 4.071532]\n",
      "1950 [D loss: 0.151730, acc.: 94.44%] [G loss: 3.991882]\n",
      "1951 [D loss: 0.020171, acc.: 100.00%] [G loss: 6.605239]\n",
      "1952 [D loss: 0.062019, acc.: 100.00%] [G loss: 3.119203]\n",
      "1953 [D loss: 0.033657, acc.: 100.00%] [G loss: 4.696502]\n",
      "1954 [D loss: 0.054649, acc.: 100.00%] [G loss: 4.101438]\n",
      "1955 [D loss: 0.090501, acc.: 94.44%] [G loss: 5.733799]\n",
      "1956 [D loss: 0.125728, acc.: 94.44%] [G loss: 3.861982]\n",
      "1957 [D loss: 0.020450, acc.: 100.00%] [G loss: 5.612926]\n",
      "1958 [D loss: 0.069342, acc.: 100.00%] [G loss: 6.501475]\n",
      "1959 [D loss: 0.122676, acc.: 100.00%] [G loss: 4.357388]\n",
      "1960 [D loss: 0.013589, acc.: 100.00%] [G loss: 9.817992]\n",
      "1961 [D loss: 0.072840, acc.: 100.00%] [G loss: 5.818475]\n",
      "1962 [D loss: 0.033138, acc.: 100.00%] [G loss: 4.876287]\n",
      "1963 [D loss: 0.250609, acc.: 88.89%] [G loss: 3.940705]\n",
      "1964 [D loss: 0.061699, acc.: 100.00%] [G loss: 5.635808]\n",
      "1965 [D loss: 0.053831, acc.: 100.00%] [G loss: 5.936068]\n",
      "1966 [D loss: 0.345676, acc.: 83.33%] [G loss: 3.520418]\n",
      "1967 [D loss: 0.203556, acc.: 83.33%] [G loss: 4.984303]\n",
      "1968 [D loss: 0.198385, acc.: 88.89%] [G loss: 3.362585]\n",
      "1969 [D loss: 0.081216, acc.: 100.00%] [G loss: 4.673934]\n",
      "1970 [D loss: 0.076406, acc.: 100.00%] [G loss: 3.426764]\n",
      "1971 [D loss: 0.043237, acc.: 100.00%] [G loss: 5.226360]\n",
      "1972 [D loss: 0.324118, acc.: 88.89%] [G loss: 4.550899]\n",
      "1973 [D loss: 0.068328, acc.: 100.00%] [G loss: 5.500660]\n",
      "1974 [D loss: 0.104057, acc.: 94.44%] [G loss: 6.058792]\n",
      "1975 [D loss: 0.460619, acc.: 88.89%] [G loss: 4.169508]\n",
      "1976 [D loss: 0.290455, acc.: 88.89%] [G loss: 3.570525]\n",
      "1977 [D loss: 0.174320, acc.: 94.44%] [G loss: 4.452501]\n",
      "1978 [D loss: 0.250855, acc.: 94.44%] [G loss: 3.996724]\n",
      "1979 [D loss: 0.114433, acc.: 94.44%] [G loss: 3.819128]\n",
      "1980 [D loss: 0.077164, acc.: 94.44%] [G loss: 5.181323]\n",
      "1981 [D loss: 0.030296, acc.: 100.00%] [G loss: 5.752864]\n",
      "1982 [D loss: 0.269353, acc.: 83.33%] [G loss: 4.773566]\n",
      "1983 [D loss: 0.232091, acc.: 88.89%] [G loss: 5.549587]\n",
      "1984 [D loss: 0.124814, acc.: 100.00%] [G loss: 6.836362]\n",
      "1985 [D loss: 0.534066, acc.: 77.78%] [G loss: 4.474805]\n",
      "1986 [D loss: 0.242059, acc.: 88.89%] [G loss: 3.361455]\n",
      "1987 [D loss: 0.086888, acc.: 100.00%] [G loss: 5.746626]\n",
      "1988 [D loss: 0.055165, acc.: 100.00%] [G loss: 4.600178]\n",
      "1989 [D loss: 0.064683, acc.: 100.00%] [G loss: 5.250017]\n",
      "1990 [D loss: 0.097704, acc.: 100.00%] [G loss: 4.276163]\n",
      "1991 [D loss: 0.187378, acc.: 94.44%] [G loss: 4.388390]\n",
      "1992 [D loss: 0.242450, acc.: 83.33%] [G loss: 6.633673]\n",
      "1993 [D loss: 0.032782, acc.: 100.00%] [G loss: 6.039742]\n",
      "1994 [D loss: 0.331914, acc.: 83.33%] [G loss: 4.832438]\n",
      "1995 [D loss: 0.034759, acc.: 100.00%] [G loss: 4.389035]\n",
      "1996 [D loss: 0.047284, acc.: 100.00%] [G loss: 4.703965]\n",
      "1997 [D loss: 0.267215, acc.: 88.89%] [G loss: 5.217451]\n",
      "1998 [D loss: 0.155631, acc.: 88.89%] [G loss: 5.781254]\n",
      "1999 [D loss: 0.282598, acc.: 88.89%] [G loss: 3.592482]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 [D loss: 0.104234, acc.: 100.00%] [G loss: 4.899949]\n",
      "2001 [D loss: 0.663358, acc.: 72.22%] [G loss: 2.546225]\n",
      "2002 [D loss: 0.409375, acc.: 77.78%] [G loss: 4.848515]\n",
      "2003 [D loss: 0.040971, acc.: 100.00%] [G loss: 7.913608]\n",
      "2004 [D loss: 0.849159, acc.: 66.67%] [G loss: 2.315641]\n",
      "2005 [D loss: 0.038528, acc.: 100.00%] [G loss: 4.563128]\n",
      "2006 [D loss: 0.202637, acc.: 88.89%] [G loss: 4.325750]\n",
      "2007 [D loss: 0.128940, acc.: 94.44%] [G loss: 4.978884]\n",
      "2008 [D loss: 0.095477, acc.: 94.44%] [G loss: 6.610780]\n",
      "2009 [D loss: 0.054751, acc.: 100.00%] [G loss: 4.751818]\n",
      "2010 [D loss: 0.125885, acc.: 88.89%] [G loss: 4.160649]\n",
      "2011 [D loss: 0.042698, acc.: 100.00%] [G loss: 5.698212]\n",
      "2012 [D loss: 0.034416, acc.: 100.00%] [G loss: 5.649685]\n",
      "2013 [D loss: 0.062757, acc.: 100.00%] [G loss: 3.128489]\n",
      "2014 [D loss: 0.105171, acc.: 100.00%] [G loss: 3.815269]\n",
      "2015 [D loss: 0.101409, acc.: 94.44%] [G loss: 3.790495]\n",
      "2016 [D loss: 0.147284, acc.: 100.00%] [G loss: 3.918965]\n",
      "2017 [D loss: 0.027472, acc.: 100.00%] [G loss: 5.331564]\n",
      "2018 [D loss: 0.215320, acc.: 83.33%] [G loss: 3.227166]\n",
      "2019 [D loss: 0.212264, acc.: 94.44%] [G loss: 4.838532]\n",
      "2020 [D loss: 0.075420, acc.: 100.00%] [G loss: 5.555635]\n",
      "2021 [D loss: 0.031558, acc.: 100.00%] [G loss: 6.130097]\n",
      "2022 [D loss: 0.119883, acc.: 100.00%] [G loss: 4.965769]\n",
      "2023 [D loss: 0.163772, acc.: 94.44%] [G loss: 3.840085]\n",
      "2024 [D loss: 0.313647, acc.: 94.44%] [G loss: 3.926899]\n",
      "2025 [D loss: 0.162243, acc.: 88.89%] [G loss: 4.488396]\n",
      "2026 [D loss: 0.490182, acc.: 77.78%] [G loss: 5.469922]\n",
      "2027 [D loss: 0.066240, acc.: 100.00%] [G loss: 4.911111]\n",
      "2028 [D loss: 0.184869, acc.: 88.89%] [G loss: 6.355815]\n",
      "2029 [D loss: 0.082346, acc.: 94.44%] [G loss: 6.462503]\n",
      "2030 [D loss: 0.034429, acc.: 100.00%] [G loss: 4.529603]\n",
      "2031 [D loss: 0.173021, acc.: 94.44%] [G loss: 4.774630]\n",
      "2032 [D loss: 0.422849, acc.: 77.78%] [G loss: 5.513244]\n",
      "2033 [D loss: 0.114377, acc.: 94.44%] [G loss: 5.455371]\n",
      "2034 [D loss: 0.123635, acc.: 94.44%] [G loss: 5.008454]\n",
      "2035 [D loss: 0.169119, acc.: 94.44%] [G loss: 3.921814]\n",
      "2036 [D loss: 0.072684, acc.: 100.00%] [G loss: 4.222243]\n",
      "2037 [D loss: 0.078322, acc.: 100.00%] [G loss: 4.910887]\n",
      "2038 [D loss: 0.144596, acc.: 94.44%] [G loss: 4.302946]\n",
      "2039 [D loss: 0.038930, acc.: 100.00%] [G loss: 3.986440]\n",
      "2040 [D loss: 0.192934, acc.: 88.89%] [G loss: 5.367628]\n",
      "2041 [D loss: 0.029135, acc.: 100.00%] [G loss: 5.206405]\n",
      "2042 [D loss: 0.180660, acc.: 100.00%] [G loss: 5.007954]\n",
      "2043 [D loss: 0.155896, acc.: 88.89%] [G loss: 5.258460]\n",
      "2044 [D loss: 0.110673, acc.: 94.44%] [G loss: 4.082281]\n",
      "2045 [D loss: 0.151417, acc.: 94.44%] [G loss: 4.694474]\n",
      "2046 [D loss: 0.153544, acc.: 94.44%] [G loss: 4.819980]\n",
      "2047 [D loss: 0.258736, acc.: 88.89%] [G loss: 3.852141]\n",
      "2048 [D loss: 0.135271, acc.: 94.44%] [G loss: 5.548394]\n",
      "2049 [D loss: 0.116060, acc.: 100.00%] [G loss: 6.905436]\n",
      "2050 [D loss: 0.271713, acc.: 88.89%] [G loss: 3.884991]\n",
      "2051 [D loss: 0.096945, acc.: 94.44%] [G loss: 4.180403]\n",
      "2052 [D loss: 0.038370, acc.: 100.00%] [G loss: 6.253210]\n",
      "2053 [D loss: 0.142736, acc.: 94.44%] [G loss: 4.429109]\n",
      "2054 [D loss: 0.055578, acc.: 100.00%] [G loss: 5.110468]\n",
      "2055 [D loss: 0.007757, acc.: 100.00%] [G loss: 5.603699]\n",
      "2056 [D loss: 0.096862, acc.: 100.00%] [G loss: 4.879379]\n",
      "2057 [D loss: 0.030789, acc.: 100.00%] [G loss: 4.936181]\n",
      "2058 [D loss: 0.166191, acc.: 94.44%] [G loss: 4.601713]\n",
      "2059 [D loss: 0.192255, acc.: 88.89%] [G loss: 4.757756]\n",
      "2060 [D loss: 0.193263, acc.: 94.44%] [G loss: 4.269117]\n",
      "2061 [D loss: 0.796331, acc.: 72.22%] [G loss: 2.261895]\n",
      "2062 [D loss: 0.157962, acc.: 88.89%] [G loss: 4.041089]\n",
      "2063 [D loss: 0.100825, acc.: 100.00%] [G loss: 4.250937]\n",
      "2064 [D loss: 0.088550, acc.: 100.00%] [G loss: 4.405659]\n",
      "2065 [D loss: 0.152249, acc.: 94.44%] [G loss: 4.647907]\n",
      "2066 [D loss: 0.654681, acc.: 72.22%] [G loss: 4.241135]\n",
      "2067 [D loss: 0.134784, acc.: 94.44%] [G loss: 4.929777]\n",
      "2068 [D loss: 0.065892, acc.: 100.00%] [G loss: 5.940382]\n",
      "2069 [D loss: 0.124334, acc.: 94.44%] [G loss: 4.355563]\n",
      "2070 [D loss: 0.328672, acc.: 88.89%] [G loss: 4.813265]\n",
      "2071 [D loss: 0.282304, acc.: 83.33%] [G loss: 4.729909]\n",
      "2072 [D loss: 0.077933, acc.: 100.00%] [G loss: 3.878354]\n",
      "2073 [D loss: 0.102784, acc.: 94.44%] [G loss: 4.882639]\n",
      "2074 [D loss: 0.134101, acc.: 88.89%] [G loss: 6.779116]\n",
      "2075 [D loss: 0.169407, acc.: 83.33%] [G loss: 2.906845]\n",
      "2076 [D loss: 0.087271, acc.: 100.00%] [G loss: 3.953614]\n",
      "2077 [D loss: 0.039851, acc.: 100.00%] [G loss: 5.860670]\n",
      "2078 [D loss: 0.029578, acc.: 100.00%] [G loss: 6.806327]\n",
      "2079 [D loss: 0.104960, acc.: 94.44%] [G loss: 3.677586]\n",
      "2080 [D loss: 0.097297, acc.: 94.44%] [G loss: 5.080667]\n",
      "2081 [D loss: 0.461203, acc.: 88.89%] [G loss: 6.819820]\n",
      "2082 [D loss: 0.137712, acc.: 94.44%] [G loss: 5.332036]\n",
      "2083 [D loss: 0.147808, acc.: 94.44%] [G loss: 4.840055]\n",
      "2084 [D loss: 0.039828, acc.: 100.00%] [G loss: 5.224201]\n",
      "2085 [D loss: 0.106415, acc.: 94.44%] [G loss: 3.502957]\n",
      "2086 [D loss: 0.029474, acc.: 100.00%] [G loss: 6.404747]\n",
      "2087 [D loss: 0.133640, acc.: 88.89%] [G loss: 5.810387]\n",
      "2088 [D loss: 0.174199, acc.: 88.89%] [G loss: 5.426142]\n",
      "2089 [D loss: 0.015420, acc.: 100.00%] [G loss: 6.266385]\n",
      "2090 [D loss: 0.063960, acc.: 100.00%] [G loss: 5.047027]\n",
      "2091 [D loss: 0.193010, acc.: 88.89%] [G loss: 6.132068]\n",
      "2092 [D loss: 0.141387, acc.: 88.89%] [G loss: 7.282485]\n",
      "2093 [D loss: 0.625445, acc.: 72.22%] [G loss: 2.958970]\n",
      "2094 [D loss: 0.082582, acc.: 94.44%] [G loss: 6.225090]\n",
      "2095 [D loss: 0.059625, acc.: 100.00%] [G loss: 5.170308]\n",
      "2096 [D loss: 0.333218, acc.: 77.78%] [G loss: 4.192091]\n",
      "2097 [D loss: 0.221238, acc.: 94.44%] [G loss: 5.487837]\n",
      "2098 [D loss: 0.200378, acc.: 88.89%] [G loss: 5.145880]\n",
      "2099 [D loss: 0.420634, acc.: 94.44%] [G loss: 4.572341]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 [D loss: 0.081942, acc.: 100.00%] [G loss: 5.122931]\n",
      "2101 [D loss: 0.037053, acc.: 100.00%] [G loss: 5.184978]\n",
      "2102 [D loss: 0.047962, acc.: 100.00%] [G loss: 6.170735]\n",
      "2103 [D loss: 0.167275, acc.: 88.89%] [G loss: 5.072847]\n",
      "2104 [D loss: 0.073996, acc.: 100.00%] [G loss: 5.107903]\n",
      "2105 [D loss: 0.282333, acc.: 83.33%] [G loss: 3.758053]\n",
      "2106 [D loss: 0.147844, acc.: 94.44%] [G loss: 3.964417]\n",
      "2107 [D loss: 0.116074, acc.: 94.44%] [G loss: 4.878340]\n",
      "2108 [D loss: 0.044061, acc.: 100.00%] [G loss: 3.649820]\n",
      "2109 [D loss: 0.034722, acc.: 100.00%] [G loss: 4.175872]\n",
      "2110 [D loss: 0.117691, acc.: 100.00%] [G loss: 3.682309]\n",
      "2111 [D loss: 0.087797, acc.: 100.00%] [G loss: 4.835926]\n",
      "2112 [D loss: 0.035362, acc.: 100.00%] [G loss: 6.144521]\n",
      "2113 [D loss: 0.048312, acc.: 100.00%] [G loss: 4.276576]\n",
      "2114 [D loss: 0.025960, acc.: 100.00%] [G loss: 5.842848]\n",
      "2115 [D loss: 0.045142, acc.: 100.00%] [G loss: 5.182306]\n",
      "2116 [D loss: 0.090044, acc.: 94.44%] [G loss: 4.947395]\n",
      "2117 [D loss: 0.196698, acc.: 94.44%] [G loss: 4.401324]\n",
      "2118 [D loss: 0.238268, acc.: 88.89%] [G loss: 3.522125]\n",
      "2119 [D loss: 0.029369, acc.: 100.00%] [G loss: 4.095091]\n",
      "2120 [D loss: 0.041712, acc.: 100.00%] [G loss: 4.896801]\n",
      "2121 [D loss: 0.057451, acc.: 100.00%] [G loss: 6.470511]\n",
      "2122 [D loss: 0.066068, acc.: 100.00%] [G loss: 4.578459]\n",
      "2123 [D loss: 0.239097, acc.: 88.89%] [G loss: 4.906549]\n",
      "2124 [D loss: 0.271039, acc.: 88.89%] [G loss: 4.360109]\n",
      "2125 [D loss: 0.089206, acc.: 94.44%] [G loss: 5.660739]\n",
      "2126 [D loss: 0.433254, acc.: 83.33%] [G loss: 4.194438]\n",
      "2127 [D loss: 0.383912, acc.: 88.89%] [G loss: 4.875232]\n",
      "2128 [D loss: 0.074754, acc.: 100.00%] [G loss: 5.298061]\n",
      "2129 [D loss: 0.100530, acc.: 94.44%] [G loss: 4.635978]\n",
      "2130 [D loss: 0.182074, acc.: 94.44%] [G loss: 4.236647]\n",
      "2131 [D loss: 0.094881, acc.: 100.00%] [G loss: 4.270056]\n",
      "2132 [D loss: 0.029700, acc.: 100.00%] [G loss: 4.412250]\n",
      "2133 [D loss: 0.073972, acc.: 100.00%] [G loss: 3.438739]\n",
      "2134 [D loss: 0.257834, acc.: 88.89%] [G loss: 4.041895]\n",
      "2135 [D loss: 0.135572, acc.: 88.89%] [G loss: 5.326984]\n",
      "2136 [D loss: 0.144304, acc.: 94.44%] [G loss: 5.358848]\n",
      "2137 [D loss: 0.143085, acc.: 94.44%] [G loss: 4.367778]\n",
      "2138 [D loss: 0.235061, acc.: 88.89%] [G loss: 4.457216]\n",
      "2139 [D loss: 0.069303, acc.: 94.44%] [G loss: 4.912689]\n",
      "2140 [D loss: 0.175343, acc.: 94.44%] [G loss: 5.474414]\n",
      "2141 [D loss: 0.196199, acc.: 94.44%] [G loss: 5.746718]\n",
      "2142 [D loss: 0.329706, acc.: 83.33%] [G loss: 2.030646]\n",
      "2143 [D loss: 0.354592, acc.: 83.33%] [G loss: 3.869927]\n",
      "2144 [D loss: 0.293512, acc.: 83.33%] [G loss: 4.989755]\n",
      "2145 [D loss: 0.486431, acc.: 72.22%] [G loss: 3.356558]\n",
      "2146 [D loss: 0.142279, acc.: 88.89%] [G loss: 3.807666]\n",
      "2147 [D loss: 0.142718, acc.: 94.44%] [G loss: 4.886468]\n",
      "2148 [D loss: 0.222886, acc.: 83.33%] [G loss: 4.556773]\n",
      "2149 [D loss: 0.027343, acc.: 100.00%] [G loss: 5.595206]\n",
      "2150 [D loss: 0.019129, acc.: 100.00%] [G loss: 5.329073]\n",
      "2151 [D loss: 0.081994, acc.: 100.00%] [G loss: 5.732791]\n",
      "2152 [D loss: 0.184728, acc.: 88.89%] [G loss: 5.311131]\n",
      "2153 [D loss: 0.218358, acc.: 88.89%] [G loss: 3.791383]\n",
      "2154 [D loss: 0.046525, acc.: 100.00%] [G loss: 3.094401]\n",
      "2155 [D loss: 0.087969, acc.: 94.44%] [G loss: 3.512407]\n",
      "2156 [D loss: 0.060948, acc.: 100.00%] [G loss: 3.303864]\n",
      "2157 [D loss: 0.155240, acc.: 88.89%] [G loss: 6.821595]\n",
      "2158 [D loss: 0.113223, acc.: 100.00%] [G loss: 4.651738]\n",
      "2159 [D loss: 0.043832, acc.: 100.00%] [G loss: 5.406524]\n",
      "2160 [D loss: 0.046772, acc.: 100.00%] [G loss: 4.687387]\n",
      "2161 [D loss: 0.541111, acc.: 77.78%] [G loss: 4.332586]\n",
      "2162 [D loss: 0.283879, acc.: 88.89%] [G loss: 4.061248]\n",
      "2163 [D loss: 0.314916, acc.: 83.33%] [G loss: 3.919934]\n",
      "2164 [D loss: 0.030708, acc.: 100.00%] [G loss: 6.755750]\n",
      "2165 [D loss: 0.073832, acc.: 100.00%] [G loss: 6.375730]\n",
      "2166 [D loss: 0.303599, acc.: 83.33%] [G loss: 4.444045]\n",
      "2167 [D loss: 0.166228, acc.: 88.89%] [G loss: 4.562290]\n",
      "2168 [D loss: 0.087757, acc.: 100.00%] [G loss: 3.910165]\n",
      "2169 [D loss: 0.144308, acc.: 94.44%] [G loss: 3.825149]\n",
      "2170 [D loss: 0.122891, acc.: 94.44%] [G loss: 4.465312]\n",
      "2171 [D loss: 0.123773, acc.: 100.00%] [G loss: 4.057189]\n",
      "2172 [D loss: 0.102972, acc.: 94.44%] [G loss: 6.074321]\n",
      "2173 [D loss: 0.043107, acc.: 100.00%] [G loss: 4.581653]\n",
      "2174 [D loss: 0.597224, acc.: 66.67%] [G loss: 4.685941]\n",
      "2175 [D loss: 0.119973, acc.: 94.44%] [G loss: 5.183451]\n",
      "2176 [D loss: 0.062299, acc.: 100.00%] [G loss: 5.965528]\n",
      "2177 [D loss: 0.014186, acc.: 100.00%] [G loss: 6.430593]\n",
      "2178 [D loss: 0.057324, acc.: 94.44%] [G loss: 5.338315]\n",
      "2179 [D loss: 0.075900, acc.: 100.00%] [G loss: 4.864647]\n",
      "2180 [D loss: 0.148541, acc.: 94.44%] [G loss: 6.562462]\n",
      "2181 [D loss: 0.086719, acc.: 94.44%] [G loss: 5.868160]\n",
      "2182 [D loss: 0.071788, acc.: 100.00%] [G loss: 6.144406]\n",
      "2183 [D loss: 0.136886, acc.: 94.44%] [G loss: 4.996863]\n",
      "2184 [D loss: 0.053370, acc.: 100.00%] [G loss: 5.948048]\n",
      "2185 [D loss: 0.240725, acc.: 83.33%] [G loss: 3.202081]\n",
      "2186 [D loss: 0.280560, acc.: 88.89%] [G loss: 4.514367]\n",
      "2187 [D loss: 0.014875, acc.: 100.00%] [G loss: 5.774016]\n",
      "2188 [D loss: 0.076630, acc.: 94.44%] [G loss: 5.491760]\n",
      "2189 [D loss: 0.200876, acc.: 88.89%] [G loss: 6.143228]\n",
      "2190 [D loss: 0.085421, acc.: 100.00%] [G loss: 4.221962]\n",
      "2191 [D loss: 0.134611, acc.: 100.00%] [G loss: 4.474682]\n",
      "2192 [D loss: 0.121119, acc.: 94.44%] [G loss: 5.633036]\n",
      "2193 [D loss: 0.043330, acc.: 100.00%] [G loss: 5.205311]\n",
      "2194 [D loss: 0.128189, acc.: 94.44%] [G loss: 3.275975]\n",
      "2195 [D loss: 0.062281, acc.: 100.00%] [G loss: 3.466907]\n",
      "2196 [D loss: 0.251227, acc.: 88.89%] [G loss: 5.315594]\n",
      "2197 [D loss: 0.079454, acc.: 100.00%] [G loss: 5.681715]\n",
      "2198 [D loss: 0.409804, acc.: 88.89%] [G loss: 6.000406]\n",
      "2199 [D loss: 0.131957, acc.: 88.89%] [G loss: 6.653841]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200 [D loss: 0.269244, acc.: 88.89%] [G loss: 3.734772]\n",
      "2201 [D loss: 0.170685, acc.: 88.89%] [G loss: 5.406408]\n",
      "2202 [D loss: 0.010422, acc.: 100.00%] [G loss: 6.160188]\n",
      "2203 [D loss: 0.093001, acc.: 94.44%] [G loss: 5.945557]\n",
      "2204 [D loss: 0.077423, acc.: 100.00%] [G loss: 4.170597]\n",
      "2205 [D loss: 0.039199, acc.: 100.00%] [G loss: 3.804658]\n",
      "2206 [D loss: 0.138972, acc.: 94.44%] [G loss: 3.685802]\n",
      "2207 [D loss: 0.037203, acc.: 100.00%] [G loss: 5.582483]\n",
      "2208 [D loss: 0.340242, acc.: 77.78%] [G loss: 3.305367]\n",
      "2209 [D loss: 0.132766, acc.: 100.00%] [G loss: 4.550622]\n",
      "2210 [D loss: 0.019135, acc.: 100.00%] [G loss: 6.500979]\n",
      "2211 [D loss: 0.290169, acc.: 88.89%] [G loss: 2.456170]\n",
      "2212 [D loss: 0.118581, acc.: 94.44%] [G loss: 4.434934]\n",
      "2213 [D loss: 0.199273, acc.: 88.89%] [G loss: 7.699793]\n",
      "2214 [D loss: 0.118472, acc.: 88.89%] [G loss: 6.287348]\n",
      "2215 [D loss: 0.233595, acc.: 94.44%] [G loss: 4.551717]\n",
      "2216 [D loss: 0.342850, acc.: 88.89%] [G loss: 5.007569]\n",
      "2217 [D loss: 0.053402, acc.: 100.00%] [G loss: 4.014536]\n",
      "2218 [D loss: 0.142077, acc.: 94.44%] [G loss: 4.956573]\n",
      "2219 [D loss: 0.033392, acc.: 100.00%] [G loss: 6.117743]\n",
      "2220 [D loss: 0.075020, acc.: 100.00%] [G loss: 4.627787]\n",
      "2221 [D loss: 0.082809, acc.: 100.00%] [G loss: 4.684550]\n",
      "2222 [D loss: 0.103241, acc.: 100.00%] [G loss: 5.065037]\n",
      "2223 [D loss: 0.193687, acc.: 88.89%] [G loss: 4.012885]\n",
      "2224 [D loss: 0.055692, acc.: 100.00%] [G loss: 5.117228]\n",
      "2225 [D loss: 0.095465, acc.: 100.00%] [G loss: 3.759491]\n",
      "2226 [D loss: 0.148559, acc.: 94.44%] [G loss: 4.198297]\n",
      "2227 [D loss: 0.137762, acc.: 94.44%] [G loss: 4.212873]\n",
      "2228 [D loss: 0.099621, acc.: 100.00%] [G loss: 4.243939]\n",
      "2229 [D loss: 0.232038, acc.: 88.89%] [G loss: 4.113784]\n",
      "2230 [D loss: 0.113294, acc.: 100.00%] [G loss: 3.938118]\n",
      "2231 [D loss: 0.208473, acc.: 88.89%] [G loss: 5.195177]\n",
      "2232 [D loss: 0.082660, acc.: 94.44%] [G loss: 6.414248]\n",
      "2233 [D loss: 0.119930, acc.: 100.00%] [G loss: 3.456959]\n",
      "2234 [D loss: 0.140941, acc.: 94.44%] [G loss: 3.618306]\n",
      "2235 [D loss: 0.147856, acc.: 94.44%] [G loss: 3.649175]\n",
      "2236 [D loss: 0.240709, acc.: 83.33%] [G loss: 5.765553]\n",
      "2237 [D loss: 0.159310, acc.: 94.44%] [G loss: 6.017629]\n",
      "2238 [D loss: 0.117780, acc.: 100.00%] [G loss: 5.561430]\n",
      "2239 [D loss: 0.054592, acc.: 100.00%] [G loss: 4.648113]\n",
      "2240 [D loss: 0.392556, acc.: 83.33%] [G loss: 6.358819]\n",
      "2241 [D loss: 0.602004, acc.: 77.78%] [G loss: 3.688869]\n",
      "2242 [D loss: 0.076825, acc.: 100.00%] [G loss: 5.761279]\n",
      "2243 [D loss: 0.274992, acc.: 94.44%] [G loss: 4.999403]\n",
      "2244 [D loss: 0.024647, acc.: 100.00%] [G loss: 4.674063]\n",
      "2245 [D loss: 0.037283, acc.: 100.00%] [G loss: 6.861870]\n",
      "2246 [D loss: 0.068417, acc.: 100.00%] [G loss: 4.659827]\n",
      "2247 [D loss: 0.767748, acc.: 72.22%] [G loss: 3.478639]\n",
      "2248 [D loss: 0.025451, acc.: 100.00%] [G loss: 6.383442]\n",
      "2249 [D loss: 0.132197, acc.: 94.44%] [G loss: 6.537199]\n",
      "2250 [D loss: 0.047027, acc.: 100.00%] [G loss: 3.877178]\n",
      "2251 [D loss: 0.117095, acc.: 94.44%] [G loss: 4.033632]\n",
      "2252 [D loss: 0.046847, acc.: 100.00%] [G loss: 4.889254]\n",
      "2253 [D loss: 0.034161, acc.: 100.00%] [G loss: 5.441428]\n",
      "2254 [D loss: 0.084501, acc.: 100.00%] [G loss: 5.052847]\n",
      "2255 [D loss: 0.337684, acc.: 77.78%] [G loss: 3.599131]\n",
      "2256 [D loss: 0.079864, acc.: 100.00%] [G loss: 4.115192]\n",
      "2257 [D loss: 0.047919, acc.: 100.00%] [G loss: 4.242684]\n",
      "2258 [D loss: 0.174885, acc.: 88.89%] [G loss: 4.550124]\n",
      "2259 [D loss: 0.245174, acc.: 94.44%] [G loss: 4.729791]\n",
      "2260 [D loss: 0.106525, acc.: 100.00%] [G loss: 6.463884]\n",
      "2261 [D loss: 0.045313, acc.: 100.00%] [G loss: 7.446280]\n",
      "2262 [D loss: 0.018615, acc.: 100.00%] [G loss: 6.158110]\n",
      "2263 [D loss: 0.069341, acc.: 94.44%] [G loss: 6.071711]\n",
      "2264 [D loss: 0.073421, acc.: 100.00%] [G loss: 6.366728]\n",
      "2265 [D loss: 0.068801, acc.: 100.00%] [G loss: 6.022246]\n",
      "2266 [D loss: 0.051365, acc.: 94.44%] [G loss: 5.350190]\n",
      "2267 [D loss: 0.078320, acc.: 94.44%] [G loss: 5.147604]\n",
      "2268 [D loss: 0.028565, acc.: 100.00%] [G loss: 6.221604]\n",
      "2269 [D loss: 0.052499, acc.: 100.00%] [G loss: 5.127310]\n",
      "2270 [D loss: 0.071764, acc.: 100.00%] [G loss: 5.312075]\n",
      "2271 [D loss: 0.064087, acc.: 100.00%] [G loss: 5.055306]\n",
      "2272 [D loss: 0.102641, acc.: 94.44%] [G loss: 6.339596]\n",
      "2273 [D loss: 0.057589, acc.: 94.44%] [G loss: 6.456894]\n",
      "2274 [D loss: 0.021199, acc.: 100.00%] [G loss: 7.083124]\n",
      "2275 [D loss: 0.146010, acc.: 94.44%] [G loss: 5.068583]\n",
      "2276 [D loss: 0.097059, acc.: 94.44%] [G loss: 6.628324]\n",
      "2277 [D loss: 0.009523, acc.: 100.00%] [G loss: 5.149101]\n",
      "2278 [D loss: 0.037927, acc.: 100.00%] [G loss: 5.707454]\n",
      "2279 [D loss: 0.161001, acc.: 83.33%] [G loss: 4.838042]\n",
      "2280 [D loss: 0.207500, acc.: 94.44%] [G loss: 5.288530]\n",
      "2281 [D loss: 0.177780, acc.: 94.44%] [G loss: 5.091520]\n",
      "2282 [D loss: 0.115922, acc.: 94.44%] [G loss: 6.603540]\n",
      "2283 [D loss: 0.045800, acc.: 100.00%] [G loss: 8.593541]\n",
      "2284 [D loss: 0.107762, acc.: 100.00%] [G loss: 4.681612]\n",
      "2285 [D loss: 0.281098, acc.: 94.44%] [G loss: 3.917944]\n",
      "2286 [D loss: 0.022474, acc.: 100.00%] [G loss: 4.628370]\n",
      "2287 [D loss: 0.088695, acc.: 94.44%] [G loss: 4.643056]\n",
      "2288 [D loss: 0.093191, acc.: 100.00%] [G loss: 5.172337]\n",
      "2289 [D loss: 0.107697, acc.: 100.00%] [G loss: 5.901789]\n",
      "2290 [D loss: 0.047961, acc.: 100.00%] [G loss: 3.966548]\n",
      "2291 [D loss: 0.088618, acc.: 100.00%] [G loss: 3.851764]\n",
      "2292 [D loss: 0.282601, acc.: 94.44%] [G loss: 4.430277]\n",
      "2293 [D loss: 0.154472, acc.: 94.44%] [G loss: 5.618047]\n",
      "2294 [D loss: 0.025414, acc.: 100.00%] [G loss: 5.278997]\n",
      "2295 [D loss: 0.140183, acc.: 94.44%] [G loss: 3.863729]\n",
      "2296 [D loss: 0.040451, acc.: 100.00%] [G loss: 4.027378]\n",
      "2297 [D loss: 0.152200, acc.: 94.44%] [G loss: 5.161368]\n",
      "2298 [D loss: 0.109075, acc.: 94.44%] [G loss: 6.384403]\n",
      "2299 [D loss: 0.063415, acc.: 94.44%] [G loss: 5.279133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300 [D loss: 0.212874, acc.: 88.89%] [G loss: 5.886582]\n",
      "2301 [D loss: 0.109864, acc.: 94.44%] [G loss: 8.303042]\n",
      "2302 [D loss: 0.108262, acc.: 94.44%] [G loss: 4.960802]\n",
      "2303 [D loss: 0.169918, acc.: 88.89%] [G loss: 5.130110]\n",
      "2304 [D loss: 0.116928, acc.: 100.00%] [G loss: 3.501947]\n",
      "2305 [D loss: 0.087017, acc.: 94.44%] [G loss: 3.942769]\n",
      "2306 [D loss: 0.056611, acc.: 100.00%] [G loss: 5.302942]\n",
      "2307 [D loss: 0.025753, acc.: 100.00%] [G loss: 4.383806]\n",
      "2308 [D loss: 0.065327, acc.: 100.00%] [G loss: 5.811827]\n",
      "2309 [D loss: 0.011492, acc.: 100.00%] [G loss: 6.510266]\n",
      "2310 [D loss: 0.065414, acc.: 100.00%] [G loss: 4.708371]\n",
      "2311 [D loss: 0.093706, acc.: 94.44%] [G loss: 5.391082]\n",
      "2312 [D loss: 0.216051, acc.: 88.89%] [G loss: 4.874918]\n",
      "2313 [D loss: 0.175530, acc.: 94.44%] [G loss: 3.993130]\n",
      "2314 [D loss: 0.042752, acc.: 100.00%] [G loss: 5.572639]\n",
      "2315 [D loss: 0.035202, acc.: 100.00%] [G loss: 6.117282]\n",
      "2316 [D loss: 0.113106, acc.: 88.89%] [G loss: 5.409351]\n",
      "2317 [D loss: 0.077040, acc.: 94.44%] [G loss: 7.533558]\n",
      "2318 [D loss: 0.094328, acc.: 94.44%] [G loss: 5.236425]\n",
      "2319 [D loss: 0.024989, acc.: 100.00%] [G loss: 6.652986]\n",
      "2320 [D loss: 0.080665, acc.: 100.00%] [G loss: 5.385415]\n",
      "2321 [D loss: 0.048852, acc.: 100.00%] [G loss: 5.789128]\n",
      "2322 [D loss: 0.024442, acc.: 100.00%] [G loss: 7.059741]\n",
      "2323 [D loss: 0.185003, acc.: 94.44%] [G loss: 4.721843]\n",
      "2324 [D loss: 0.123734, acc.: 94.44%] [G loss: 5.845122]\n",
      "2325 [D loss: 0.077135, acc.: 100.00%] [G loss: 4.558649]\n",
      "2326 [D loss: 0.048443, acc.: 100.00%] [G loss: 5.749888]\n",
      "2327 [D loss: 0.159838, acc.: 94.44%] [G loss: 2.001573]\n",
      "2328 [D loss: 0.033408, acc.: 100.00%] [G loss: 4.768308]\n",
      "2329 [D loss: 0.108540, acc.: 94.44%] [G loss: 3.845021]\n",
      "2330 [D loss: 0.055283, acc.: 100.00%] [G loss: 4.414079]\n",
      "2331 [D loss: 0.008920, acc.: 100.00%] [G loss: 5.691046]\n",
      "2332 [D loss: 0.039827, acc.: 100.00%] [G loss: 5.450831]\n",
      "2333 [D loss: 0.362854, acc.: 83.33%] [G loss: 4.458372]\n",
      "2334 [D loss: 0.135371, acc.: 94.44%] [G loss: 4.976027]\n",
      "2335 [D loss: 0.016321, acc.: 100.00%] [G loss: 5.584657]\n",
      "2336 [D loss: 0.298742, acc.: 83.33%] [G loss: 4.059748]\n",
      "2337 [D loss: 0.077865, acc.: 100.00%] [G loss: 4.889325]\n",
      "2338 [D loss: 0.084752, acc.: 94.44%] [G loss: 4.560699]\n",
      "2339 [D loss: 0.133746, acc.: 100.00%] [G loss: 6.039809]\n",
      "2340 [D loss: 0.093566, acc.: 94.44%] [G loss: 5.837312]\n",
      "2341 [D loss: 0.044905, acc.: 100.00%] [G loss: 3.694191]\n",
      "2342 [D loss: 0.046282, acc.: 100.00%] [G loss: 3.853103]\n",
      "2343 [D loss: 0.161236, acc.: 88.89%] [G loss: 4.727018]\n",
      "2344 [D loss: 0.012237, acc.: 100.00%] [G loss: 4.464788]\n",
      "2345 [D loss: 0.067852, acc.: 100.00%] [G loss: 4.713347]\n",
      "2346 [D loss: 0.117109, acc.: 100.00%] [G loss: 4.320080]\n",
      "2347 [D loss: 0.223110, acc.: 83.33%] [G loss: 3.213692]\n",
      "2348 [D loss: 0.396238, acc.: 77.78%] [G loss: 5.893405]\n",
      "2349 [D loss: 0.119322, acc.: 94.44%] [G loss: 6.450880]\n",
      "2350 [D loss: 0.777933, acc.: 72.22%] [G loss: 0.988575]\n",
      "2351 [D loss: 0.161178, acc.: 94.44%] [G loss: 5.324846]\n",
      "2352 [D loss: 0.133140, acc.: 94.44%] [G loss: 5.332024]\n",
      "2353 [D loss: 0.237269, acc.: 88.89%] [G loss: 5.633339]\n",
      "2354 [D loss: 0.235406, acc.: 94.44%] [G loss: 4.618474]\n",
      "2355 [D loss: 0.369114, acc.: 88.89%] [G loss: 6.739470]\n",
      "2356 [D loss: 0.140718, acc.: 94.44%] [G loss: 5.714695]\n",
      "2357 [D loss: 0.092399, acc.: 100.00%] [G loss: 4.975213]\n",
      "2358 [D loss: 0.205742, acc.: 94.44%] [G loss: 3.997344]\n",
      "2359 [D loss: 0.234856, acc.: 94.44%] [G loss: 5.482888]\n",
      "2360 [D loss: 0.200228, acc.: 88.89%] [G loss: 4.704275]\n",
      "2361 [D loss: 0.064396, acc.: 100.00%] [G loss: 5.017016]\n",
      "2362 [D loss: 0.039737, acc.: 100.00%] [G loss: 6.418876]\n",
      "2363 [D loss: 0.120062, acc.: 94.44%] [G loss: 4.498349]\n",
      "2364 [D loss: 0.029871, acc.: 100.00%] [G loss: 5.343435]\n",
      "2365 [D loss: 0.168313, acc.: 88.89%] [G loss: 3.693781]\n",
      "2366 [D loss: 0.175002, acc.: 88.89%] [G loss: 6.532341]\n",
      "2367 [D loss: 0.143878, acc.: 94.44%] [G loss: 6.145268]\n",
      "2368 [D loss: 0.082863, acc.: 100.00%] [G loss: 4.021311]\n",
      "2369 [D loss: 0.053516, acc.: 100.00%] [G loss: 3.928411]\n",
      "2370 [D loss: 0.106403, acc.: 94.44%] [G loss: 4.554255]\n",
      "2371 [D loss: 0.042982, acc.: 100.00%] [G loss: 4.541656]\n",
      "2372 [D loss: 0.128991, acc.: 94.44%] [G loss: 5.150740]\n",
      "2373 [D loss: 0.119383, acc.: 94.44%] [G loss: 3.607719]\n",
      "2374 [D loss: 0.064043, acc.: 100.00%] [G loss: 6.200953]\n",
      "2375 [D loss: 0.195279, acc.: 94.44%] [G loss: 5.161783]\n",
      "2376 [D loss: 0.222278, acc.: 94.44%] [G loss: 3.728283]\n",
      "2377 [D loss: 0.328757, acc.: 83.33%] [G loss: 5.543615]\n",
      "2378 [D loss: 0.057023, acc.: 100.00%] [G loss: 6.171892]\n",
      "2379 [D loss: 0.253576, acc.: 94.44%] [G loss: 3.542272]\n",
      "2380 [D loss: 0.192092, acc.: 83.33%] [G loss: 2.674910]\n",
      "2381 [D loss: 0.099206, acc.: 94.44%] [G loss: 5.169501]\n",
      "2382 [D loss: 0.098219, acc.: 94.44%] [G loss: 6.080257]\n",
      "2383 [D loss: 0.494804, acc.: 77.78%] [G loss: 7.253191]\n",
      "2384 [D loss: 0.257930, acc.: 94.44%] [G loss: 5.018237]\n",
      "2385 [D loss: 1.152796, acc.: 55.56%] [G loss: 5.590699]\n",
      "2386 [D loss: 0.395732, acc.: 77.78%] [G loss: 4.093635]\n",
      "2387 [D loss: 0.064294, acc.: 94.44%] [G loss: 6.105105]\n",
      "2388 [D loss: 0.244695, acc.: 83.33%] [G loss: 4.025979]\n",
      "2389 [D loss: 0.103031, acc.: 100.00%] [G loss: 4.430738]\n",
      "2390 [D loss: 0.050731, acc.: 100.00%] [G loss: 5.155240]\n",
      "2391 [D loss: 0.085597, acc.: 100.00%] [G loss: 4.653001]\n",
      "2392 [D loss: 0.137326, acc.: 94.44%] [G loss: 2.990551]\n",
      "2393 [D loss: 0.068805, acc.: 100.00%] [G loss: 5.596125]\n",
      "2394 [D loss: 0.152354, acc.: 100.00%] [G loss: 4.709513]\n",
      "2395 [D loss: 0.042490, acc.: 100.00%] [G loss: 5.190998]\n",
      "2396 [D loss: 0.276571, acc.: 83.33%] [G loss: 6.248420]\n",
      "2397 [D loss: 0.224300, acc.: 94.44%] [G loss: 5.419954]\n",
      "2398 [D loss: 0.075775, acc.: 94.44%] [G loss: 6.010138]\n",
      "2399 [D loss: 0.126938, acc.: 100.00%] [G loss: 5.636538]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 [D loss: 0.168823, acc.: 88.89%] [G loss: 4.836356]\n",
      "2401 [D loss: 0.146185, acc.: 94.44%] [G loss: 5.734968]\n",
      "2402 [D loss: 0.195342, acc.: 94.44%] [G loss: 3.712777]\n",
      "2403 [D loss: 0.017515, acc.: 100.00%] [G loss: 5.652158]\n",
      "2404 [D loss: 0.067366, acc.: 94.44%] [G loss: 5.078860]\n",
      "2405 [D loss: 0.015986, acc.: 100.00%] [G loss: 4.860258]\n",
      "2406 [D loss: 0.136738, acc.: 100.00%] [G loss: 4.938136]\n",
      "2407 [D loss: 0.027912, acc.: 100.00%] [G loss: 4.433668]\n",
      "2408 [D loss: 0.071937, acc.: 94.44%] [G loss: 7.513061]\n",
      "2409 [D loss: 0.184245, acc.: 94.44%] [G loss: 6.590567]\n",
      "2410 [D loss: 0.038192, acc.: 100.00%] [G loss: 9.129663]\n",
      "2411 [D loss: 0.174913, acc.: 94.44%] [G loss: 5.694367]\n",
      "2412 [D loss: 0.033279, acc.: 100.00%] [G loss: 5.061186]\n",
      "2413 [D loss: 0.210652, acc.: 88.89%] [G loss: 7.838355]\n",
      "2414 [D loss: 0.027865, acc.: 100.00%] [G loss: 6.378846]\n",
      "2415 [D loss: 0.158145, acc.: 88.89%] [G loss: 7.771732]\n",
      "2416 [D loss: 0.014766, acc.: 100.00%] [G loss: 3.841917]\n",
      "2417 [D loss: 0.066179, acc.: 100.00%] [G loss: 5.441835]\n",
      "2418 [D loss: 0.038280, acc.: 100.00%] [G loss: 5.653026]\n",
      "2419 [D loss: 0.016566, acc.: 100.00%] [G loss: 6.400795]\n",
      "2420 [D loss: 0.104188, acc.: 100.00%] [G loss: 4.781562]\n",
      "2421 [D loss: 0.282841, acc.: 94.44%] [G loss: 5.514435]\n",
      "2422 [D loss: 0.074146, acc.: 100.00%] [G loss: 5.566102]\n",
      "2423 [D loss: 0.060282, acc.: 100.00%] [G loss: 6.706485]\n",
      "2424 [D loss: 0.176707, acc.: 94.44%] [G loss: 3.827817]\n",
      "2425 [D loss: 0.049006, acc.: 100.00%] [G loss: 4.919726]\n",
      "2426 [D loss: 0.120559, acc.: 94.44%] [G loss: 4.797651]\n",
      "2427 [D loss: 0.296691, acc.: 83.33%] [G loss: 4.566604]\n",
      "2428 [D loss: 0.026869, acc.: 100.00%] [G loss: 7.006996]\n",
      "2429 [D loss: 0.075659, acc.: 100.00%] [G loss: 5.861161]\n",
      "2430 [D loss: 0.037330, acc.: 100.00%] [G loss: 4.209499]\n",
      "2431 [D loss: 0.073981, acc.: 100.00%] [G loss: 4.241819]\n",
      "2432 [D loss: 0.026667, acc.: 100.00%] [G loss: 5.822831]\n",
      "2433 [D loss: 0.047600, acc.: 100.00%] [G loss: 6.647283]\n",
      "2434 [D loss: 0.208793, acc.: 88.89%] [G loss: 4.816420]\n",
      "2435 [D loss: 0.132157, acc.: 94.44%] [G loss: 5.852182]\n",
      "2436 [D loss: 0.031745, acc.: 100.00%] [G loss: 4.109915]\n",
      "2437 [D loss: 0.059368, acc.: 100.00%] [G loss: 4.980481]\n",
      "2438 [D loss: 0.131505, acc.: 94.44%] [G loss: 4.776964]\n",
      "2439 [D loss: 0.078863, acc.: 100.00%] [G loss: 4.385235]\n",
      "2440 [D loss: 0.067005, acc.: 100.00%] [G loss: 5.768369]\n",
      "2441 [D loss: 0.148680, acc.: 88.89%] [G loss: 3.852943]\n",
      "2442 [D loss: 0.101594, acc.: 94.44%] [G loss: 5.743189]\n",
      "2443 [D loss: 0.071061, acc.: 100.00%] [G loss: 4.506337]\n",
      "2444 [D loss: 0.008676, acc.: 100.00%] [G loss: 6.522320]\n",
      "2445 [D loss: 0.086196, acc.: 100.00%] [G loss: 4.646791]\n",
      "2446 [D loss: 0.166226, acc.: 100.00%] [G loss: 5.241563]\n",
      "2447 [D loss: 0.273114, acc.: 83.33%] [G loss: 4.574340]\n",
      "2448 [D loss: 0.149091, acc.: 94.44%] [G loss: 5.173528]\n",
      "2449 [D loss: 0.213602, acc.: 88.89%] [G loss: 5.140482]\n",
      "2450 [D loss: 0.249692, acc.: 83.33%] [G loss: 4.070535]\n",
      "2451 [D loss: 0.166248, acc.: 88.89%] [G loss: 3.715238]\n",
      "2452 [D loss: 0.072371, acc.: 100.00%] [G loss: 5.504108]\n",
      "2453 [D loss: 0.177591, acc.: 94.44%] [G loss: 5.055899]\n",
      "2454 [D loss: 0.114334, acc.: 100.00%] [G loss: 4.910250]\n",
      "2455 [D loss: 0.140470, acc.: 88.89%] [G loss: 5.646215]\n",
      "2456 [D loss: 0.041710, acc.: 100.00%] [G loss: 4.904214]\n",
      "2457 [D loss: 0.028353, acc.: 100.00%] [G loss: 5.483445]\n",
      "2458 [D loss: 0.114745, acc.: 94.44%] [G loss: 7.440752]\n",
      "2459 [D loss: 0.032915, acc.: 100.00%] [G loss: 7.280726]\n",
      "2460 [D loss: 0.248666, acc.: 94.44%] [G loss: 4.637068]\n",
      "2461 [D loss: 0.182984, acc.: 94.44%] [G loss: 3.869943]\n",
      "2462 [D loss: 0.020714, acc.: 100.00%] [G loss: 5.957702]\n",
      "2463 [D loss: 0.044933, acc.: 100.00%] [G loss: 5.160243]\n",
      "2464 [D loss: 0.049370, acc.: 100.00%] [G loss: 4.187043]\n",
      "2465 [D loss: 0.040239, acc.: 100.00%] [G loss: 6.088333]\n",
      "2466 [D loss: 0.048280, acc.: 100.00%] [G loss: 6.829926]\n",
      "2467 [D loss: 0.044696, acc.: 100.00%] [G loss: 4.120371]\n",
      "2468 [D loss: 0.205052, acc.: 88.89%] [G loss: 4.036636]\n",
      "2469 [D loss: 0.080809, acc.: 94.44%] [G loss: 4.492636]\n",
      "2470 [D loss: 0.150787, acc.: 94.44%] [G loss: 4.522231]\n",
      "2471 [D loss: 0.085407, acc.: 100.00%] [G loss: 5.286835]\n",
      "2472 [D loss: 0.292447, acc.: 83.33%] [G loss: 5.037224]\n",
      "2473 [D loss: 0.052133, acc.: 100.00%] [G loss: 9.405428]\n",
      "2474 [D loss: 0.177620, acc.: 88.89%] [G loss: 5.566289]\n",
      "2475 [D loss: 0.140401, acc.: 94.44%] [G loss: 5.626585]\n",
      "2476 [D loss: 0.125351, acc.: 94.44%] [G loss: 4.330442]\n",
      "2477 [D loss: 0.028100, acc.: 100.00%] [G loss: 8.208675]\n",
      "2478 [D loss: 0.363067, acc.: 88.89%] [G loss: 3.668936]\n",
      "2479 [D loss: 0.148576, acc.: 94.44%] [G loss: 5.371844]\n",
      "2480 [D loss: 0.187306, acc.: 94.44%] [G loss: 5.165515]\n",
      "2481 [D loss: 0.102500, acc.: 100.00%] [G loss: 3.935671]\n",
      "2482 [D loss: 0.147250, acc.: 94.44%] [G loss: 7.033738]\n",
      "2483 [D loss: 0.020255, acc.: 100.00%] [G loss: 5.679581]\n",
      "2484 [D loss: 0.149791, acc.: 94.44%] [G loss: 4.424174]\n",
      "2485 [D loss: 0.076104, acc.: 94.44%] [G loss: 8.574282]\n",
      "2486 [D loss: 0.207781, acc.: 88.89%] [G loss: 4.980555]\n",
      "2487 [D loss: 0.183211, acc.: 88.89%] [G loss: 5.985195]\n",
      "2488 [D loss: 0.084191, acc.: 100.00%] [G loss: 6.164236]\n",
      "2489 [D loss: 0.275321, acc.: 88.89%] [G loss: 4.577248]\n",
      "2490 [D loss: 0.045707, acc.: 100.00%] [G loss: 7.108686]\n",
      "2491 [D loss: 0.097948, acc.: 100.00%] [G loss: 4.162662]\n",
      "2492 [D loss: 0.035393, acc.: 100.00%] [G loss: 5.492302]\n",
      "2493 [D loss: 0.059773, acc.: 100.00%] [G loss: 6.007571]\n",
      "2494 [D loss: 0.058155, acc.: 100.00%] [G loss: 5.231055]\n",
      "2495 [D loss: 0.092099, acc.: 94.44%] [G loss: 5.308845]\n",
      "2496 [D loss: 0.077027, acc.: 100.00%] [G loss: 4.874125]\n",
      "2497 [D loss: 0.504083, acc.: 77.78%] [G loss: 2.276378]\n",
      "2498 [D loss: 0.667506, acc.: 72.22%] [G loss: 5.718750]\n",
      "2499 [D loss: 0.088022, acc.: 100.00%] [G loss: 8.794036]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 [D loss: 0.094800, acc.: 94.44%] [G loss: 5.876960]\n",
      "2501 [D loss: 0.182974, acc.: 94.44%] [G loss: 3.703252]\n",
      "2502 [D loss: 0.307702, acc.: 88.89%] [G loss: 2.809357]\n",
      "2503 [D loss: 0.076863, acc.: 100.00%] [G loss: 4.491839]\n",
      "2504 [D loss: 0.097783, acc.: 94.44%] [G loss: 3.694018]\n",
      "2505 [D loss: 0.181424, acc.: 94.44%] [G loss: 5.006133]\n",
      "2506 [D loss: 0.049344, acc.: 100.00%] [G loss: 4.197916]\n",
      "2507 [D loss: 0.194451, acc.: 88.89%] [G loss: 5.820669]\n",
      "2508 [D loss: 0.119236, acc.: 94.44%] [G loss: 6.946227]\n",
      "2509 [D loss: 0.185565, acc.: 88.89%] [G loss: 4.072500]\n",
      "2510 [D loss: 0.231295, acc.: 88.89%] [G loss: 4.976336]\n",
      "2511 [D loss: 0.065592, acc.: 100.00%] [G loss: 5.668861]\n",
      "2512 [D loss: 0.147074, acc.: 94.44%] [G loss: 4.582201]\n",
      "2513 [D loss: 0.130313, acc.: 88.89%] [G loss: 6.740498]\n",
      "2514 [D loss: 0.062964, acc.: 100.00%] [G loss: 5.419540]\n",
      "2515 [D loss: 0.096972, acc.: 94.44%] [G loss: 4.758017]\n",
      "2516 [D loss: 0.132671, acc.: 88.89%] [G loss: 5.654148]\n",
      "2517 [D loss: 0.045052, acc.: 100.00%] [G loss: 4.837167]\n",
      "2518 [D loss: 0.121393, acc.: 94.44%] [G loss: 3.971740]\n",
      "2519 [D loss: 0.025561, acc.: 100.00%] [G loss: 4.472045]\n",
      "2520 [D loss: 0.061114, acc.: 100.00%] [G loss: 5.209059]\n",
      "2521 [D loss: 0.025233, acc.: 100.00%] [G loss: 5.108325]\n",
      "2522 [D loss: 0.113411, acc.: 94.44%] [G loss: 6.768976]\n",
      "2523 [D loss: 0.189777, acc.: 88.89%] [G loss: 6.785552]\n",
      "2524 [D loss: 0.150614, acc.: 94.44%] [G loss: 5.752896]\n",
      "2525 [D loss: 0.269641, acc.: 88.89%] [G loss: 3.073201]\n",
      "2526 [D loss: 0.065268, acc.: 100.00%] [G loss: 4.380523]\n",
      "2527 [D loss: 0.031225, acc.: 100.00%] [G loss: 7.056311]\n",
      "2528 [D loss: 0.048962, acc.: 100.00%] [G loss: 6.499834]\n",
      "2529 [D loss: 0.236799, acc.: 88.89%] [G loss: 6.336697]\n",
      "2530 [D loss: 0.017893, acc.: 100.00%] [G loss: 8.457279]\n",
      "2531 [D loss: 0.500055, acc.: 77.78%] [G loss: 3.533707]\n",
      "2532 [D loss: 0.288294, acc.: 88.89%] [G loss: 3.553278]\n",
      "2533 [D loss: 0.049184, acc.: 100.00%] [G loss: 4.996092]\n",
      "2534 [D loss: 0.065207, acc.: 100.00%] [G loss: 3.849829]\n",
      "2535 [D loss: 0.129477, acc.: 94.44%] [G loss: 4.137124]\n",
      "2536 [D loss: 0.163056, acc.: 94.44%] [G loss: 4.765762]\n",
      "2537 [D loss: 0.206508, acc.: 88.89%] [G loss: 5.313793]\n",
      "2538 [D loss: 0.098133, acc.: 94.44%] [G loss: 7.534687]\n",
      "2539 [D loss: 0.036993, acc.: 100.00%] [G loss: 6.142308]\n",
      "2540 [D loss: 0.045543, acc.: 100.00%] [G loss: 6.128347]\n",
      "2541 [D loss: 0.024436, acc.: 100.00%] [G loss: 4.552572]\n",
      "2542 [D loss: 0.148336, acc.: 100.00%] [G loss: 4.160635]\n",
      "2543 [D loss: 0.051779, acc.: 100.00%] [G loss: 4.487473]\n",
      "2544 [D loss: 0.079281, acc.: 100.00%] [G loss: 4.935364]\n",
      "2545 [D loss: 0.005089, acc.: 100.00%] [G loss: 6.151669]\n",
      "2546 [D loss: 0.073260, acc.: 100.00%] [G loss: 4.181483]\n",
      "2547 [D loss: 0.035914, acc.: 100.00%] [G loss: 6.730807]\n",
      "2548 [D loss: 0.041628, acc.: 100.00%] [G loss: 4.687437]\n",
      "2549 [D loss: 0.041119, acc.: 100.00%] [G loss: 5.139330]\n",
      "2550 [D loss: 0.096726, acc.: 100.00%] [G loss: 5.310276]\n",
      "2551 [D loss: 0.093594, acc.: 94.44%] [G loss: 6.743070]\n",
      "2552 [D loss: 0.486566, acc.: 72.22%] [G loss: 2.577840]\n",
      "2553 [D loss: 0.256586, acc.: 88.89%] [G loss: 5.300135]\n",
      "2554 [D loss: 0.177635, acc.: 94.44%] [G loss: 6.005702]\n",
      "2555 [D loss: 0.432710, acc.: 88.89%] [G loss: 4.153907]\n",
      "2556 [D loss: 0.442275, acc.: 83.33%] [G loss: 5.312429]\n",
      "2557 [D loss: 0.070728, acc.: 100.00%] [G loss: 7.929534]\n",
      "2558 [D loss: 0.035989, acc.: 100.00%] [G loss: 5.225610]\n",
      "2559 [D loss: 0.036131, acc.: 100.00%] [G loss: 4.147220]\n",
      "2560 [D loss: 0.041052, acc.: 100.00%] [G loss: 3.991840]\n",
      "2561 [D loss: 0.081873, acc.: 100.00%] [G loss: 6.802687]\n",
      "2562 [D loss: 0.141603, acc.: 100.00%] [G loss: 4.129629]\n",
      "2563 [D loss: 0.079149, acc.: 94.44%] [G loss: 5.457245]\n",
      "2564 [D loss: 0.239143, acc.: 88.89%] [G loss: 6.535337]\n",
      "2565 [D loss: 0.156548, acc.: 94.44%] [G loss: 4.212327]\n",
      "2566 [D loss: 0.096136, acc.: 88.89%] [G loss: 5.395771]\n",
      "2567 [D loss: 0.014544, acc.: 100.00%] [G loss: 6.483904]\n",
      "2568 [D loss: 0.050193, acc.: 100.00%] [G loss: 4.592347]\n",
      "2569 [D loss: 0.098868, acc.: 100.00%] [G loss: 5.233168]\n",
      "2570 [D loss: 0.050215, acc.: 100.00%] [G loss: 5.344660]\n",
      "2571 [D loss: 0.062570, acc.: 100.00%] [G loss: 5.782377]\n",
      "2572 [D loss: 0.230649, acc.: 83.33%] [G loss: 5.551754]\n",
      "2573 [D loss: 0.002115, acc.: 100.00%] [G loss: 13.814550]\n",
      "2574 [D loss: 0.043411, acc.: 100.00%] [G loss: 8.980790]\n",
      "2575 [D loss: 0.003459, acc.: 100.00%] [G loss: 8.900086]\n",
      "2576 [D loss: 0.002088, acc.: 100.00%] [G loss: 8.235869]\n",
      "2577 [D loss: 0.008477, acc.: 100.00%] [G loss: 7.098537]\n",
      "2578 [D loss: 0.008209, acc.: 100.00%] [G loss: 6.756179]\n",
      "2579 [D loss: 0.008197, acc.: 100.00%] [G loss: 6.607646]\n",
      "2580 [D loss: 0.008556, acc.: 100.00%] [G loss: 7.325942]\n",
      "2581 [D loss: 0.015363, acc.: 100.00%] [G loss: 5.930638]\n",
      "2582 [D loss: 0.008575, acc.: 100.00%] [G loss: 6.372204]\n",
      "2583 [D loss: 0.025058, acc.: 100.00%] [G loss: 6.030724]\n",
      "2584 [D loss: 0.016721, acc.: 100.00%] [G loss: 5.999228]\n",
      "2585 [D loss: 0.027812, acc.: 100.00%] [G loss: 5.247551]\n",
      "2586 [D loss: 0.007987, acc.: 100.00%] [G loss: 6.627838]\n",
      "2587 [D loss: 0.054182, acc.: 100.00%] [G loss: 4.859277]\n",
      "2588 [D loss: 0.028697, acc.: 100.00%] [G loss: 8.626629]\n",
      "2589 [D loss: 0.022634, acc.: 100.00%] [G loss: 5.551686]\n",
      "2590 [D loss: 0.068856, acc.: 94.44%] [G loss: 6.490676]\n",
      "2591 [D loss: 0.073013, acc.: 100.00%] [G loss: 4.158509]\n",
      "2592 [D loss: 0.034473, acc.: 100.00%] [G loss: 5.155061]\n",
      "2593 [D loss: 0.019530, acc.: 100.00%] [G loss: 8.232837]\n",
      "2594 [D loss: 0.019998, acc.: 100.00%] [G loss: 9.191110]\n",
      "2595 [D loss: 0.031306, acc.: 100.00%] [G loss: 5.166274]\n",
      "2596 [D loss: 0.069238, acc.: 100.00%] [G loss: 5.925607]\n",
      "2597 [D loss: 0.096589, acc.: 94.44%] [G loss: 6.284638]\n",
      "2598 [D loss: 0.004744, acc.: 100.00%] [G loss: 7.607317]\n",
      "2599 [D loss: 0.068115, acc.: 100.00%] [G loss: 4.462046]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600 [D loss: 0.030874, acc.: 100.00%] [G loss: 6.160684]\n",
      "2601 [D loss: 0.043661, acc.: 100.00%] [G loss: 6.459417]\n",
      "2602 [D loss: 0.006347, acc.: 100.00%] [G loss: 6.613536]\n",
      "2603 [D loss: 0.030639, acc.: 100.00%] [G loss: 5.672847]\n",
      "2604 [D loss: 0.077026, acc.: 94.44%] [G loss: 5.019829]\n",
      "2605 [D loss: 0.215832, acc.: 94.44%] [G loss: 4.615737]\n",
      "2606 [D loss: 0.096702, acc.: 94.44%] [G loss: 5.419081]\n",
      "2607 [D loss: 0.007192, acc.: 100.00%] [G loss: 8.284620]\n",
      "2608 [D loss: 0.019174, acc.: 100.00%] [G loss: 7.212446]\n",
      "2609 [D loss: 0.033944, acc.: 100.00%] [G loss: 4.632588]\n",
      "2610 [D loss: 0.037644, acc.: 100.00%] [G loss: 5.479555]\n",
      "2611 [D loss: 0.038732, acc.: 100.00%] [G loss: 5.302384]\n",
      "2612 [D loss: 0.020989, acc.: 100.00%] [G loss: 6.399711]\n",
      "2613 [D loss: 0.018080, acc.: 100.00%] [G loss: 6.509155]\n",
      "2614 [D loss: 0.091718, acc.: 94.44%] [G loss: 5.853867]\n",
      "2615 [D loss: 0.010641, acc.: 100.00%] [G loss: 4.743161]\n",
      "2616 [D loss: 0.061839, acc.: 100.00%] [G loss: 3.719475]\n",
      "2617 [D loss: 0.026188, acc.: 100.00%] [G loss: 4.680280]\n",
      "2618 [D loss: 0.331054, acc.: 94.44%] [G loss: 5.872499]\n",
      "2619 [D loss: 0.048631, acc.: 100.00%] [G loss: 5.082404]\n",
      "2620 [D loss: 0.068716, acc.: 100.00%] [G loss: 8.190154]\n",
      "2621 [D loss: 0.006383, acc.: 100.00%] [G loss: 5.775850]\n",
      "2622 [D loss: 0.010735, acc.: 100.00%] [G loss: 7.238506]\n",
      "2623 [D loss: 0.145140, acc.: 88.89%] [G loss: 5.199914]\n",
      "2624 [D loss: 0.023895, acc.: 100.00%] [G loss: 6.044363]\n",
      "2625 [D loss: 0.029654, acc.: 100.00%] [G loss: 5.695069]\n",
      "2626 [D loss: 0.022382, acc.: 100.00%] [G loss: 6.297221]\n",
      "2627 [D loss: 0.012857, acc.: 100.00%] [G loss: 5.724829]\n",
      "2628 [D loss: 0.007846, acc.: 100.00%] [G loss: 6.210310]\n",
      "2629 [D loss: 0.016666, acc.: 100.00%] [G loss: 6.320911]\n",
      "2630 [D loss: 0.055994, acc.: 94.44%] [G loss: 5.992852]\n",
      "2631 [D loss: 0.085665, acc.: 100.00%] [G loss: 6.206663]\n",
      "2632 [D loss: 0.027485, acc.: 100.00%] [G loss: 7.853563]\n",
      "2633 [D loss: 0.050257, acc.: 100.00%] [G loss: 6.297324]\n",
      "2634 [D loss: 0.090270, acc.: 94.44%] [G loss: 5.933063]\n",
      "2635 [D loss: 0.037153, acc.: 100.00%] [G loss: 4.674493]\n",
      "2636 [D loss: 0.027460, acc.: 100.00%] [G loss: 6.692084]\n",
      "2637 [D loss: 0.026030, acc.: 100.00%] [G loss: 5.185878]\n",
      "2638 [D loss: 0.327315, acc.: 88.89%] [G loss: 4.571098]\n",
      "2639 [D loss: 0.019777, acc.: 100.00%] [G loss: 4.774200]\n",
      "2640 [D loss: 0.053524, acc.: 100.00%] [G loss: 5.311055]\n",
      "2641 [D loss: 0.073611, acc.: 100.00%] [G loss: 6.858391]\n",
      "2642 [D loss: 0.172717, acc.: 88.89%] [G loss: 5.956101]\n",
      "2643 [D loss: 0.258270, acc.: 88.89%] [G loss: 3.784636]\n",
      "2644 [D loss: 0.122333, acc.: 94.44%] [G loss: 5.129793]\n",
      "2645 [D loss: 0.159131, acc.: 88.89%] [G loss: 4.956311]\n",
      "2646 [D loss: 0.038678, acc.: 100.00%] [G loss: 6.585228]\n",
      "2647 [D loss: 0.030902, acc.: 100.00%] [G loss: 7.034717]\n",
      "2648 [D loss: 0.054245, acc.: 100.00%] [G loss: 5.055211]\n",
      "2649 [D loss: 0.132591, acc.: 94.44%] [G loss: 4.604253]\n",
      "2650 [D loss: 0.248203, acc.: 83.33%] [G loss: 3.721976]\n",
      "2651 [D loss: 0.059608, acc.: 100.00%] [G loss: 5.081021]\n",
      "2652 [D loss: 0.090249, acc.: 94.44%] [G loss: 3.550872]\n",
      "2653 [D loss: 0.007531, acc.: 100.00%] [G loss: 7.622519]\n",
      "2654 [D loss: 0.183948, acc.: 88.89%] [G loss: 4.548082]\n",
      "2655 [D loss: 0.453789, acc.: 83.33%] [G loss: 6.566420]\n",
      "2656 [D loss: 0.181597, acc.: 94.44%] [G loss: 6.702142]\n",
      "2657 [D loss: 0.301201, acc.: 83.33%] [G loss: 6.277656]\n",
      "2658 [D loss: 0.120514, acc.: 100.00%] [G loss: 4.804920]\n",
      "2659 [D loss: 0.040484, acc.: 100.00%] [G loss: 4.549115]\n",
      "2660 [D loss: 0.147325, acc.: 88.89%] [G loss: 6.291865]\n",
      "2661 [D loss: 0.506337, acc.: 77.78%] [G loss: 3.611769]\n",
      "2662 [D loss: 0.231000, acc.: 88.89%] [G loss: 4.666327]\n",
      "2663 [D loss: 0.015594, acc.: 100.00%] [G loss: 6.922523]\n",
      "2664 [D loss: 0.284994, acc.: 94.44%] [G loss: 3.072502]\n",
      "2665 [D loss: 0.065869, acc.: 94.44%] [G loss: 3.833876]\n",
      "2666 [D loss: 0.042866, acc.: 100.00%] [G loss: 4.647080]\n",
      "2667 [D loss: 0.082812, acc.: 94.44%] [G loss: 5.193179]\n",
      "2668 [D loss: 0.128675, acc.: 94.44%] [G loss: 4.911204]\n",
      "2669 [D loss: 0.295617, acc.: 83.33%] [G loss: 4.179006]\n",
      "2670 [D loss: 0.284726, acc.: 88.89%] [G loss: 3.020701]\n",
      "2671 [D loss: 0.307183, acc.: 77.78%] [G loss: 6.642522]\n",
      "2672 [D loss: 0.183458, acc.: 94.44%] [G loss: 5.067577]\n",
      "2673 [D loss: 0.060178, acc.: 100.00%] [G loss: 6.173189]\n",
      "2674 [D loss: 0.227205, acc.: 83.33%] [G loss: 4.032820]\n",
      "2675 [D loss: 0.104025, acc.: 88.89%] [G loss: 6.434130]\n",
      "2676 [D loss: 0.215976, acc.: 88.89%] [G loss: 6.719450]\n",
      "2677 [D loss: 0.038758, acc.: 100.00%] [G loss: 4.930141]\n",
      "2678 [D loss: 0.123943, acc.: 94.44%] [G loss: 5.130226]\n",
      "2679 [D loss: 0.107661, acc.: 94.44%] [G loss: 7.020223]\n",
      "2680 [D loss: 0.029361, acc.: 100.00%] [G loss: 6.259118]\n",
      "2681 [D loss: 0.706618, acc.: 66.67%] [G loss: 1.352287]\n",
      "2682 [D loss: 1.347152, acc.: 55.56%] [G loss: 7.992355]\n",
      "2683 [D loss: 0.398694, acc.: 77.78%] [G loss: 6.951952]\n",
      "2684 [D loss: 0.796881, acc.: 77.78%] [G loss: 3.291048]\n",
      "2685 [D loss: 0.029578, acc.: 100.00%] [G loss: 4.765084]\n",
      "2686 [D loss: 0.349575, acc.: 72.22%] [G loss: 5.417758]\n",
      "2687 [D loss: 0.119393, acc.: 94.44%] [G loss: 6.490210]\n",
      "2688 [D loss: 0.628962, acc.: 77.78%] [G loss: 2.879551]\n",
      "2689 [D loss: 0.466294, acc.: 88.89%] [G loss: 5.321983]\n",
      "2690 [D loss: 0.071672, acc.: 94.44%] [G loss: 7.502302]\n",
      "2691 [D loss: 0.273351, acc.: 94.44%] [G loss: 3.712979]\n",
      "2692 [D loss: 0.445185, acc.: 77.78%] [G loss: 4.576178]\n",
      "2693 [D loss: 0.052107, acc.: 100.00%] [G loss: 5.383333]\n",
      "2694 [D loss: 0.071239, acc.: 94.44%] [G loss: 4.733046]\n",
      "2695 [D loss: 0.021347, acc.: 100.00%] [G loss: 5.009247]\n",
      "2696 [D loss: 0.098228, acc.: 94.44%] [G loss: 5.198279]\n",
      "2697 [D loss: 0.408620, acc.: 88.89%] [G loss: 3.551999]\n",
      "2698 [D loss: 0.076007, acc.: 100.00%] [G loss: 5.355428]\n",
      "2699 [D loss: 0.138807, acc.: 100.00%] [G loss: 3.952694]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 [D loss: 0.062352, acc.: 100.00%] [G loss: 4.573194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2701 [D loss: 0.093091, acc.: 94.44%] [G loss: 5.204515]\n",
      "2702 [D loss: 0.066484, acc.: 100.00%] [G loss: 4.764088]\n",
      "2703 [D loss: 0.234301, acc.: 94.44%] [G loss: 3.861125]\n",
      "2704 [D loss: 0.036957, acc.: 100.00%] [G loss: 6.497248]\n",
      "2705 [D loss: 0.027914, acc.: 100.00%] [G loss: 4.812910]\n",
      "2706 [D loss: 0.163233, acc.: 94.44%] [G loss: 4.497072]\n",
      "2707 [D loss: 0.121189, acc.: 94.44%] [G loss: 3.846242]\n",
      "2708 [D loss: 0.062277, acc.: 100.00%] [G loss: 5.242455]\n",
      "2709 [D loss: 0.092096, acc.: 100.00%] [G loss: 6.047468]\n",
      "2710 [D loss: 0.091441, acc.: 100.00%] [G loss: 4.068042]\n",
      "2711 [D loss: 0.046510, acc.: 100.00%] [G loss: 3.610963]\n",
      "2712 [D loss: 0.198363, acc.: 88.89%] [G loss: 4.817270]\n",
      "2713 [D loss: 0.069456, acc.: 100.00%] [G loss: 5.731918]\n",
      "2714 [D loss: 0.077043, acc.: 94.44%] [G loss: 3.561714]\n",
      "2715 [D loss: 0.035667, acc.: 100.00%] [G loss: 5.312204]\n",
      "2716 [D loss: 0.041502, acc.: 100.00%] [G loss: 6.623437]\n",
      "2717 [D loss: 0.084778, acc.: 94.44%] [G loss: 4.468709]\n",
      "2718 [D loss: 0.164270, acc.: 94.44%] [G loss: 4.836256]\n",
      "2719 [D loss: 0.136558, acc.: 94.44%] [G loss: 5.376469]\n",
      "2720 [D loss: 0.260170, acc.: 88.89%] [G loss: 5.892458]\n",
      "2721 [D loss: 0.045895, acc.: 100.00%] [G loss: 5.940287]\n",
      "2722 [D loss: 0.162802, acc.: 88.89%] [G loss: 4.072941]\n",
      "2723 [D loss: 0.124980, acc.: 94.44%] [G loss: 5.401206]\n",
      "2724 [D loss: 0.238187, acc.: 94.44%] [G loss: 7.285189]\n",
      "2725 [D loss: 0.028048, acc.: 100.00%] [G loss: 4.542999]\n",
      "2726 [D loss: 0.072917, acc.: 100.00%] [G loss: 5.394449]\n",
      "2727 [D loss: 0.146258, acc.: 94.44%] [G loss: 4.969975]\n",
      "2728 [D loss: 0.029463, acc.: 100.00%] [G loss: 4.463475]\n",
      "2729 [D loss: 0.202029, acc.: 94.44%] [G loss: 5.692341]\n",
      "2730 [D loss: 0.077965, acc.: 94.44%] [G loss: 5.072784]\n",
      "2731 [D loss: 0.217099, acc.: 94.44%] [G loss: 4.803497]\n",
      "2732 [D loss: 0.052297, acc.: 100.00%] [G loss: 5.283165]\n",
      "2733 [D loss: 0.092867, acc.: 100.00%] [G loss: 6.457708]\n",
      "2734 [D loss: 0.112848, acc.: 94.44%] [G loss: 5.711257]\n",
      "2735 [D loss: 0.011418, acc.: 100.00%] [G loss: 5.638129]\n",
      "2736 [D loss: 0.142043, acc.: 94.44%] [G loss: 4.592048]\n",
      "2737 [D loss: 0.093535, acc.: 100.00%] [G loss: 4.737575]\n",
      "2738 [D loss: 0.137428, acc.: 94.44%] [G loss: 4.507498]\n",
      "2739 [D loss: 0.031275, acc.: 100.00%] [G loss: 5.525919]\n",
      "2740 [D loss: 0.099740, acc.: 94.44%] [G loss: 5.712986]\n",
      "2741 [D loss: 0.159305, acc.: 100.00%] [G loss: 3.421875]\n",
      "2742 [D loss: 0.022299, acc.: 100.00%] [G loss: 4.196860]\n",
      "2743 [D loss: 0.087097, acc.: 100.00%] [G loss: 5.883454]\n",
      "2744 [D loss: 0.170634, acc.: 88.89%] [G loss: 5.822001]\n",
      "2745 [D loss: 0.045061, acc.: 100.00%] [G loss: 6.727996]\n",
      "2746 [D loss: 0.518247, acc.: 83.33%] [G loss: 2.740995]\n",
      "2747 [D loss: 0.306823, acc.: 83.33%] [G loss: 5.017214]\n",
      "2748 [D loss: 0.236444, acc.: 88.89%] [G loss: 6.643627]\n",
      "2749 [D loss: 0.039093, acc.: 100.00%] [G loss: 5.393222]\n",
      "2750 [D loss: 0.295655, acc.: 88.89%] [G loss: 5.654352]\n",
      "2751 [D loss: 0.090871, acc.: 100.00%] [G loss: 5.985503]\n",
      "2752 [D loss: 0.002593, acc.: 100.00%] [G loss: 9.476080]\n",
      "2753 [D loss: 0.084349, acc.: 94.44%] [G loss: 7.120690]\n",
      "2754 [D loss: 0.149683, acc.: 94.44%] [G loss: 6.991665]\n",
      "2755 [D loss: 0.042099, acc.: 100.00%] [G loss: 7.014936]\n",
      "2756 [D loss: 0.031870, acc.: 100.00%] [G loss: 5.310637]\n",
      "2757 [D loss: 0.024718, acc.: 100.00%] [G loss: 5.725602]\n",
      "2758 [D loss: 0.212278, acc.: 94.44%] [G loss: 6.537210]\n",
      "2759 [D loss: 0.048399, acc.: 100.00%] [G loss: 5.830865]\n",
      "2760 [D loss: 0.185294, acc.: 94.44%] [G loss: 4.428535]\n",
      "2761 [D loss: 0.066600, acc.: 100.00%] [G loss: 4.029686]\n",
      "2762 [D loss: 0.386133, acc.: 77.78%] [G loss: 3.057178]\n",
      "2763 [D loss: 0.078360, acc.: 100.00%] [G loss: 4.150757]\n",
      "2764 [D loss: 0.053559, acc.: 100.00%] [G loss: 4.770354]\n",
      "2765 [D loss: 0.050423, acc.: 100.00%] [G loss: 5.441534]\n",
      "2766 [D loss: 0.031251, acc.: 100.00%] [G loss: 5.464010]\n",
      "2767 [D loss: 0.052897, acc.: 100.00%] [G loss: 5.171375]\n",
      "2768 [D loss: 0.053391, acc.: 100.00%] [G loss: 6.378775]\n",
      "2769 [D loss: 0.067876, acc.: 100.00%] [G loss: 5.621717]\n",
      "2770 [D loss: 0.064323, acc.: 100.00%] [G loss: 5.743046]\n",
      "2771 [D loss: 0.188156, acc.: 94.44%] [G loss: 4.989752]\n",
      "2772 [D loss: 0.152397, acc.: 88.89%] [G loss: 5.971319]\n",
      "2773 [D loss: 0.193325, acc.: 83.33%] [G loss: 5.112092]\n",
      "2774 [D loss: 0.017567, acc.: 100.00%] [G loss: 5.050487]\n",
      "2775 [D loss: 0.362807, acc.: 88.89%] [G loss: 5.588398]\n",
      "2776 [D loss: 0.030642, acc.: 100.00%] [G loss: 5.370293]\n",
      "2777 [D loss: 0.518765, acc.: 83.33%] [G loss: 4.387602]\n",
      "2778 [D loss: 0.296833, acc.: 83.33%] [G loss: 5.234360]\n",
      "2779 [D loss: 0.023391, acc.: 100.00%] [G loss: 6.392279]\n",
      "2780 [D loss: 0.030163, acc.: 100.00%] [G loss: 6.356367]\n",
      "2781 [D loss: 0.045886, acc.: 100.00%] [G loss: 5.008107]\n",
      "2782 [D loss: 0.506539, acc.: 77.78%] [G loss: 3.600396]\n",
      "2783 [D loss: 0.380095, acc.: 83.33%] [G loss: 5.790182]\n",
      "2784 [D loss: 0.024022, acc.: 100.00%] [G loss: 7.232801]\n",
      "2785 [D loss: 0.193814, acc.: 88.89%] [G loss: 4.126687]\n",
      "2786 [D loss: 0.107037, acc.: 100.00%] [G loss: 5.660933]\n",
      "2787 [D loss: 0.073410, acc.: 94.44%] [G loss: 5.236969]\n",
      "2788 [D loss: 0.100086, acc.: 94.44%] [G loss: 4.768038]\n",
      "2789 [D loss: 0.095123, acc.: 100.00%] [G loss: 4.365427]\n",
      "2790 [D loss: 0.013529, acc.: 100.00%] [G loss: 5.273903]\n",
      "2791 [D loss: 0.048256, acc.: 100.00%] [G loss: 4.172368]\n",
      "2792 [D loss: 0.037266, acc.: 100.00%] [G loss: 4.533163]\n",
      "2793 [D loss: 0.041566, acc.: 100.00%] [G loss: 4.951131]\n",
      "2794 [D loss: 0.034958, acc.: 100.00%] [G loss: 4.726927]\n",
      "2795 [D loss: 0.070453, acc.: 100.00%] [G loss: 4.877060]\n",
      "2796 [D loss: 0.019817, acc.: 100.00%] [G loss: 6.992188]\n",
      "2797 [D loss: 0.028340, acc.: 100.00%] [G loss: 5.892140]\n",
      "2798 [D loss: 0.012011, acc.: 100.00%] [G loss: 5.826036]\n",
      "2799 [D loss: 0.013687, acc.: 100.00%] [G loss: 6.585786]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800 [D loss: 0.191511, acc.: 88.89%] [G loss: 5.149658]\n",
      "2801 [D loss: 0.030403, acc.: 100.00%] [G loss: 5.015165]\n",
      "2802 [D loss: 0.076560, acc.: 100.00%] [G loss: 4.982441]\n",
      "2803 [D loss: 0.095690, acc.: 94.44%] [G loss: 5.284988]\n",
      "2804 [D loss: 0.097512, acc.: 94.44%] [G loss: 4.297953]\n",
      "2805 [D loss: 0.037445, acc.: 100.00%] [G loss: 5.483647]\n",
      "2806 [D loss: 0.031399, acc.: 100.00%] [G loss: 6.934987]\n",
      "2807 [D loss: 0.035322, acc.: 100.00%] [G loss: 5.910603]\n",
      "2808 [D loss: 0.228834, acc.: 83.33%] [G loss: 5.168678]\n",
      "2809 [D loss: 0.036540, acc.: 100.00%] [G loss: 6.161180]\n",
      "2810 [D loss: 0.051896, acc.: 100.00%] [G loss: 5.705476]\n",
      "2811 [D loss: 0.051499, acc.: 100.00%] [G loss: 5.595580]\n",
      "2812 [D loss: 0.017111, acc.: 100.00%] [G loss: 7.913917]\n",
      "2813 [D loss: 0.182600, acc.: 88.89%] [G loss: 2.619628]\n",
      "2814 [D loss: 0.122270, acc.: 94.44%] [G loss: 4.805106]\n",
      "2815 [D loss: 0.061421, acc.: 100.00%] [G loss: 5.101898]\n",
      "2816 [D loss: 0.108525, acc.: 100.00%] [G loss: 5.124454]\n",
      "2817 [D loss: 0.650550, acc.: 77.78%] [G loss: 4.457769]\n",
      "2818 [D loss: 0.258292, acc.: 88.89%] [G loss: 6.497583]\n",
      "2819 [D loss: 0.022252, acc.: 100.00%] [G loss: 7.382531]\n",
      "2820 [D loss: 0.336496, acc.: 88.89%] [G loss: 4.158094]\n",
      "2821 [D loss: 0.258652, acc.: 88.89%] [G loss: 3.786445]\n",
      "2822 [D loss: 0.142285, acc.: 94.44%] [G loss: 5.919127]\n",
      "2823 [D loss: 0.299103, acc.: 88.89%] [G loss: 6.573507]\n",
      "2824 [D loss: 0.025051, acc.: 100.00%] [G loss: 7.466942]\n",
      "2825 [D loss: 0.054378, acc.: 100.00%] [G loss: 5.979715]\n",
      "2826 [D loss: 0.025084, acc.: 100.00%] [G loss: 6.142575]\n",
      "2827 [D loss: 0.100874, acc.: 94.44%] [G loss: 5.252470]\n",
      "2828 [D loss: 0.047107, acc.: 100.00%] [G loss: 6.188129]\n",
      "2829 [D loss: 0.155708, acc.: 94.44%] [G loss: 6.648268]\n",
      "2830 [D loss: 0.050393, acc.: 100.00%] [G loss: 7.352769]\n",
      "2831 [D loss: 0.079271, acc.: 100.00%] [G loss: 6.282728]\n",
      "2832 [D loss: 0.108771, acc.: 94.44%] [G loss: 4.910299]\n",
      "2833 [D loss: 0.051615, acc.: 100.00%] [G loss: 4.224442]\n",
      "2834 [D loss: 0.012877, acc.: 100.00%] [G loss: 6.595328]\n",
      "2835 [D loss: 0.183168, acc.: 88.89%] [G loss: 5.082370]\n",
      "2836 [D loss: 0.014288, acc.: 100.00%] [G loss: 5.553266]\n",
      "2837 [D loss: 0.029391, acc.: 100.00%] [G loss: 5.962650]\n",
      "2838 [D loss: 0.021381, acc.: 100.00%] [G loss: 4.356431]\n",
      "2839 [D loss: 0.330979, acc.: 77.78%] [G loss: 7.871913]\n",
      "2840 [D loss: 0.076579, acc.: 100.00%] [G loss: 11.982162]\n",
      "2841 [D loss: 0.241405, acc.: 88.89%] [G loss: 7.615577]\n",
      "2842 [D loss: 0.015142, acc.: 100.00%] [G loss: 5.655782]\n",
      "2843 [D loss: 0.459707, acc.: 83.33%] [G loss: 5.897902]\n",
      "2844 [D loss: 0.055616, acc.: 100.00%] [G loss: 10.285885]\n",
      "2845 [D loss: 0.145364, acc.: 88.89%] [G loss: 6.924165]\n",
      "2846 [D loss: 0.188795, acc.: 88.89%] [G loss: 5.544936]\n",
      "2847 [D loss: 0.092368, acc.: 100.00%] [G loss: 5.679979]\n",
      "2848 [D loss: 0.074566, acc.: 100.00%] [G loss: 3.559849]\n",
      "2849 [D loss: 0.105488, acc.: 94.44%] [G loss: 4.650588]\n",
      "2850 [D loss: 0.039366, acc.: 100.00%] [G loss: 5.728769]\n",
      "2851 [D loss: 0.133122, acc.: 88.89%] [G loss: 5.361359]\n",
      "2852 [D loss: 0.016070, acc.: 100.00%] [G loss: 5.969916]\n",
      "2853 [D loss: 0.045958, acc.: 100.00%] [G loss: 5.520947]\n",
      "2854 [D loss: 0.158725, acc.: 94.44%] [G loss: 4.954808]\n",
      "2855 [D loss: 0.013496, acc.: 100.00%] [G loss: 6.613075]\n",
      "2856 [D loss: 0.009903, acc.: 100.00%] [G loss: 5.481885]\n",
      "2857 [D loss: 0.095004, acc.: 94.44%] [G loss: 4.880208]\n",
      "2858 [D loss: 0.026127, acc.: 100.00%] [G loss: 6.634987]\n",
      "2859 [D loss: 0.017036, acc.: 100.00%] [G loss: 6.964247]\n",
      "2860 [D loss: 0.017889, acc.: 100.00%] [G loss: 4.010580]\n",
      "2861 [D loss: 0.062941, acc.: 94.44%] [G loss: 6.442314]\n",
      "2862 [D loss: 0.156300, acc.: 88.89%] [G loss: 4.803682]\n",
      "2863 [D loss: 0.022237, acc.: 100.00%] [G loss: 7.980503]\n",
      "2864 [D loss: 0.205483, acc.: 94.44%] [G loss: 7.126266]\n",
      "2865 [D loss: 0.042898, acc.: 100.00%] [G loss: 8.378252]\n",
      "2866 [D loss: 0.218568, acc.: 94.44%] [G loss: 7.595242]\n",
      "2867 [D loss: 0.032910, acc.: 100.00%] [G loss: 5.013390]\n",
      "2868 [D loss: 0.057700, acc.: 100.00%] [G loss: 4.727228]\n",
      "2869 [D loss: 0.003869, acc.: 100.00%] [G loss: 8.158515]\n",
      "2870 [D loss: 0.036793, acc.: 100.00%] [G loss: 7.885203]\n",
      "2871 [D loss: 0.008853, acc.: 100.00%] [G loss: 6.414159]\n",
      "2872 [D loss: 0.056551, acc.: 100.00%] [G loss: 7.529311]\n",
      "2873 [D loss: 0.111688, acc.: 94.44%] [G loss: 7.529521]\n",
      "2874 [D loss: 0.011640, acc.: 100.00%] [G loss: 6.223607]\n",
      "2875 [D loss: 0.231288, acc.: 88.89%] [G loss: 4.993543]\n",
      "2876 [D loss: 0.060765, acc.: 94.44%] [G loss: 5.396988]\n",
      "2877 [D loss: 0.140203, acc.: 94.44%] [G loss: 5.807520]\n",
      "2878 [D loss: 0.058985, acc.: 100.00%] [G loss: 5.396705]\n",
      "2879 [D loss: 0.059023, acc.: 100.00%] [G loss: 5.970871]\n",
      "2880 [D loss: 0.028125, acc.: 100.00%] [G loss: 6.965289]\n",
      "2881 [D loss: 0.083217, acc.: 94.44%] [G loss: 6.382233]\n",
      "2882 [D loss: 0.034667, acc.: 100.00%] [G loss: 4.652134]\n",
      "2883 [D loss: 0.084505, acc.: 94.44%] [G loss: 4.537195]\n",
      "2884 [D loss: 0.094536, acc.: 94.44%] [G loss: 6.547358]\n",
      "2885 [D loss: 0.078623, acc.: 94.44%] [G loss: 4.910517]\n",
      "2886 [D loss: 0.404138, acc.: 77.78%] [G loss: 6.008698]\n",
      "2887 [D loss: 0.042166, acc.: 100.00%] [G loss: 7.507314]\n",
      "2888 [D loss: 0.123637, acc.: 94.44%] [G loss: 6.194703]\n",
      "2889 [D loss: 0.014563, acc.: 100.00%] [G loss: 7.260101]\n",
      "2890 [D loss: 0.038299, acc.: 100.00%] [G loss: 6.349691]\n",
      "2891 [D loss: 0.059308, acc.: 100.00%] [G loss: 5.634500]\n",
      "2892 [D loss: 0.056540, acc.: 100.00%] [G loss: 5.473826]\n",
      "2893 [D loss: 0.156057, acc.: 94.44%] [G loss: 5.972049]\n",
      "2894 [D loss: 0.100486, acc.: 94.44%] [G loss: 5.244989]\n",
      "2895 [D loss: 0.027228, acc.: 100.00%] [G loss: 4.202978]\n",
      "2896 [D loss: 0.170329, acc.: 94.44%] [G loss: 2.790106]\n",
      "2897 [D loss: 0.268070, acc.: 88.89%] [G loss: 4.033016]\n",
      "2898 [D loss: 0.032808, acc.: 100.00%] [G loss: 6.052341]\n",
      "2899 [D loss: 0.205938, acc.: 88.89%] [G loss: 3.854036]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 [D loss: 0.019148, acc.: 100.00%] [G loss: 6.092229]\n",
      "2901 [D loss: 0.050810, acc.: 100.00%] [G loss: 5.731223]\n",
      "2902 [D loss: 0.051180, acc.: 100.00%] [G loss: 4.150674]\n",
      "2903 [D loss: 0.071114, acc.: 94.44%] [G loss: 5.236614]\n",
      "2904 [D loss: 0.166652, acc.: 94.44%] [G loss: 5.814083]\n",
      "2905 [D loss: 0.079781, acc.: 100.00%] [G loss: 5.675369]\n",
      "2906 [D loss: 0.023261, acc.: 100.00%] [G loss: 5.135819]\n",
      "2907 [D loss: 0.127532, acc.: 94.44%] [G loss: 6.067617]\n",
      "2908 [D loss: 0.274589, acc.: 83.33%] [G loss: 6.722203]\n",
      "2909 [D loss: 0.054025, acc.: 100.00%] [G loss: 8.276757]\n",
      "2910 [D loss: 0.168190, acc.: 94.44%] [G loss: 6.771976]\n",
      "2911 [D loss: 0.034883, acc.: 100.00%] [G loss: 5.057928]\n",
      "2912 [D loss: 0.059008, acc.: 94.44%] [G loss: 5.965875]\n",
      "2913 [D loss: 0.025448, acc.: 100.00%] [G loss: 7.233523]\n",
      "2914 [D loss: 0.094848, acc.: 100.00%] [G loss: 5.885065]\n",
      "2915 [D loss: 0.339761, acc.: 88.89%] [G loss: 5.337047]\n",
      "2916 [D loss: 0.024493, acc.: 100.00%] [G loss: 6.317226]\n",
      "2917 [D loss: 0.156213, acc.: 94.44%] [G loss: 5.401648]\n",
      "2918 [D loss: 0.079764, acc.: 100.00%] [G loss: 5.026489]\n",
      "2919 [D loss: 0.038426, acc.: 100.00%] [G loss: 5.798060]\n",
      "2920 [D loss: 0.133104, acc.: 94.44%] [G loss: 5.473677]\n",
      "2921 [D loss: 0.016968, acc.: 100.00%] [G loss: 6.166487]\n",
      "2922 [D loss: 0.087272, acc.: 94.44%] [G loss: 6.828697]\n",
      "2923 [D loss: 0.355714, acc.: 83.33%] [G loss: 4.590782]\n",
      "2924 [D loss: 0.070644, acc.: 100.00%] [G loss: 6.914318]\n",
      "2925 [D loss: 0.099918, acc.: 100.00%] [G loss: 4.950073]\n",
      "2926 [D loss: 0.496430, acc.: 72.22%] [G loss: 4.961515]\n",
      "2927 [D loss: 0.220874, acc.: 88.89%] [G loss: 4.384397]\n",
      "2928 [D loss: 0.032851, acc.: 100.00%] [G loss: 7.102220]\n",
      "2929 [D loss: 0.082330, acc.: 100.00%] [G loss: 6.189742]\n",
      "2930 [D loss: 0.234551, acc.: 94.44%] [G loss: 3.437086]\n",
      "2931 [D loss: 0.216117, acc.: 94.44%] [G loss: 5.382666]\n",
      "2932 [D loss: 0.025332, acc.: 100.00%] [G loss: 6.280603]\n",
      "2933 [D loss: 0.216571, acc.: 94.44%] [G loss: 4.821395]\n",
      "2934 [D loss: 0.026271, acc.: 100.00%] [G loss: 5.373995]\n",
      "2935 [D loss: 0.121363, acc.: 94.44%] [G loss: 5.637143]\n",
      "2936 [D loss: 0.139211, acc.: 100.00%] [G loss: 5.193333]\n",
      "2937 [D loss: 0.123701, acc.: 94.44%] [G loss: 6.616532]\n",
      "2938 [D loss: 0.075429, acc.: 94.44%] [G loss: 4.892433]\n",
      "2939 [D loss: 0.213451, acc.: 88.89%] [G loss: 5.970901]\n",
      "2940 [D loss: 0.069906, acc.: 100.00%] [G loss: 6.263918]\n",
      "2941 [D loss: 0.057046, acc.: 100.00%] [G loss: 5.046566]\n",
      "2942 [D loss: 0.249843, acc.: 77.78%] [G loss: 3.624296]\n",
      "2943 [D loss: 0.094246, acc.: 94.44%] [G loss: 3.725672]\n",
      "2944 [D loss: 0.061237, acc.: 100.00%] [G loss: 6.969068]\n",
      "2945 [D loss: 0.188988, acc.: 88.89%] [G loss: 4.846695]\n",
      "2946 [D loss: 0.056878, acc.: 100.00%] [G loss: 5.793234]\n",
      "2947 [D loss: 0.475348, acc.: 88.89%] [G loss: 2.099096]\n",
      "2948 [D loss: 0.076533, acc.: 100.00%] [G loss: 5.007705]\n",
      "2949 [D loss: 0.085763, acc.: 94.44%] [G loss: 5.396792]\n",
      "2950 [D loss: 0.009385, acc.: 100.00%] [G loss: 4.844202]\n",
      "2951 [D loss: 0.017975, acc.: 100.00%] [G loss: 5.674698]\n",
      "2952 [D loss: 0.140131, acc.: 94.44%] [G loss: 3.856508]\n",
      "2953 [D loss: 0.374943, acc.: 88.89%] [G loss: 4.753130]\n",
      "2954 [D loss: 0.660974, acc.: 77.78%] [G loss: 5.471223]\n",
      "2955 [D loss: 0.094357, acc.: 94.44%] [G loss: 5.100826]\n",
      "2956 [D loss: 0.047665, acc.: 100.00%] [G loss: 6.464369]\n",
      "2957 [D loss: 0.046437, acc.: 100.00%] [G loss: 5.218242]\n",
      "2958 [D loss: 0.138396, acc.: 94.44%] [G loss: 4.537757]\n",
      "2959 [D loss: 0.045985, acc.: 100.00%] [G loss: 4.606942]\n",
      "2960 [D loss: 0.054148, acc.: 100.00%] [G loss: 5.430689]\n",
      "2961 [D loss: 0.076659, acc.: 94.44%] [G loss: 5.246873]\n",
      "2962 [D loss: 0.115909, acc.: 94.44%] [G loss: 5.676563]\n",
      "2963 [D loss: 0.093141, acc.: 100.00%] [G loss: 5.584846]\n",
      "2964 [D loss: 0.113652, acc.: 94.44%] [G loss: 5.092143]\n",
      "2965 [D loss: 0.330344, acc.: 88.89%] [G loss: 5.356427]\n",
      "2966 [D loss: 0.072103, acc.: 100.00%] [G loss: 6.214471]\n",
      "2967 [D loss: 0.648292, acc.: 66.67%] [G loss: 3.231797]\n",
      "2968 [D loss: 0.210298, acc.: 94.44%] [G loss: 4.563203]\n",
      "2969 [D loss: 0.124343, acc.: 100.00%] [G loss: 6.636992]\n",
      "2970 [D loss: 0.019846, acc.: 100.00%] [G loss: 6.823863]\n",
      "2971 [D loss: 0.065045, acc.: 100.00%] [G loss: 5.748212]\n",
      "2972 [D loss: 0.040524, acc.: 100.00%] [G loss: 5.337604]\n",
      "2973 [D loss: 0.040033, acc.: 100.00%] [G loss: 5.103440]\n",
      "2974 [D loss: 0.237079, acc.: 94.44%] [G loss: 3.205094]\n",
      "2975 [D loss: 0.184744, acc.: 88.89%] [G loss: 5.797463]\n",
      "2976 [D loss: 0.208496, acc.: 88.89%] [G loss: 5.216702]\n",
      "2977 [D loss: 0.261924, acc.: 88.89%] [G loss: 4.958178]\n",
      "2978 [D loss: 0.253617, acc.: 94.44%] [G loss: 6.318964]\n",
      "2979 [D loss: 0.343541, acc.: 83.33%] [G loss: 3.938269]\n",
      "2980 [D loss: 0.127362, acc.: 88.89%] [G loss: 5.107706]\n",
      "2981 [D loss: 0.083974, acc.: 100.00%] [G loss: 5.633760]\n",
      "2982 [D loss: 0.157400, acc.: 88.89%] [G loss: 3.902079]\n",
      "2983 [D loss: 0.058013, acc.: 100.00%] [G loss: 4.066559]\n",
      "2984 [D loss: 0.101144, acc.: 94.44%] [G loss: 4.814484]\n",
      "2985 [D loss: 0.085861, acc.: 100.00%] [G loss: 7.513049]\n",
      "2986 [D loss: 0.008835, acc.: 100.00%] [G loss: 6.494672]\n",
      "2987 [D loss: 0.067711, acc.: 100.00%] [G loss: 5.762077]\n",
      "2988 [D loss: 0.326238, acc.: 83.33%] [G loss: 4.251146]\n",
      "2989 [D loss: 0.153052, acc.: 88.89%] [G loss: 7.083302]\n",
      "2990 [D loss: 0.018459, acc.: 100.00%] [G loss: 7.927221]\n",
      "2991 [D loss: 0.270301, acc.: 94.44%] [G loss: 5.558710]\n",
      "2992 [D loss: 0.023810, acc.: 100.00%] [G loss: 4.857657]\n",
      "2993 [D loss: 0.049211, acc.: 100.00%] [G loss: 5.900333]\n",
      "2994 [D loss: 0.048180, acc.: 100.00%] [G loss: 5.116220]\n",
      "2995 [D loss: 0.169187, acc.: 94.44%] [G loss: 4.947396]\n",
      "2996 [D loss: 0.124537, acc.: 94.44%] [G loss: 5.491432]\n",
      "2997 [D loss: 0.089493, acc.: 94.44%] [G loss: 6.639822]\n",
      "2998 [D loss: 0.168290, acc.: 94.44%] [G loss: 5.905474]\n",
      "2999 [D loss: 0.025746, acc.: 100.00%] [G loss: 5.693195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 [D loss: 0.214716, acc.: 88.89%] [G loss: 3.158299]\n",
      "3001 [D loss: 0.147094, acc.: 88.89%] [G loss: 3.917291]\n",
      "3002 [D loss: 0.067947, acc.: 100.00%] [G loss: 5.095243]\n",
      "3003 [D loss: 0.361385, acc.: 77.78%] [G loss: 5.448614]\n",
      "3004 [D loss: 0.028750, acc.: 100.00%] [G loss: 5.748822]\n",
      "3005 [D loss: 0.192901, acc.: 88.89%] [G loss: 5.519064]\n",
      "3006 [D loss: 0.055230, acc.: 100.00%] [G loss: 5.908641]\n",
      "3007 [D loss: 0.030194, acc.: 100.00%] [G loss: 5.293167]\n",
      "3008 [D loss: 0.021798, acc.: 100.00%] [G loss: 7.501734]\n",
      "3009 [D loss: 0.009647, acc.: 100.00%] [G loss: 7.485559]\n",
      "3010 [D loss: 0.194858, acc.: 88.89%] [G loss: 4.720793]\n",
      "3011 [D loss: 0.103150, acc.: 88.89%] [G loss: 5.027768]\n",
      "3012 [D loss: 0.025654, acc.: 100.00%] [G loss: 5.090090]\n",
      "3013 [D loss: 0.015218, acc.: 100.00%] [G loss: 6.422576]\n",
      "3014 [D loss: 0.105832, acc.: 94.44%] [G loss: 4.778510]\n",
      "3015 [D loss: 0.488174, acc.: 77.78%] [G loss: 8.071629]\n",
      "3016 [D loss: 0.023995, acc.: 100.00%] [G loss: 10.166256]\n",
      "3017 [D loss: 0.064715, acc.: 100.00%] [G loss: 8.609679]\n",
      "3018 [D loss: 0.074225, acc.: 94.44%] [G loss: 7.380982]\n",
      "3019 [D loss: 0.044592, acc.: 100.00%] [G loss: 5.957458]\n",
      "3020 [D loss: 0.035995, acc.: 100.00%] [G loss: 7.421887]\n",
      "3021 [D loss: 0.012344, acc.: 100.00%] [G loss: 5.404748]\n",
      "3022 [D loss: 0.024589, acc.: 100.00%] [G loss: 7.663482]\n",
      "3023 [D loss: 0.075670, acc.: 100.00%] [G loss: 5.678783]\n",
      "3024 [D loss: 0.194080, acc.: 94.44%] [G loss: 6.841296]\n",
      "3025 [D loss: 0.030469, acc.: 100.00%] [G loss: 6.760902]\n",
      "3026 [D loss: 0.015240, acc.: 100.00%] [G loss: 7.070919]\n",
      "3027 [D loss: 0.003327, acc.: 100.00%] [G loss: 8.370289]\n",
      "3028 [D loss: 0.045972, acc.: 100.00%] [G loss: 7.897208]\n",
      "3029 [D loss: 0.189047, acc.: 94.44%] [G loss: 4.405858]\n",
      "3030 [D loss: 0.373449, acc.: 88.89%] [G loss: 5.586229]\n",
      "3031 [D loss: 0.065580, acc.: 94.44%] [G loss: 7.955688]\n",
      "3032 [D loss: 0.025930, acc.: 100.00%] [G loss: 6.452176]\n",
      "3033 [D loss: 0.205396, acc.: 88.89%] [G loss: 5.258146]\n",
      "3034 [D loss: 0.024089, acc.: 100.00%] [G loss: 3.883657]\n",
      "3035 [D loss: 0.352033, acc.: 83.33%] [G loss: 5.943398]\n",
      "3036 [D loss: 0.085060, acc.: 94.44%] [G loss: 6.417046]\n",
      "3037 [D loss: 0.090199, acc.: 94.44%] [G loss: 4.708887]\n",
      "3038 [D loss: 0.438290, acc.: 83.33%] [G loss: 6.256923]\n",
      "3039 [D loss: 0.123831, acc.: 100.00%] [G loss: 6.521005]\n",
      "3040 [D loss: 0.081435, acc.: 100.00%] [G loss: 4.366944]\n",
      "3041 [D loss: 0.403515, acc.: 88.89%] [G loss: 5.226724]\n",
      "3042 [D loss: 0.044793, acc.: 100.00%] [G loss: 6.844352]\n",
      "3043 [D loss: 0.208640, acc.: 94.44%] [G loss: 6.334293]\n",
      "3044 [D loss: 0.078701, acc.: 94.44%] [G loss: 6.052618]\n",
      "3045 [D loss: 0.775856, acc.: 77.78%] [G loss: 2.242945]\n",
      "3046 [D loss: 0.140446, acc.: 88.89%] [G loss: 4.715624]\n",
      "3047 [D loss: 0.171617, acc.: 94.44%] [G loss: 6.696868]\n",
      "3048 [D loss: 0.047874, acc.: 100.00%] [G loss: 5.902805]\n",
      "3049 [D loss: 0.541795, acc.: 83.33%] [G loss: 5.378139]\n",
      "3050 [D loss: 0.129482, acc.: 94.44%] [G loss: 7.620882]\n",
      "3051 [D loss: 0.192909, acc.: 94.44%] [G loss: 6.228628]\n",
      "3052 [D loss: 0.114406, acc.: 94.44%] [G loss: 4.214350]\n",
      "3053 [D loss: 0.028806, acc.: 100.00%] [G loss: 5.922239]\n",
      "3054 [D loss: 0.109420, acc.: 94.44%] [G loss: 5.165552]\n",
      "3055 [D loss: 0.199066, acc.: 94.44%] [G loss: 3.095106]\n",
      "3056 [D loss: 0.167009, acc.: 94.44%] [G loss: 4.369755]\n",
      "3057 [D loss: 0.116138, acc.: 94.44%] [G loss: 5.969688]\n",
      "3058 [D loss: 0.286535, acc.: 94.44%] [G loss: 5.173693]\n",
      "3059 [D loss: 0.155180, acc.: 94.44%] [G loss: 4.473995]\n",
      "3060 [D loss: 0.048367, acc.: 100.00%] [G loss: 4.389347]\n",
      "3061 [D loss: 0.101224, acc.: 94.44%] [G loss: 4.524052]\n",
      "3062 [D loss: 0.091756, acc.: 100.00%] [G loss: 5.786092]\n",
      "3063 [D loss: 0.058266, acc.: 100.00%] [G loss: 6.224615]\n",
      "3064 [D loss: 0.009972, acc.: 100.00%] [G loss: 6.586668]\n",
      "3065 [D loss: 0.038074, acc.: 100.00%] [G loss: 5.983849]\n",
      "3066 [D loss: 0.137989, acc.: 94.44%] [G loss: 6.667574]\n",
      "3067 [D loss: 0.013014, acc.: 100.00%] [G loss: 8.389331]\n",
      "3068 [D loss: 0.312432, acc.: 83.33%] [G loss: 5.061187]\n",
      "3069 [D loss: 0.268260, acc.: 88.89%] [G loss: 4.765745]\n",
      "3070 [D loss: 0.148563, acc.: 88.89%] [G loss: 5.667704]\n",
      "3071 [D loss: 0.059081, acc.: 100.00%] [G loss: 5.674524]\n",
      "3072 [D loss: 0.202203, acc.: 94.44%] [G loss: 5.415978]\n",
      "3073 [D loss: 0.036182, acc.: 100.00%] [G loss: 5.915273]\n",
      "3074 [D loss: 0.194017, acc.: 88.89%] [G loss: 6.874764]\n",
      "3075 [D loss: 0.040063, acc.: 100.00%] [G loss: 4.882724]\n",
      "3076 [D loss: 0.130110, acc.: 94.44%] [G loss: 3.947030]\n",
      "3077 [D loss: 0.138389, acc.: 94.44%] [G loss: 5.817607]\n",
      "3078 [D loss: 0.063061, acc.: 100.00%] [G loss: 7.312440]\n",
      "3079 [D loss: 0.039713, acc.: 100.00%] [G loss: 6.380536]\n",
      "3080 [D loss: 0.110210, acc.: 94.44%] [G loss: 4.686707]\n",
      "3081 [D loss: 0.086013, acc.: 94.44%] [G loss: 3.929669]\n",
      "3082 [D loss: 0.009790, acc.: 100.00%] [G loss: 6.645102]\n",
      "3083 [D loss: 0.024354, acc.: 100.00%] [G loss: 5.747530]\n",
      "3084 [D loss: 0.060646, acc.: 100.00%] [G loss: 6.209372]\n",
      "3085 [D loss: 0.010865, acc.: 100.00%] [G loss: 6.556283]\n",
      "3086 [D loss: 0.049631, acc.: 100.00%] [G loss: 5.541305]\n",
      "3087 [D loss: 0.138557, acc.: 100.00%] [G loss: 6.121844]\n",
      "3088 [D loss: 0.064246, acc.: 100.00%] [G loss: 5.640904]\n",
      "3089 [D loss: 0.023976, acc.: 100.00%] [G loss: 5.291642]\n",
      "3090 [D loss: 0.072853, acc.: 94.44%] [G loss: 5.225376]\n",
      "3091 [D loss: 0.043848, acc.: 100.00%] [G loss: 5.604528]\n",
      "3092 [D loss: 0.084924, acc.: 94.44%] [G loss: 5.945875]\n",
      "3093 [D loss: 0.233776, acc.: 88.89%] [G loss: 5.965917]\n",
      "3094 [D loss: 0.040969, acc.: 100.00%] [G loss: 7.952052]\n",
      "3095 [D loss: 0.044136, acc.: 100.00%] [G loss: 6.185188]\n",
      "3096 [D loss: 0.154234, acc.: 94.44%] [G loss: 5.094702]\n",
      "3097 [D loss: 0.108640, acc.: 94.44%] [G loss: 4.395862]\n",
      "3098 [D loss: 0.049057, acc.: 100.00%] [G loss: 5.698499]\n",
      "3099 [D loss: 0.036031, acc.: 100.00%] [G loss: 5.730242]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100 [D loss: 0.311055, acc.: 88.89%] [G loss: 2.884871]\n",
      "3101 [D loss: 0.241919, acc.: 94.44%] [G loss: 4.713422]\n",
      "3102 [D loss: 0.076981, acc.: 100.00%] [G loss: 4.711465]\n",
      "3103 [D loss: 0.099744, acc.: 100.00%] [G loss: 3.995003]\n",
      "3104 [D loss: 0.014181, acc.: 100.00%] [G loss: 7.352654]\n",
      "3105 [D loss: 0.154926, acc.: 88.89%] [G loss: 5.413291]\n",
      "3106 [D loss: 0.036586, acc.: 100.00%] [G loss: 4.979841]\n",
      "3107 [D loss: 0.082625, acc.: 94.44%] [G loss: 6.545498]\n",
      "3108 [D loss: 0.091576, acc.: 94.44%] [G loss: 5.786988]\n",
      "3109 [D loss: 0.131535, acc.: 94.44%] [G loss: 6.588383]\n",
      "3110 [D loss: 0.131927, acc.: 94.44%] [G loss: 5.447635]\n",
      "3111 [D loss: 0.238852, acc.: 77.78%] [G loss: 5.010498]\n",
      "3112 [D loss: 0.014553, acc.: 100.00%] [G loss: 6.701973]\n",
      "3113 [D loss: 0.715313, acc.: 83.33%] [G loss: 3.863925]\n",
      "3114 [D loss: 0.081710, acc.: 100.00%] [G loss: 4.094199]\n",
      "3115 [D loss: 0.050446, acc.: 100.00%] [G loss: 5.480416]\n",
      "3116 [D loss: 0.276973, acc.: 88.89%] [G loss: 6.263911]\n",
      "3117 [D loss: 0.162552, acc.: 94.44%] [G loss: 6.795659]\n",
      "3118 [D loss: 0.109507, acc.: 94.44%] [G loss: 6.589249]\n",
      "3119 [D loss: 0.030575, acc.: 100.00%] [G loss: 4.870191]\n",
      "3120 [D loss: 0.045251, acc.: 100.00%] [G loss: 6.798060]\n",
      "3121 [D loss: 0.226317, acc.: 83.33%] [G loss: 6.331105]\n",
      "3122 [D loss: 0.057239, acc.: 100.00%] [G loss: 8.029453]\n",
      "3123 [D loss: 0.107537, acc.: 94.44%] [G loss: 7.285569]\n",
      "3124 [D loss: 0.282117, acc.: 94.44%] [G loss: 3.433533]\n",
      "3125 [D loss: 0.137775, acc.: 94.44%] [G loss: 4.173092]\n",
      "3126 [D loss: 0.047315, acc.: 100.00%] [G loss: 6.905339]\n",
      "3127 [D loss: 0.111008, acc.: 94.44%] [G loss: 7.234788]\n",
      "3128 [D loss: 0.128472, acc.: 94.44%] [G loss: 6.127275]\n",
      "3129 [D loss: 0.127186, acc.: 94.44%] [G loss: 4.940063]\n",
      "3130 [D loss: 0.058322, acc.: 94.44%] [G loss: 5.057974]\n",
      "3131 [D loss: 0.018765, acc.: 100.00%] [G loss: 6.533971]\n",
      "3132 [D loss: 0.140114, acc.: 94.44%] [G loss: 5.003137]\n",
      "3133 [D loss: 0.360609, acc.: 88.89%] [G loss: 6.858578]\n",
      "3134 [D loss: 0.063568, acc.: 100.00%] [G loss: 5.358787]\n",
      "3135 [D loss: 0.094186, acc.: 100.00%] [G loss: 6.482961]\n",
      "3136 [D loss: 0.019685, acc.: 100.00%] [G loss: 5.754275]\n",
      "3137 [D loss: 0.170608, acc.: 94.44%] [G loss: 5.107108]\n",
      "3138 [D loss: 0.147806, acc.: 100.00%] [G loss: 4.000124]\n",
      "3139 [D loss: 0.030656, acc.: 100.00%] [G loss: 5.395897]\n",
      "3140 [D loss: 0.056036, acc.: 100.00%] [G loss: 4.788921]\n",
      "3141 [D loss: 0.037585, acc.: 100.00%] [G loss: 4.980829]\n",
      "3142 [D loss: 0.030306, acc.: 100.00%] [G loss: 5.901792]\n",
      "3143 [D loss: 0.063871, acc.: 100.00%] [G loss: 5.525565]\n",
      "3144 [D loss: 0.067242, acc.: 100.00%] [G loss: 3.667218]\n",
      "3145 [D loss: 0.147853, acc.: 94.44%] [G loss: 5.480490]\n",
      "3146 [D loss: 0.014330, acc.: 100.00%] [G loss: 6.392174]\n",
      "3147 [D loss: 0.058552, acc.: 94.44%] [G loss: 4.947536]\n",
      "3148 [D loss: 0.061064, acc.: 100.00%] [G loss: 4.608563]\n",
      "3149 [D loss: 0.495422, acc.: 66.67%] [G loss: 3.910034]\n",
      "3150 [D loss: 0.189358, acc.: 88.89%] [G loss: 3.170053]\n",
      "3151 [D loss: 0.148832, acc.: 88.89%] [G loss: 4.015415]\n",
      "3152 [D loss: 0.025495, acc.: 100.00%] [G loss: 7.350731]\n",
      "3153 [D loss: 0.236072, acc.: 94.44%] [G loss: 4.782053]\n",
      "3154 [D loss: 0.066768, acc.: 94.44%] [G loss: 5.670287]\n",
      "3155 [D loss: 0.133063, acc.: 94.44%] [G loss: 7.146700]\n",
      "3156 [D loss: 0.019633, acc.: 100.00%] [G loss: 6.080370]\n",
      "3157 [D loss: 0.055140, acc.: 100.00%] [G loss: 4.801712]\n",
      "3158 [D loss: 0.024359, acc.: 100.00%] [G loss: 6.941911]\n",
      "3159 [D loss: 0.025731, acc.: 100.00%] [G loss: 8.200954]\n",
      "3160 [D loss: 0.090822, acc.: 94.44%] [G loss: 6.635420]\n",
      "3161 [D loss: 0.019427, acc.: 100.00%] [G loss: 8.883090]\n",
      "3162 [D loss: 0.110297, acc.: 94.44%] [G loss: 5.302404]\n",
      "3163 [D loss: 0.005440, acc.: 100.00%] [G loss: 6.481044]\n",
      "3164 [D loss: 0.147572, acc.: 94.44%] [G loss: 5.734097]\n",
      "3165 [D loss: 0.004036, acc.: 100.00%] [G loss: 5.579906]\n",
      "3166 [D loss: 0.030412, acc.: 100.00%] [G loss: 5.850446]\n",
      "3167 [D loss: 0.059876, acc.: 94.44%] [G loss: 7.024633]\n",
      "3168 [D loss: 0.246885, acc.: 83.33%] [G loss: 5.801001]\n",
      "3169 [D loss: 0.124026, acc.: 94.44%] [G loss: 4.872571]\n",
      "3170 [D loss: 0.061178, acc.: 100.00%] [G loss: 5.634439]\n",
      "3171 [D loss: 0.273746, acc.: 88.89%] [G loss: 5.263878]\n",
      "3172 [D loss: 0.136450, acc.: 94.44%] [G loss: 4.914120]\n",
      "3173 [D loss: 0.017833, acc.: 100.00%] [G loss: 6.447531]\n",
      "3174 [D loss: 0.031094, acc.: 100.00%] [G loss: 5.882966]\n",
      "3175 [D loss: 0.098173, acc.: 100.00%] [G loss: 4.932488]\n",
      "3176 [D loss: 0.249805, acc.: 88.89%] [G loss: 6.206771]\n",
      "3177 [D loss: 0.078596, acc.: 100.00%] [G loss: 6.700703]\n",
      "3178 [D loss: 0.059994, acc.: 100.00%] [G loss: 4.983365]\n",
      "3179 [D loss: 0.290446, acc.: 88.89%] [G loss: 4.143186]\n",
      "3180 [D loss: 0.020492, acc.: 100.00%] [G loss: 5.530063]\n",
      "3181 [D loss: 0.037990, acc.: 100.00%] [G loss: 4.938881]\n",
      "3182 [D loss: 0.060097, acc.: 100.00%] [G loss: 4.416282]\n",
      "3183 [D loss: 0.021891, acc.: 100.00%] [G loss: 5.823751]\n",
      "3184 [D loss: 0.100292, acc.: 94.44%] [G loss: 5.067181]\n",
      "3185 [D loss: 0.162414, acc.: 94.44%] [G loss: 6.177777]\n",
      "3186 [D loss: 0.035437, acc.: 100.00%] [G loss: 6.948841]\n",
      "3187 [D loss: 0.491842, acc.: 77.78%] [G loss: 5.347592]\n",
      "3188 [D loss: 0.024851, acc.: 100.00%] [G loss: 8.085082]\n",
      "3189 [D loss: 0.061662, acc.: 100.00%] [G loss: 5.859329]\n",
      "3190 [D loss: 0.061053, acc.: 100.00%] [G loss: 7.253599]\n",
      "3191 [D loss: 0.034832, acc.: 100.00%] [G loss: 5.254723]\n",
      "3192 [D loss: 0.101069, acc.: 94.44%] [G loss: 4.437529]\n",
      "3193 [D loss: 0.106604, acc.: 94.44%] [G loss: 5.237278]\n",
      "3194 [D loss: 0.360769, acc.: 88.89%] [G loss: 5.797736]\n",
      "3195 [D loss: 0.254712, acc.: 83.33%] [G loss: 3.524133]\n",
      "3196 [D loss: 0.173616, acc.: 88.89%] [G loss: 6.052334]\n",
      "3197 [D loss: 0.239996, acc.: 88.89%] [G loss: 5.188085]\n",
      "3198 [D loss: 0.146061, acc.: 94.44%] [G loss: 4.814149]\n",
      "3199 [D loss: 0.015530, acc.: 100.00%] [G loss: 6.023054]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200 [D loss: 0.136378, acc.: 94.44%] [G loss: 5.993169]\n",
      "3201 [D loss: 0.117262, acc.: 94.44%] [G loss: 5.130063]\n",
      "3202 [D loss: 0.115251, acc.: 94.44%] [G loss: 6.982954]\n",
      "3203 [D loss: 0.083941, acc.: 100.00%] [G loss: 4.770556]\n",
      "3204 [D loss: 0.027742, acc.: 100.00%] [G loss: 6.277723]\n",
      "3205 [D loss: 0.096070, acc.: 100.00%] [G loss: 7.386508]\n",
      "3206 [D loss: 0.055867, acc.: 100.00%] [G loss: 5.266117]\n",
      "3207 [D loss: 0.140658, acc.: 94.44%] [G loss: 5.815027]\n",
      "3208 [D loss: 0.028980, acc.: 100.00%] [G loss: 5.159146]\n",
      "3209 [D loss: 0.071428, acc.: 100.00%] [G loss: 6.694441]\n",
      "3210 [D loss: 0.055232, acc.: 100.00%] [G loss: 5.507568]\n",
      "3211 [D loss: 0.023419, acc.: 100.00%] [G loss: 6.986013]\n",
      "3212 [D loss: 0.012215, acc.: 100.00%] [G loss: 8.491373]\n",
      "3213 [D loss: 0.014228, acc.: 100.00%] [G loss: 6.782981]\n",
      "3214 [D loss: 0.157413, acc.: 94.44%] [G loss: 5.165612]\n",
      "3215 [D loss: 0.157092, acc.: 94.44%] [G loss: 5.621890]\n",
      "3216 [D loss: 0.051142, acc.: 100.00%] [G loss: 5.885695]\n",
      "3217 [D loss: 0.052733, acc.: 100.00%] [G loss: 6.638395]\n",
      "3218 [D loss: 0.050865, acc.: 100.00%] [G loss: 11.674079]\n",
      "3219 [D loss: 0.044859, acc.: 100.00%] [G loss: 5.856719]\n",
      "3220 [D loss: 0.019255, acc.: 100.00%] [G loss: 6.392538]\n",
      "3221 [D loss: 0.053906, acc.: 100.00%] [G loss: 6.650945]\n",
      "3222 [D loss: 0.033908, acc.: 100.00%] [G loss: 7.294097]\n",
      "3223 [D loss: 0.177542, acc.: 88.89%] [G loss: 3.810444]\n",
      "3224 [D loss: 0.294932, acc.: 88.89%] [G loss: 4.856909]\n",
      "3225 [D loss: 0.003794, acc.: 100.00%] [G loss: 7.425002]\n",
      "3226 [D loss: 0.171337, acc.: 88.89%] [G loss: 3.225593]\n",
      "3227 [D loss: 0.111573, acc.: 94.44%] [G loss: 6.774637]\n",
      "3228 [D loss: 0.054331, acc.: 100.00%] [G loss: 6.117281]\n",
      "3229 [D loss: 0.072659, acc.: 94.44%] [G loss: 5.382001]\n",
      "3230 [D loss: 0.090116, acc.: 100.00%] [G loss: 4.582370]\n",
      "3231 [D loss: 0.042792, acc.: 100.00%] [G loss: 5.764060]\n",
      "3232 [D loss: 0.085592, acc.: 94.44%] [G loss: 5.619167]\n",
      "3233 [D loss: 0.022851, acc.: 100.00%] [G loss: 5.850435]\n",
      "3234 [D loss: 0.085249, acc.: 100.00%] [G loss: 5.087717]\n",
      "3235 [D loss: 0.241089, acc.: 83.33%] [G loss: 6.312722]\n",
      "3236 [D loss: 0.036151, acc.: 100.00%] [G loss: 5.957218]\n",
      "3237 [D loss: 0.579444, acc.: 77.78%] [G loss: 5.126973]\n",
      "3238 [D loss: 0.033647, acc.: 100.00%] [G loss: 4.629147]\n",
      "3239 [D loss: 0.079068, acc.: 100.00%] [G loss: 4.090560]\n",
      "3240 [D loss: 0.026241, acc.: 100.00%] [G loss: 5.593288]\n",
      "3241 [D loss: 0.057239, acc.: 100.00%] [G loss: 6.003290]\n",
      "3242 [D loss: 0.110097, acc.: 94.44%] [G loss: 6.302200]\n",
      "3243 [D loss: 0.031379, acc.: 100.00%] [G loss: 7.714588]\n",
      "3244 [D loss: 0.078753, acc.: 94.44%] [G loss: 4.130353]\n",
      "3245 [D loss: 0.039364, acc.: 100.00%] [G loss: 5.298376]\n",
      "3246 [D loss: 0.043119, acc.: 100.00%] [G loss: 4.945768]\n",
      "3247 [D loss: 0.079506, acc.: 94.44%] [G loss: 5.891592]\n",
      "3248 [D loss: 0.377699, acc.: 88.89%] [G loss: 4.503899]\n",
      "3249 [D loss: 0.088111, acc.: 100.00%] [G loss: 6.193979]\n",
      "3250 [D loss: 0.260306, acc.: 83.33%] [G loss: 5.984952]\n",
      "3251 [D loss: 0.289240, acc.: 83.33%] [G loss: 4.763819]\n",
      "3252 [D loss: 0.268173, acc.: 77.78%] [G loss: 7.787034]\n",
      "3253 [D loss: 0.352341, acc.: 94.44%] [G loss: 5.987311]\n",
      "3254 [D loss: 0.082259, acc.: 94.44%] [G loss: 6.516285]\n",
      "3255 [D loss: 0.239204, acc.: 83.33%] [G loss: 6.374571]\n",
      "3256 [D loss: 0.057501, acc.: 100.00%] [G loss: 5.608264]\n",
      "3257 [D loss: 0.122181, acc.: 94.44%] [G loss: 5.133752]\n",
      "3258 [D loss: 0.101817, acc.: 94.44%] [G loss: 6.624222]\n",
      "3259 [D loss: 0.039908, acc.: 100.00%] [G loss: 5.690036]\n",
      "3260 [D loss: 0.047928, acc.: 100.00%] [G loss: 4.722190]\n",
      "3261 [D loss: 0.012631, acc.: 100.00%] [G loss: 5.030134]\n",
      "3262 [D loss: 0.164521, acc.: 94.44%] [G loss: 4.265053]\n",
      "3263 [D loss: 0.091758, acc.: 94.44%] [G loss: 4.320854]\n",
      "3264 [D loss: 0.119372, acc.: 94.44%] [G loss: 6.940981]\n",
      "3265 [D loss: 0.096292, acc.: 94.44%] [G loss: 5.458549]\n",
      "3266 [D loss: 0.088517, acc.: 94.44%] [G loss: 5.430439]\n",
      "3267 [D loss: 0.132464, acc.: 94.44%] [G loss: 4.566366]\n",
      "3268 [D loss: 0.039671, acc.: 100.00%] [G loss: 3.930144]\n",
      "3269 [D loss: 0.011781, acc.: 100.00%] [G loss: 6.200560]\n",
      "3270 [D loss: 0.032607, acc.: 100.00%] [G loss: 5.045372]\n",
      "3271 [D loss: 0.038896, acc.: 100.00%] [G loss: 6.424537]\n",
      "3272 [D loss: 0.024583, acc.: 100.00%] [G loss: 5.917882]\n",
      "3273 [D loss: 0.090758, acc.: 100.00%] [G loss: 4.500937]\n",
      "3274 [D loss: 0.016997, acc.: 100.00%] [G loss: 4.695827]\n",
      "3275 [D loss: 0.171872, acc.: 94.44%] [G loss: 3.627046]\n",
      "3276 [D loss: 0.043330, acc.: 100.00%] [G loss: 6.663813]\n",
      "3277 [D loss: 0.190738, acc.: 94.44%] [G loss: 5.775606]\n",
      "3278 [D loss: 0.264515, acc.: 88.89%] [G loss: 6.561605]\n",
      "3279 [D loss: 0.027448, acc.: 100.00%] [G loss: 7.503277]\n",
      "3280 [D loss: 0.569549, acc.: 72.22%] [G loss: 1.857421]\n",
      "3281 [D loss: 0.361524, acc.: 77.78%] [G loss: 8.484139]\n",
      "3282 [D loss: 0.020696, acc.: 100.00%] [G loss: 8.279109]\n",
      "3283 [D loss: 0.345610, acc.: 77.78%] [G loss: 6.994730]\n",
      "3284 [D loss: 0.252631, acc.: 88.89%] [G loss: 6.343432]\n",
      "3285 [D loss: 0.205551, acc.: 88.89%] [G loss: 6.773538]\n",
      "3286 [D loss: 0.013080, acc.: 100.00%] [G loss: 7.167733]\n",
      "3287 [D loss: 0.043790, acc.: 100.00%] [G loss: 5.236212]\n",
      "3288 [D loss: 0.036643, acc.: 100.00%] [G loss: 5.644742]\n",
      "3289 [D loss: 0.043368, acc.: 100.00%] [G loss: 5.256044]\n",
      "3290 [D loss: 0.240854, acc.: 83.33%] [G loss: 5.317513]\n",
      "3291 [D loss: 0.024392, acc.: 100.00%] [G loss: 7.636914]\n",
      "3292 [D loss: 0.019919, acc.: 100.00%] [G loss: 7.964933]\n",
      "3293 [D loss: 0.108325, acc.: 94.44%] [G loss: 4.174964]\n",
      "3294 [D loss: 0.099512, acc.: 94.44%] [G loss: 5.728806]\n",
      "3295 [D loss: 0.054963, acc.: 100.00%] [G loss: 6.167251]\n",
      "3296 [D loss: 0.067995, acc.: 100.00%] [G loss: 5.000349]\n",
      "3297 [D loss: 0.034726, acc.: 100.00%] [G loss: 3.382298]\n",
      "3298 [D loss: 0.059758, acc.: 100.00%] [G loss: 5.305449]\n",
      "3299 [D loss: 0.067891, acc.: 100.00%] [G loss: 6.784061]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 [D loss: 0.069921, acc.: 100.00%] [G loss: 5.895854]\n",
      "3301 [D loss: 0.201328, acc.: 83.33%] [G loss: 6.269003]\n",
      "3302 [D loss: 0.024297, acc.: 100.00%] [G loss: 4.831323]\n",
      "3303 [D loss: 0.067731, acc.: 100.00%] [G loss: 5.240175]\n",
      "3304 [D loss: 0.165752, acc.: 88.89%] [G loss: 5.640532]\n",
      "3305 [D loss: 0.017782, acc.: 100.00%] [G loss: 7.292126]\n",
      "3306 [D loss: 0.062112, acc.: 100.00%] [G loss: 8.484158]\n",
      "3307 [D loss: 0.060743, acc.: 100.00%] [G loss: 5.716350]\n",
      "3308 [D loss: 0.018555, acc.: 100.00%] [G loss: 7.906230]\n",
      "3309 [D loss: 0.070333, acc.: 94.44%] [G loss: 6.690787]\n",
      "3310 [D loss: 0.043015, acc.: 100.00%] [G loss: 7.366830]\n",
      "3311 [D loss: 0.088454, acc.: 94.44%] [G loss: 6.007885]\n",
      "3312 [D loss: 0.107539, acc.: 100.00%] [G loss: 4.213107]\n",
      "3313 [D loss: 0.145221, acc.: 94.44%] [G loss: 5.429148]\n",
      "3314 [D loss: 0.196939, acc.: 94.44%] [G loss: 4.263006]\n",
      "3315 [D loss: 0.026466, acc.: 100.00%] [G loss: 5.788634]\n",
      "3316 [D loss: 0.005238, acc.: 100.00%] [G loss: 7.702287]\n",
      "3317 [D loss: 0.026146, acc.: 100.00%] [G loss: 5.743075]\n",
      "3318 [D loss: 0.031613, acc.: 100.00%] [G loss: 6.752649]\n",
      "3319 [D loss: 0.072768, acc.: 100.00%] [G loss: 5.148273]\n",
      "3320 [D loss: 0.038971, acc.: 100.00%] [G loss: 5.742438]\n",
      "3321 [D loss: 0.220902, acc.: 94.44%] [G loss: 6.056849]\n",
      "3322 [D loss: 0.021003, acc.: 100.00%] [G loss: 8.846050]\n",
      "3323 [D loss: 0.215935, acc.: 94.44%] [G loss: 4.127910]\n",
      "3324 [D loss: 0.016724, acc.: 100.00%] [G loss: 7.220056]\n",
      "3325 [D loss: 0.148492, acc.: 88.89%] [G loss: 7.370526]\n",
      "3326 [D loss: 0.362471, acc.: 88.89%] [G loss: 8.515858]\n",
      "3327 [D loss: 0.018872, acc.: 100.00%] [G loss: 11.245481]\n",
      "3328 [D loss: 0.322691, acc.: 83.33%] [G loss: 5.124097]\n",
      "3329 [D loss: 0.823505, acc.: 77.78%] [G loss: 7.100813]\n",
      "3330 [D loss: 0.288840, acc.: 88.89%] [G loss: 7.807710]\n",
      "3331 [D loss: 0.130270, acc.: 88.89%] [G loss: 6.428858]\n",
      "3332 [D loss: 0.108526, acc.: 88.89%] [G loss: 4.591282]\n",
      "3333 [D loss: 0.017161, acc.: 100.00%] [G loss: 7.290370]\n",
      "3334 [D loss: 0.190716, acc.: 94.44%] [G loss: 7.282864]\n",
      "3335 [D loss: 0.019537, acc.: 100.00%] [G loss: 7.859341]\n",
      "3336 [D loss: 0.183100, acc.: 94.44%] [G loss: 6.471911]\n",
      "3337 [D loss: 0.079838, acc.: 100.00%] [G loss: 4.266302]\n",
      "3338 [D loss: 0.034169, acc.: 100.00%] [G loss: 5.108390]\n",
      "3339 [D loss: 0.050968, acc.: 94.44%] [G loss: 6.533882]\n",
      "3340 [D loss: 0.039826, acc.: 100.00%] [G loss: 4.927906]\n",
      "3341 [D loss: 0.135304, acc.: 94.44%] [G loss: 4.747455]\n",
      "3342 [D loss: 0.151825, acc.: 94.44%] [G loss: 5.226747]\n",
      "3343 [D loss: 0.087107, acc.: 100.00%] [G loss: 5.689220]\n",
      "3344 [D loss: 0.049298, acc.: 100.00%] [G loss: 5.601148]\n",
      "3345 [D loss: 0.251719, acc.: 88.89%] [G loss: 5.582173]\n",
      "3346 [D loss: 0.071233, acc.: 100.00%] [G loss: 4.512056]\n",
      "3347 [D loss: 0.199651, acc.: 94.44%] [G loss: 5.692338]\n",
      "3348 [D loss: 0.134189, acc.: 94.44%] [G loss: 6.129641]\n",
      "3349 [D loss: 0.041250, acc.: 100.00%] [G loss: 4.803617]\n",
      "3350 [D loss: 0.058690, acc.: 94.44%] [G loss: 7.705729]\n",
      "3351 [D loss: 0.035514, acc.: 100.00%] [G loss: 11.975410]\n",
      "3352 [D loss: 0.009870, acc.: 100.00%] [G loss: 5.684011]\n",
      "3353 [D loss: 0.040117, acc.: 100.00%] [G loss: 7.491529]\n",
      "3354 [D loss: 0.058535, acc.: 100.00%] [G loss: 5.750230]\n",
      "3355 [D loss: 0.062738, acc.: 100.00%] [G loss: 5.911173]\n",
      "3356 [D loss: 0.058300, acc.: 100.00%] [G loss: 7.833396]\n",
      "3357 [D loss: 0.166872, acc.: 88.89%] [G loss: 4.164322]\n",
      "3358 [D loss: 0.095066, acc.: 94.44%] [G loss: 4.193267]\n",
      "3359 [D loss: 0.065771, acc.: 100.00%] [G loss: 6.157351]\n",
      "3360 [D loss: 0.072148, acc.: 100.00%] [G loss: 6.021278]\n",
      "3361 [D loss: 0.069345, acc.: 100.00%] [G loss: 5.240701]\n",
      "3362 [D loss: 0.158658, acc.: 88.89%] [G loss: 6.718575]\n",
      "3363 [D loss: 0.045243, acc.: 100.00%] [G loss: 5.730634]\n",
      "3364 [D loss: 0.119159, acc.: 94.44%] [G loss: 8.546347]\n",
      "3365 [D loss: 0.512488, acc.: 83.33%] [G loss: 5.851106]\n",
      "3366 [D loss: 0.025586, acc.: 100.00%] [G loss: 7.280407]\n",
      "3367 [D loss: 0.161692, acc.: 88.89%] [G loss: 6.305472]\n",
      "3368 [D loss: 0.040729, acc.: 100.00%] [G loss: 5.385927]\n",
      "3369 [D loss: 0.002691, acc.: 100.00%] [G loss: 5.632574]\n",
      "3370 [D loss: 0.041148, acc.: 100.00%] [G loss: 4.820146]\n",
      "3371 [D loss: 0.036268, acc.: 100.00%] [G loss: 4.298674]\n",
      "3372 [D loss: 0.047347, acc.: 100.00%] [G loss: 7.020784]\n",
      "3373 [D loss: 0.023183, acc.: 100.00%] [G loss: 6.407377]\n",
      "3374 [D loss: 0.034347, acc.: 100.00%] [G loss: 6.019296]\n",
      "3375 [D loss: 0.016472, acc.: 100.00%] [G loss: 5.770940]\n",
      "3376 [D loss: 0.164385, acc.: 94.44%] [G loss: 6.297594]\n",
      "3377 [D loss: 0.031284, acc.: 100.00%] [G loss: 8.347227]\n",
      "3378 [D loss: 0.298296, acc.: 88.89%] [G loss: 3.676340]\n",
      "3379 [D loss: 0.219890, acc.: 88.89%] [G loss: 5.541056]\n",
      "3380 [D loss: 0.187472, acc.: 94.44%] [G loss: 5.936449]\n",
      "3381 [D loss: 0.016685, acc.: 100.00%] [G loss: 4.657488]\n",
      "3382 [D loss: 0.107189, acc.: 94.44%] [G loss: 5.095657]\n",
      "3383 [D loss: 0.021545, acc.: 100.00%] [G loss: 3.920892]\n",
      "3384 [D loss: 0.021690, acc.: 100.00%] [G loss: 5.866322]\n",
      "3385 [D loss: 0.007129, acc.: 100.00%] [G loss: 8.127035]\n",
      "3386 [D loss: 0.088585, acc.: 94.44%] [G loss: 8.527053]\n",
      "3387 [D loss: 0.027855, acc.: 100.00%] [G loss: 7.261429]\n",
      "3388 [D loss: 0.069017, acc.: 100.00%] [G loss: 6.985295]\n",
      "3389 [D loss: 0.095033, acc.: 94.44%] [G loss: 5.543352]\n",
      "3390 [D loss: 0.047351, acc.: 100.00%] [G loss: 5.547381]\n",
      "3391 [D loss: 0.070034, acc.: 100.00%] [G loss: 7.316183]\n",
      "3392 [D loss: 0.044218, acc.: 100.00%] [G loss: 8.880938]\n",
      "3393 [D loss: 0.026909, acc.: 100.00%] [G loss: 7.020435]\n",
      "3394 [D loss: 0.011385, acc.: 100.00%] [G loss: 7.052446]\n",
      "3395 [D loss: 0.019578, acc.: 100.00%] [G loss: 5.897178]\n",
      "3396 [D loss: 0.152284, acc.: 94.44%] [G loss: 7.051150]\n",
      "3397 [D loss: 0.089490, acc.: 100.00%] [G loss: 4.973237]\n",
      "3398 [D loss: 0.410350, acc.: 88.89%] [G loss: 6.598865]\n",
      "3399 [D loss: 0.026324, acc.: 100.00%] [G loss: 10.641800]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3400 [D loss: 0.136182, acc.: 94.44%] [G loss: 8.139286]\n",
      "3401 [D loss: 0.025398, acc.: 100.00%] [G loss: 6.201988]\n",
      "3402 [D loss: 0.048173, acc.: 100.00%] [G loss: 5.250380]\n",
      "3403 [D loss: 0.066156, acc.: 100.00%] [G loss: 5.630729]\n",
      "3404 [D loss: 0.036487, acc.: 100.00%] [G loss: 5.819216]\n",
      "3405 [D loss: 0.063460, acc.: 94.44%] [G loss: 5.998637]\n",
      "3406 [D loss: 0.421285, acc.: 77.78%] [G loss: 4.771212]\n",
      "3407 [D loss: 0.209785, acc.: 94.44%] [G loss: 5.962769]\n",
      "3408 [D loss: 0.024075, acc.: 100.00%] [G loss: 6.504404]\n",
      "3409 [D loss: 0.152936, acc.: 88.89%] [G loss: 4.374282]\n",
      "3410 [D loss: 0.034391, acc.: 100.00%] [G loss: 5.221599]\n",
      "3411 [D loss: 0.037580, acc.: 100.00%] [G loss: 5.208292]\n",
      "3412 [D loss: 0.051858, acc.: 100.00%] [G loss: 6.214692]\n",
      "3413 [D loss: 0.021808, acc.: 100.00%] [G loss: 6.610832]\n",
      "3414 [D loss: 0.135945, acc.: 88.89%] [G loss: 6.947160]\n",
      "3415 [D loss: 0.047385, acc.: 100.00%] [G loss: 6.797158]\n",
      "3416 [D loss: 0.017631, acc.: 100.00%] [G loss: 5.877133]\n",
      "3417 [D loss: 0.032510, acc.: 100.00%] [G loss: 5.173275]\n",
      "3418 [D loss: 0.011461, acc.: 100.00%] [G loss: 7.676233]\n",
      "3419 [D loss: 0.033713, acc.: 100.00%] [G loss: 7.459503]\n",
      "3420 [D loss: 0.005759, acc.: 100.00%] [G loss: 5.636069]\n",
      "3421 [D loss: 0.054882, acc.: 100.00%] [G loss: 6.834093]\n",
      "3422 [D loss: 0.021835, acc.: 100.00%] [G loss: 7.689719]\n",
      "3423 [D loss: 0.071986, acc.: 94.44%] [G loss: 8.775897]\n",
      "3424 [D loss: 0.030572, acc.: 100.00%] [G loss: 6.859082]\n",
      "3425 [D loss: 0.350658, acc.: 77.78%] [G loss: 8.301090]\n",
      "3426 [D loss: 0.143935, acc.: 94.44%] [G loss: 6.223090]\n",
      "3427 [D loss: 0.008168, acc.: 100.00%] [G loss: 9.323217]\n",
      "3428 [D loss: 0.218196, acc.: 94.44%] [G loss: 5.143198]\n",
      "3429 [D loss: 0.319102, acc.: 72.22%] [G loss: 7.152200]\n",
      "3430 [D loss: 0.110915, acc.: 94.44%] [G loss: 10.131349]\n",
      "3431 [D loss: 0.042976, acc.: 100.00%] [G loss: 9.022442]\n",
      "3432 [D loss: 0.228360, acc.: 88.89%] [G loss: 4.483325]\n",
      "3433 [D loss: 0.247369, acc.: 88.89%] [G loss: 5.129678]\n",
      "3434 [D loss: 0.142709, acc.: 94.44%] [G loss: 5.941855]\n",
      "3435 [D loss: 0.026457, acc.: 100.00%] [G loss: 6.362222]\n",
      "3436 [D loss: 0.475542, acc.: 83.33%] [G loss: 4.192225]\n",
      "3437 [D loss: 0.068016, acc.: 94.44%] [G loss: 5.195324]\n",
      "3438 [D loss: 0.016258, acc.: 100.00%] [G loss: 5.731670]\n",
      "3439 [D loss: 0.128675, acc.: 94.44%] [G loss: 5.003172]\n",
      "3440 [D loss: 0.141050, acc.: 94.44%] [G loss: 6.004163]\n",
      "3441 [D loss: 0.063778, acc.: 100.00%] [G loss: 5.203184]\n",
      "3442 [D loss: 0.011338, acc.: 100.00%] [G loss: 5.009557]\n",
      "3443 [D loss: 0.361179, acc.: 88.89%] [G loss: 6.082602]\n",
      "3444 [D loss: 0.044799, acc.: 100.00%] [G loss: 7.139002]\n",
      "3445 [D loss: 0.489308, acc.: 77.78%] [G loss: 5.378675]\n",
      "3446 [D loss: 0.125364, acc.: 94.44%] [G loss: 5.409678]\n",
      "3447 [D loss: 0.226013, acc.: 88.89%] [G loss: 4.448001]\n",
      "3448 [D loss: 0.119154, acc.: 94.44%] [G loss: 4.484873]\n",
      "3449 [D loss: 0.073409, acc.: 94.44%] [G loss: 5.096235]\n",
      "3450 [D loss: 0.084555, acc.: 100.00%] [G loss: 3.985259]\n",
      "3451 [D loss: 0.159811, acc.: 94.44%] [G loss: 5.954651]\n",
      "3452 [D loss: 0.157971, acc.: 88.89%] [G loss: 6.373545]\n",
      "3453 [D loss: 0.031904, acc.: 100.00%] [G loss: 8.303630]\n",
      "3454 [D loss: 0.053569, acc.: 100.00%] [G loss: 7.233028]\n",
      "3455 [D loss: 0.266284, acc.: 88.89%] [G loss: 3.900006]\n",
      "3456 [D loss: 0.154094, acc.: 94.44%] [G loss: 6.267279]\n",
      "3457 [D loss: 0.331490, acc.: 83.33%] [G loss: 8.459522]\n",
      "3458 [D loss: 0.098343, acc.: 94.44%] [G loss: 8.773479]\n",
      "3459 [D loss: 0.723033, acc.: 77.78%] [G loss: 4.714548]\n",
      "3460 [D loss: 0.085278, acc.: 94.44%] [G loss: 5.454272]\n",
      "3461 [D loss: 0.324281, acc.: 88.89%] [G loss: 5.981020]\n",
      "3462 [D loss: 0.165348, acc.: 88.89%] [G loss: 6.299210]\n",
      "3463 [D loss: 0.234004, acc.: 88.89%] [G loss: 3.964367]\n",
      "3464 [D loss: 0.073420, acc.: 94.44%] [G loss: 5.761560]\n",
      "3465 [D loss: 0.132984, acc.: 88.89%] [G loss: 4.392230]\n",
      "3466 [D loss: 0.019855, acc.: 100.00%] [G loss: 7.814667]\n",
      "3467 [D loss: 0.071911, acc.: 100.00%] [G loss: 7.204663]\n",
      "3468 [D loss: 0.097248, acc.: 94.44%] [G loss: 5.972908]\n",
      "3469 [D loss: 0.220555, acc.: 94.44%] [G loss: 4.497126]\n",
      "3470 [D loss: 0.035143, acc.: 100.00%] [G loss: 6.163393]\n",
      "3471 [D loss: 0.162662, acc.: 83.33%] [G loss: 3.917401]\n",
      "3472 [D loss: 0.099489, acc.: 94.44%] [G loss: 4.488944]\n",
      "3473 [D loss: 0.049045, acc.: 100.00%] [G loss: 4.910576]\n",
      "3474 [D loss: 0.075968, acc.: 100.00%] [G loss: 6.030797]\n",
      "3475 [D loss: 0.064550, acc.: 94.44%] [G loss: 6.169746]\n",
      "3476 [D loss: 0.032892, acc.: 100.00%] [G loss: 6.097170]\n",
      "3477 [D loss: 0.011639, acc.: 100.00%] [G loss: 7.175907]\n",
      "3478 [D loss: 0.321807, acc.: 94.44%] [G loss: 4.837413]\n",
      "3479 [D loss: 0.284762, acc.: 94.44%] [G loss: 5.031486]\n",
      "3480 [D loss: 0.031348, acc.: 100.00%] [G loss: 5.811141]\n",
      "3481 [D loss: 0.059842, acc.: 94.44%] [G loss: 6.675954]\n",
      "3482 [D loss: 0.113637, acc.: 94.44%] [G loss: 6.383250]\n",
      "3483 [D loss: 0.075089, acc.: 94.44%] [G loss: 7.242910]\n",
      "3484 [D loss: 0.056467, acc.: 100.00%] [G loss: 6.761534]\n",
      "3485 [D loss: 0.032932, acc.: 100.00%] [G loss: 7.041137]\n",
      "3486 [D loss: 0.071603, acc.: 94.44%] [G loss: 6.210496]\n",
      "3487 [D loss: 0.062315, acc.: 100.00%] [G loss: 5.602796]\n",
      "3488 [D loss: 0.229276, acc.: 88.89%] [G loss: 8.542442]\n",
      "3489 [D loss: 0.111349, acc.: 94.44%] [G loss: 6.898097]\n",
      "3490 [D loss: 0.033184, acc.: 100.00%] [G loss: 5.805790]\n",
      "3491 [D loss: 0.085789, acc.: 100.00%] [G loss: 4.999502]\n",
      "3492 [D loss: 0.156290, acc.: 88.89%] [G loss: 8.638057]\n",
      "3493 [D loss: 0.026765, acc.: 100.00%] [G loss: 4.050688]\n",
      "3494 [D loss: 0.105540, acc.: 100.00%] [G loss: 4.090054]\n",
      "3495 [D loss: 0.057173, acc.: 100.00%] [G loss: 5.379106]\n",
      "3496 [D loss: 0.034089, acc.: 100.00%] [G loss: 6.184039]\n",
      "3497 [D loss: 0.073143, acc.: 94.44%] [G loss: 4.570710]\n",
      "3498 [D loss: 0.041515, acc.: 100.00%] [G loss: 4.760771]\n",
      "3499 [D loss: 0.043570, acc.: 100.00%] [G loss: 4.510424]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500 [D loss: 0.153584, acc.: 94.44%] [G loss: 5.632601]\n",
      "3501 [D loss: 0.102579, acc.: 94.44%] [G loss: 6.775145]\n",
      "3502 [D loss: 0.091283, acc.: 100.00%] [G loss: 6.972068]\n",
      "3503 [D loss: 0.107803, acc.: 100.00%] [G loss: 6.638025]\n",
      "3504 [D loss: 0.015469, acc.: 100.00%] [G loss: 6.912086]\n",
      "3505 [D loss: 0.025286, acc.: 100.00%] [G loss: 4.515638]\n",
      "3506 [D loss: 0.052386, acc.: 100.00%] [G loss: 4.196810]\n",
      "3507 [D loss: 0.065273, acc.: 94.44%] [G loss: 6.024118]\n",
      "3508 [D loss: 0.475018, acc.: 83.33%] [G loss: 7.179181]\n",
      "3509 [D loss: 0.270884, acc.: 88.89%] [G loss: 5.837951]\n",
      "3510 [D loss: 0.163420, acc.: 88.89%] [G loss: 6.530857]\n",
      "3511 [D loss: 0.252581, acc.: 88.89%] [G loss: 5.238616]\n",
      "3512 [D loss: 0.109142, acc.: 94.44%] [G loss: 4.977288]\n",
      "3513 [D loss: 0.025511, acc.: 100.00%] [G loss: 5.350238]\n",
      "3514 [D loss: 0.065514, acc.: 100.00%] [G loss: 6.393210]\n",
      "3515 [D loss: 0.048855, acc.: 100.00%] [G loss: 6.645213]\n",
      "3516 [D loss: 0.033572, acc.: 100.00%] [G loss: 4.298181]\n",
      "3517 [D loss: 0.304898, acc.: 88.89%] [G loss: 5.982374]\n",
      "3518 [D loss: 0.046558, acc.: 100.00%] [G loss: 7.102105]\n",
      "3519 [D loss: 0.082028, acc.: 100.00%] [G loss: 7.234928]\n",
      "3520 [D loss: 0.012318, acc.: 100.00%] [G loss: 7.057185]\n",
      "3521 [D loss: 0.067492, acc.: 100.00%] [G loss: 7.519167]\n",
      "3522 [D loss: 0.025605, acc.: 100.00%] [G loss: 7.679686]\n",
      "3523 [D loss: 0.007353, acc.: 100.00%] [G loss: 7.657860]\n",
      "3524 [D loss: 0.041547, acc.: 100.00%] [G loss: 6.605291]\n",
      "3525 [D loss: 0.040700, acc.: 100.00%] [G loss: 5.510946]\n",
      "3526 [D loss: 0.054332, acc.: 100.00%] [G loss: 5.327146]\n",
      "3527 [D loss: 0.005745, acc.: 100.00%] [G loss: 4.144177]\n",
      "3528 [D loss: 0.038279, acc.: 100.00%] [G loss: 4.673870]\n",
      "3529 [D loss: 0.076332, acc.: 94.44%] [G loss: 5.059865]\n",
      "3530 [D loss: 0.003972, acc.: 100.00%] [G loss: 6.652658]\n",
      "3531 [D loss: 0.045944, acc.: 100.00%] [G loss: 4.439375]\n",
      "3532 [D loss: 0.031944, acc.: 100.00%] [G loss: 5.621073]\n",
      "3533 [D loss: 0.153599, acc.: 88.89%] [G loss: 6.964298]\n",
      "3534 [D loss: 0.028122, acc.: 100.00%] [G loss: 5.542691]\n",
      "3535 [D loss: 0.076363, acc.: 100.00%] [G loss: 3.838092]\n",
      "3536 [D loss: 0.108893, acc.: 94.44%] [G loss: 5.943741]\n",
      "3537 [D loss: 0.085550, acc.: 94.44%] [G loss: 5.947779]\n",
      "3538 [D loss: 0.029490, acc.: 100.00%] [G loss: 6.011270]\n",
      "3539 [D loss: 0.108400, acc.: 94.44%] [G loss: 5.036679]\n",
      "3540 [D loss: 0.134557, acc.: 94.44%] [G loss: 5.705339]\n",
      "3541 [D loss: 0.113079, acc.: 94.44%] [G loss: 5.930895]\n",
      "3542 [D loss: 0.040923, acc.: 100.00%] [G loss: 6.635625]\n",
      "3543 [D loss: 0.034049, acc.: 100.00%] [G loss: 6.923147]\n",
      "3544 [D loss: 0.023983, acc.: 100.00%] [G loss: 8.004569]\n",
      "3545 [D loss: 0.082316, acc.: 94.44%] [G loss: 6.114574]\n",
      "3546 [D loss: 0.283887, acc.: 83.33%] [G loss: 4.605360]\n",
      "3547 [D loss: 0.118035, acc.: 94.44%] [G loss: 5.904206]\n",
      "3548 [D loss: 0.042233, acc.: 100.00%] [G loss: 8.249263]\n",
      "3549 [D loss: 0.022634, acc.: 100.00%] [G loss: 8.767659]\n",
      "3550 [D loss: 0.011784, acc.: 100.00%] [G loss: 4.810808]\n",
      "3551 [D loss: 0.057353, acc.: 100.00%] [G loss: 7.303079]\n",
      "3552 [D loss: 0.009448, acc.: 100.00%] [G loss: 5.762919]\n",
      "3553 [D loss: 0.052878, acc.: 100.00%] [G loss: 5.669313]\n",
      "3554 [D loss: 0.057729, acc.: 100.00%] [G loss: 5.048295]\n",
      "3555 [D loss: 0.029044, acc.: 100.00%] [G loss: 6.094313]\n",
      "3556 [D loss: 0.055722, acc.: 100.00%] [G loss: 6.076805]\n",
      "3557 [D loss: 0.026234, acc.: 100.00%] [G loss: 5.729298]\n",
      "3558 [D loss: 0.009014, acc.: 100.00%] [G loss: 6.991167]\n",
      "3559 [D loss: 0.035975, acc.: 100.00%] [G loss: 5.833150]\n",
      "3560 [D loss: 0.076114, acc.: 100.00%] [G loss: 8.722726]\n",
      "3561 [D loss: 0.096834, acc.: 94.44%] [G loss: 5.250579]\n",
      "3562 [D loss: 0.092062, acc.: 94.44%] [G loss: 6.626383]\n",
      "3563 [D loss: 0.024911, acc.: 100.00%] [G loss: 4.219382]\n",
      "3564 [D loss: 0.028009, acc.: 100.00%] [G loss: 5.284315]\n",
      "3565 [D loss: 0.040298, acc.: 100.00%] [G loss: 3.871140]\n",
      "3566 [D loss: 0.014770, acc.: 100.00%] [G loss: 5.569659]\n",
      "3567 [D loss: 0.035411, acc.: 100.00%] [G loss: 4.955951]\n",
      "3568 [D loss: 0.034143, acc.: 100.00%] [G loss: 7.003087]\n",
      "3569 [D loss: 0.014971, acc.: 100.00%] [G loss: 5.685366]\n",
      "3570 [D loss: 0.144016, acc.: 94.44%] [G loss: 5.739828]\n",
      "3571 [D loss: 0.024705, acc.: 100.00%] [G loss: 7.722593]\n",
      "3572 [D loss: 0.056868, acc.: 100.00%] [G loss: 6.006676]\n",
      "3573 [D loss: 0.006803, acc.: 100.00%] [G loss: 5.350947]\n",
      "3574 [D loss: 0.029479, acc.: 100.00%] [G loss: 7.180798]\n",
      "3575 [D loss: 0.055022, acc.: 100.00%] [G loss: 5.445204]\n",
      "3576 [D loss: 0.203991, acc.: 83.33%] [G loss: 7.302030]\n",
      "3577 [D loss: 0.020198, acc.: 100.00%] [G loss: 7.554024]\n",
      "3578 [D loss: 0.125995, acc.: 94.44%] [G loss: 7.063950]\n",
      "3579 [D loss: 0.009592, acc.: 100.00%] [G loss: 9.312469]\n",
      "3580 [D loss: 0.010059, acc.: 100.00%] [G loss: 7.579766]\n",
      "3581 [D loss: 0.026901, acc.: 100.00%] [G loss: 5.791929]\n",
      "3582 [D loss: 0.015150, acc.: 100.00%] [G loss: 4.920233]\n",
      "3583 [D loss: 0.078354, acc.: 94.44%] [G loss: 4.469844]\n",
      "3584 [D loss: 0.064796, acc.: 100.00%] [G loss: 5.609456]\n",
      "3585 [D loss: 0.066424, acc.: 100.00%] [G loss: 6.469188]\n",
      "3586 [D loss: 0.014732, acc.: 100.00%] [G loss: 7.527159]\n",
      "3587 [D loss: 0.239196, acc.: 94.44%] [G loss: 4.442850]\n",
      "3588 [D loss: 0.129064, acc.: 94.44%] [G loss: 5.608348]\n",
      "3589 [D loss: 0.038858, acc.: 100.00%] [G loss: 6.945449]\n",
      "3590 [D loss: 0.141803, acc.: 94.44%] [G loss: 6.266235]\n",
      "3591 [D loss: 0.600724, acc.: 83.33%] [G loss: 4.335402]\n",
      "3592 [D loss: 1.068367, acc.: 72.22%] [G loss: 6.506749]\n",
      "3593 [D loss: 0.007833, acc.: 100.00%] [G loss: 10.879644]\n",
      "3594 [D loss: 1.172531, acc.: 66.67%] [G loss: 3.413496]\n",
      "3595 [D loss: 0.685086, acc.: 77.78%] [G loss: 6.951632]\n",
      "3596 [D loss: 0.246581, acc.: 88.89%] [G loss: 7.038111]\n",
      "3597 [D loss: 1.073573, acc.: 61.11%] [G loss: 4.122733]\n",
      "3598 [D loss: 0.564778, acc.: 83.33%] [G loss: 6.487381]\n",
      "3599 [D loss: 0.161747, acc.: 94.44%] [G loss: 6.896813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 [D loss: 0.287620, acc.: 94.44%] [G loss: 5.240067]\n",
      "3601 [D loss: 0.142720, acc.: 94.44%] [G loss: 3.636727]\n",
      "3602 [D loss: 0.050007, acc.: 100.00%] [G loss: 5.615591]\n",
      "3603 [D loss: 0.119428, acc.: 94.44%] [G loss: 5.996723]\n",
      "3604 [D loss: 0.409406, acc.: 77.78%] [G loss: 3.504677]\n",
      "3605 [D loss: 0.018668, acc.: 100.00%] [G loss: 6.640640]\n",
      "3606 [D loss: 0.099701, acc.: 94.44%] [G loss: 6.650013]\n",
      "3607 [D loss: 0.036939, acc.: 100.00%] [G loss: 5.609071]\n",
      "3608 [D loss: 0.041957, acc.: 100.00%] [G loss: 7.818292]\n",
      "3609 [D loss: 0.065483, acc.: 100.00%] [G loss: 4.555265]\n",
      "3610 [D loss: 0.036985, acc.: 100.00%] [G loss: 5.518972]\n",
      "3611 [D loss: 0.039378, acc.: 100.00%] [G loss: 6.193387]\n",
      "3612 [D loss: 0.087140, acc.: 100.00%] [G loss: 4.707099]\n",
      "3613 [D loss: 0.320998, acc.: 83.33%] [G loss: 3.305872]\n",
      "3614 [D loss: 0.039524, acc.: 100.00%] [G loss: 5.026188]\n",
      "3615 [D loss: 0.179176, acc.: 94.44%] [G loss: 6.705750]\n",
      "3616 [D loss: 0.114573, acc.: 100.00%] [G loss: 6.657758]\n",
      "3617 [D loss: 0.037434, acc.: 100.00%] [G loss: 4.982194]\n",
      "3618 [D loss: 0.159637, acc.: 88.89%] [G loss: 4.549200]\n",
      "3619 [D loss: 0.060388, acc.: 100.00%] [G loss: 4.735158]\n",
      "3620 [D loss: 0.088293, acc.: 100.00%] [G loss: 4.706808]\n",
      "3621 [D loss: 0.013469, acc.: 100.00%] [G loss: 5.657225]\n",
      "3622 [D loss: 0.041201, acc.: 100.00%] [G loss: 5.099208]\n",
      "3623 [D loss: 0.221441, acc.: 88.89%] [G loss: 5.570626]\n",
      "3624 [D loss: 0.091924, acc.: 100.00%] [G loss: 6.244986]\n",
      "3625 [D loss: 0.071828, acc.: 100.00%] [G loss: 6.034945]\n",
      "3626 [D loss: 0.078042, acc.: 100.00%] [G loss: 5.653708]\n",
      "3627 [D loss: 0.072313, acc.: 100.00%] [G loss: 5.062845]\n",
      "3628 [D loss: 0.068395, acc.: 100.00%] [G loss: 4.517885]\n",
      "3629 [D loss: 0.232098, acc.: 94.44%] [G loss: 5.829465]\n",
      "3630 [D loss: 0.208883, acc.: 88.89%] [G loss: 5.514072]\n",
      "3631 [D loss: 0.106567, acc.: 94.44%] [G loss: 5.106809]\n",
      "3632 [D loss: 0.135942, acc.: 94.44%] [G loss: 4.310282]\n",
      "3633 [D loss: 0.057225, acc.: 94.44%] [G loss: 6.207792]\n",
      "3634 [D loss: 0.034672, acc.: 100.00%] [G loss: 6.442391]\n",
      "3635 [D loss: 0.156377, acc.: 88.89%] [G loss: 6.580111]\n",
      "3636 [D loss: 0.018777, acc.: 100.00%] [G loss: 6.107542]\n",
      "3637 [D loss: 0.095044, acc.: 94.44%] [G loss: 4.735650]\n",
      "3638 [D loss: 0.117032, acc.: 94.44%] [G loss: 5.265810]\n",
      "3639 [D loss: 0.133733, acc.: 94.44%] [G loss: 5.130077]\n",
      "3640 [D loss: 0.163853, acc.: 94.44%] [G loss: 7.030218]\n",
      "3641 [D loss: 0.297752, acc.: 83.33%] [G loss: 4.912735]\n",
      "3642 [D loss: 0.327550, acc.: 88.89%] [G loss: 4.085186]\n",
      "3643 [D loss: 0.066562, acc.: 100.00%] [G loss: 5.147051]\n",
      "3644 [D loss: 0.294981, acc.: 83.33%] [G loss: 5.156879]\n",
      "3645 [D loss: 0.033374, acc.: 100.00%] [G loss: 7.836360]\n",
      "3646 [D loss: 0.053301, acc.: 100.00%] [G loss: 6.426149]\n",
      "3647 [D loss: 0.151018, acc.: 88.89%] [G loss: 6.230140]\n",
      "3648 [D loss: 0.054385, acc.: 100.00%] [G loss: 5.669206]\n",
      "3649 [D loss: 0.019121, acc.: 100.00%] [G loss: 6.483292]\n",
      "3650 [D loss: 0.062691, acc.: 100.00%] [G loss: 5.265175]\n",
      "3651 [D loss: 0.136908, acc.: 94.44%] [G loss: 4.049330]\n",
      "3652 [D loss: 0.196757, acc.: 94.44%] [G loss: 7.152950]\n",
      "3653 [D loss: 0.016399, acc.: 100.00%] [G loss: 8.463743]\n",
      "3654 [D loss: 0.256804, acc.: 88.89%] [G loss: 8.131410]\n",
      "3655 [D loss: 0.153012, acc.: 94.44%] [G loss: 6.407826]\n",
      "3656 [D loss: 0.038129, acc.: 100.00%] [G loss: 5.432127]\n",
      "3657 [D loss: 0.040141, acc.: 100.00%] [G loss: 6.821581]\n",
      "3658 [D loss: 0.047308, acc.: 100.00%] [G loss: 5.628114]\n",
      "3659 [D loss: 0.122006, acc.: 88.89%] [G loss: 6.142325]\n",
      "3660 [D loss: 0.325501, acc.: 72.22%] [G loss: 5.991088]\n",
      "3661 [D loss: 0.150857, acc.: 88.89%] [G loss: 5.642835]\n",
      "3662 [D loss: 0.072311, acc.: 100.00%] [G loss: 4.570897]\n",
      "3663 [D loss: 0.039396, acc.: 100.00%] [G loss: 6.288872]\n",
      "3664 [D loss: 0.026448, acc.: 100.00%] [G loss: 4.994154]\n",
      "3665 [D loss: 0.041263, acc.: 100.00%] [G loss: 5.553194]\n",
      "3666 [D loss: 0.428623, acc.: 77.78%] [G loss: 5.079018]\n",
      "3667 [D loss: 0.112622, acc.: 100.00%] [G loss: 5.117520]\n",
      "3668 [D loss: 0.057067, acc.: 100.00%] [G loss: 4.758942]\n",
      "3669 [D loss: 0.098706, acc.: 100.00%] [G loss: 4.875305]\n",
      "3670 [D loss: 0.342923, acc.: 83.33%] [G loss: 7.609605]\n",
      "3671 [D loss: 0.054711, acc.: 100.00%] [G loss: 6.786794]\n",
      "3672 [D loss: 0.051558, acc.: 100.00%] [G loss: 9.954257]\n",
      "3673 [D loss: 0.154396, acc.: 88.89%] [G loss: 3.627950]\n",
      "3674 [D loss: 0.213179, acc.: 88.89%] [G loss: 7.391603]\n",
      "3675 [D loss: 0.037599, acc.: 100.00%] [G loss: 7.163637]\n",
      "3676 [D loss: 0.284453, acc.: 88.89%] [G loss: 6.334957]\n",
      "3677 [D loss: 0.071182, acc.: 100.00%] [G loss: 6.988628]\n",
      "3678 [D loss: 0.039882, acc.: 100.00%] [G loss: 9.036988]\n",
      "3679 [D loss: 0.107232, acc.: 94.44%] [G loss: 6.540207]\n",
      "3680 [D loss: 0.082646, acc.: 94.44%] [G loss: 6.153036]\n",
      "3681 [D loss: 0.049222, acc.: 100.00%] [G loss: 6.490449]\n",
      "3682 [D loss: 0.111609, acc.: 94.44%] [G loss: 8.229988]\n",
      "3683 [D loss: 0.038587, acc.: 100.00%] [G loss: 9.231391]\n",
      "3684 [D loss: 0.024950, acc.: 100.00%] [G loss: 6.364580]\n",
      "3685 [D loss: 0.018402, acc.: 100.00%] [G loss: 5.564859]\n",
      "3686 [D loss: 0.029817, acc.: 100.00%] [G loss: 7.292090]\n",
      "3687 [D loss: 0.009314, acc.: 100.00%] [G loss: 7.617414]\n",
      "3688 [D loss: 0.033183, acc.: 100.00%] [G loss: 6.835436]\n",
      "3689 [D loss: 0.016257, acc.: 100.00%] [G loss: 7.559890]\n",
      "3690 [D loss: 0.006630, acc.: 100.00%] [G loss: 5.419908]\n",
      "3691 [D loss: 0.031229, acc.: 100.00%] [G loss: 7.675128]\n",
      "3692 [D loss: 0.085604, acc.: 94.44%] [G loss: 6.992807]\n",
      "3693 [D loss: 0.018399, acc.: 100.00%] [G loss: 9.766384]\n",
      "3694 [D loss: 0.153575, acc.: 94.44%] [G loss: 9.321618]\n",
      "3695 [D loss: 0.022217, acc.: 100.00%] [G loss: 8.472245]\n",
      "3696 [D loss: 0.023396, acc.: 100.00%] [G loss: 7.155612]\n",
      "3697 [D loss: 0.022607, acc.: 100.00%] [G loss: 6.892809]\n",
      "3698 [D loss: 0.006371, acc.: 100.00%] [G loss: 6.687170]\n",
      "3699 [D loss: 0.069791, acc.: 100.00%] [G loss: 5.564969]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700 [D loss: 0.093021, acc.: 94.44%] [G loss: 6.408605]\n",
      "3701 [D loss: 0.040090, acc.: 100.00%] [G loss: 5.189846]\n",
      "3702 [D loss: 0.008117, acc.: 100.00%] [G loss: 8.242409]\n",
      "3703 [D loss: 0.031480, acc.: 100.00%] [G loss: 6.518232]\n",
      "3704 [D loss: 0.100068, acc.: 94.44%] [G loss: 6.597851]\n",
      "3705 [D loss: 0.011594, acc.: 100.00%] [G loss: 6.183017]\n",
      "3706 [D loss: 0.015434, acc.: 100.00%] [G loss: 6.562083]\n",
      "3707 [D loss: 0.013184, acc.: 100.00%] [G loss: 6.021299]\n",
      "3708 [D loss: 0.030235, acc.: 100.00%] [G loss: 4.615064]\n",
      "3709 [D loss: 0.071735, acc.: 94.44%] [G loss: 7.378020]\n",
      "3710 [D loss: 0.290400, acc.: 88.89%] [G loss: 6.433315]\n",
      "3711 [D loss: 0.024376, acc.: 100.00%] [G loss: 6.506208]\n",
      "3712 [D loss: 0.014771, acc.: 100.00%] [G loss: 8.322984]\n",
      "3713 [D loss: 0.383065, acc.: 83.33%] [G loss: 5.194494]\n",
      "3714 [D loss: 0.457004, acc.: 77.78%] [G loss: 5.043906]\n",
      "3715 [D loss: 0.008966, acc.: 100.00%] [G loss: 7.509247]\n",
      "3716 [D loss: 0.012521, acc.: 100.00%] [G loss: 9.000655]\n",
      "3717 [D loss: 0.026607, acc.: 100.00%] [G loss: 7.218796]\n",
      "3718 [D loss: 0.061021, acc.: 100.00%] [G loss: 7.518913]\n",
      "3719 [D loss: 0.006819, acc.: 100.00%] [G loss: 7.355371]\n",
      "3720 [D loss: 0.083372, acc.: 94.44%] [G loss: 7.051937]\n",
      "3721 [D loss: 0.009914, acc.: 100.00%] [G loss: 4.691310]\n",
      "3722 [D loss: 0.040365, acc.: 100.00%] [G loss: 4.675741]\n",
      "3723 [D loss: 0.058586, acc.: 100.00%] [G loss: 6.349683]\n",
      "3724 [D loss: 0.016703, acc.: 100.00%] [G loss: 6.739421]\n",
      "3725 [D loss: 0.047061, acc.: 100.00%] [G loss: 5.042469]\n",
      "3726 [D loss: 0.038083, acc.: 100.00%] [G loss: 6.909056]\n",
      "3727 [D loss: 0.101978, acc.: 94.44%] [G loss: 6.789037]\n",
      "3728 [D loss: 0.092482, acc.: 100.00%] [G loss: 6.506114]\n",
      "3729 [D loss: 0.012487, acc.: 100.00%] [G loss: 7.698079]\n",
      "3730 [D loss: 0.145136, acc.: 94.44%] [G loss: 6.215744]\n",
      "3731 [D loss: 0.014324, acc.: 100.00%] [G loss: 7.104168]\n",
      "3732 [D loss: 0.100703, acc.: 100.00%] [G loss: 5.518857]\n",
      "3733 [D loss: 0.050039, acc.: 100.00%] [G loss: 4.006118]\n",
      "3734 [D loss: 0.013542, acc.: 100.00%] [G loss: 6.552851]\n",
      "3735 [D loss: 0.051351, acc.: 100.00%] [G loss: 7.293652]\n",
      "3736 [D loss: 0.035209, acc.: 100.00%] [G loss: 5.692258]\n",
      "3737 [D loss: 0.014804, acc.: 100.00%] [G loss: 5.069863]\n",
      "3738 [D loss: 0.012749, acc.: 100.00%] [G loss: 5.421050]\n",
      "3739 [D loss: 0.066388, acc.: 94.44%] [G loss: 6.442893]\n",
      "3740 [D loss: 0.019212, acc.: 100.00%] [G loss: 5.488070]\n",
      "3741 [D loss: 0.129284, acc.: 94.44%] [G loss: 6.247243]\n",
      "3742 [D loss: 0.074138, acc.: 94.44%] [G loss: 3.487310]\n",
      "3743 [D loss: 0.414890, acc.: 83.33%] [G loss: 5.361563]\n",
      "3744 [D loss: 0.095264, acc.: 94.44%] [G loss: 8.125943]\n",
      "3745 [D loss: 0.168356, acc.: 94.44%] [G loss: 7.378345]\n",
      "3746 [D loss: 0.159519, acc.: 94.44%] [G loss: 11.307842]\n",
      "3747 [D loss: 0.367983, acc.: 88.89%] [G loss: 4.798892]\n",
      "3748 [D loss: 0.003218, acc.: 100.00%] [G loss: 7.774090]\n",
      "3749 [D loss: 0.018311, acc.: 100.00%] [G loss: 5.800145]\n",
      "3750 [D loss: 0.006198, acc.: 100.00%] [G loss: 7.315808]\n",
      "3751 [D loss: 0.004182, acc.: 100.00%] [G loss: 8.580235]\n",
      "3752 [D loss: 0.038936, acc.: 100.00%] [G loss: 4.326693]\n",
      "3753 [D loss: 0.062372, acc.: 100.00%] [G loss: 4.942568]\n",
      "3754 [D loss: 0.248392, acc.: 94.44%] [G loss: 6.349663]\n",
      "3755 [D loss: 0.040013, acc.: 100.00%] [G loss: 5.544530]\n",
      "3756 [D loss: 0.067046, acc.: 100.00%] [G loss: 6.402998]\n",
      "3757 [D loss: 0.004425, acc.: 100.00%] [G loss: 7.411675]\n",
      "3758 [D loss: 0.045053, acc.: 100.00%] [G loss: 5.726367]\n",
      "3759 [D loss: 0.067440, acc.: 94.44%] [G loss: 6.723866]\n",
      "3760 [D loss: 0.017823, acc.: 100.00%] [G loss: 6.772262]\n",
      "3761 [D loss: 0.107290, acc.: 94.44%] [G loss: 6.392889]\n",
      "3762 [D loss: 0.028496, acc.: 100.00%] [G loss: 5.915085]\n",
      "3763 [D loss: 0.120492, acc.: 94.44%] [G loss: 5.144817]\n",
      "3764 [D loss: 0.023392, acc.: 100.00%] [G loss: 6.873221]\n",
      "3765 [D loss: 0.088781, acc.: 94.44%] [G loss: 4.486708]\n",
      "3766 [D loss: 0.160887, acc.: 94.44%] [G loss: 5.758377]\n",
      "3767 [D loss: 0.440190, acc.: 77.78%] [G loss: 5.479819]\n",
      "3768 [D loss: 0.252133, acc.: 94.44%] [G loss: 5.319253]\n",
      "3769 [D loss: 0.069808, acc.: 94.44%] [G loss: 5.157118]\n",
      "3770 [D loss: 0.096500, acc.: 100.00%] [G loss: 6.566884]\n",
      "3771 [D loss: 0.044815, acc.: 100.00%] [G loss: 6.968728]\n",
      "3772 [D loss: 0.231844, acc.: 83.33%] [G loss: 3.699379]\n",
      "3773 [D loss: 0.067747, acc.: 100.00%] [G loss: 4.656521]\n",
      "3774 [D loss: 0.223798, acc.: 83.33%] [G loss: 6.447500]\n",
      "3775 [D loss: 0.133554, acc.: 94.44%] [G loss: 4.787631]\n",
      "3776 [D loss: 0.087622, acc.: 94.44%] [G loss: 7.831158]\n",
      "3777 [D loss: 0.041446, acc.: 100.00%] [G loss: 7.709547]\n",
      "3778 [D loss: 0.462647, acc.: 77.78%] [G loss: 6.025222]\n",
      "3779 [D loss: 0.016840, acc.: 100.00%] [G loss: 7.221989]\n",
      "3780 [D loss: 0.014601, acc.: 100.00%] [G loss: 5.871930]\n",
      "3781 [D loss: 0.378380, acc.: 83.33%] [G loss: 4.319366]\n",
      "3782 [D loss: 0.359850, acc.: 88.89%] [G loss: 5.558284]\n",
      "3783 [D loss: 0.034135, acc.: 100.00%] [G loss: 7.907077]\n",
      "3784 [D loss: 0.108519, acc.: 94.44%] [G loss: 6.138490]\n",
      "3785 [D loss: 0.020765, acc.: 100.00%] [G loss: 7.469818]\n",
      "3786 [D loss: 0.231018, acc.: 88.89%] [G loss: 3.999299]\n",
      "3787 [D loss: 0.356798, acc.: 77.78%] [G loss: 7.237244]\n",
      "3788 [D loss: 0.247618, acc.: 88.89%] [G loss: 6.599898]\n",
      "3789 [D loss: 0.045299, acc.: 100.00%] [G loss: 8.397462]\n",
      "3790 [D loss: 0.218759, acc.: 83.33%] [G loss: 5.823245]\n",
      "3791 [D loss: 0.095070, acc.: 94.44%] [G loss: 5.855353]\n",
      "3792 [D loss: 0.035151, acc.: 100.00%] [G loss: 6.954874]\n",
      "3793 [D loss: 0.014082, acc.: 100.00%] [G loss: 8.399601]\n",
      "3794 [D loss: 0.037101, acc.: 100.00%] [G loss: 5.934893]\n",
      "3795 [D loss: 0.144165, acc.: 94.44%] [G loss: 7.918038]\n",
      "3796 [D loss: 0.070004, acc.: 94.44%] [G loss: 7.766784]\n",
      "3797 [D loss: 0.022105, acc.: 100.00%] [G loss: 7.137301]\n",
      "3798 [D loss: 0.018488, acc.: 100.00%] [G loss: 6.621405]\n",
      "3799 [D loss: 0.162091, acc.: 94.44%] [G loss: 5.348320]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3800 [D loss: 0.105279, acc.: 100.00%] [G loss: 5.469757]\n",
      "3801 [D loss: 0.045306, acc.: 100.00%] [G loss: 4.698183]\n",
      "3802 [D loss: 0.093203, acc.: 100.00%] [G loss: 5.356098]\n",
      "3803 [D loss: 0.113664, acc.: 94.44%] [G loss: 5.946520]\n",
      "3804 [D loss: 0.205172, acc.: 94.44%] [G loss: 8.533235]\n",
      "3805 [D loss: 0.020439, acc.: 100.00%] [G loss: 4.512969]\n",
      "3806 [D loss: 0.097741, acc.: 100.00%] [G loss: 4.750212]\n",
      "3807 [D loss: 0.056698, acc.: 94.44%] [G loss: 8.873443]\n",
      "3808 [D loss: 0.106730, acc.: 94.44%] [G loss: 5.508241]\n",
      "3809 [D loss: 0.009854, acc.: 100.00%] [G loss: 4.926452]\n",
      "3810 [D loss: 0.079036, acc.: 100.00%] [G loss: 5.724004]\n",
      "3811 [D loss: 0.014481, acc.: 100.00%] [G loss: 5.774694]\n",
      "3812 [D loss: 0.014202, acc.: 100.00%] [G loss: 5.352575]\n",
      "3813 [D loss: 0.018425, acc.: 100.00%] [G loss: 4.157133]\n",
      "3814 [D loss: 0.023661, acc.: 100.00%] [G loss: 6.752897]\n",
      "3815 [D loss: 0.028696, acc.: 100.00%] [G loss: 3.541230]\n",
      "3816 [D loss: 0.015560, acc.: 100.00%] [G loss: 6.293131]\n",
      "3817 [D loss: 0.015167, acc.: 100.00%] [G loss: 5.023708]\n",
      "3818 [D loss: 0.070449, acc.: 100.00%] [G loss: 4.876448]\n",
      "3819 [D loss: 0.244601, acc.: 88.89%] [G loss: 6.994208]\n",
      "3820 [D loss: 0.168349, acc.: 94.44%] [G loss: 7.446629]\n",
      "3821 [D loss: 0.154004, acc.: 88.89%] [G loss: 5.668357]\n",
      "3822 [D loss: 0.045001, acc.: 100.00%] [G loss: 4.742041]\n",
      "3823 [D loss: 0.037994, acc.: 100.00%] [G loss: 5.426451]\n",
      "3824 [D loss: 0.012189, acc.: 100.00%] [G loss: 6.248659]\n",
      "3825 [D loss: 0.151337, acc.: 94.44%] [G loss: 6.461612]\n",
      "3826 [D loss: 0.097805, acc.: 94.44%] [G loss: 7.212346]\n",
      "3827 [D loss: 0.038887, acc.: 100.00%] [G loss: 8.271677]\n",
      "3828 [D loss: 0.042493, acc.: 100.00%] [G loss: 6.174369]\n",
      "3829 [D loss: 0.068228, acc.: 94.44%] [G loss: 7.360562]\n",
      "3830 [D loss: 0.091651, acc.: 94.44%] [G loss: 6.555730]\n",
      "3831 [D loss: 0.023413, acc.: 100.00%] [G loss: 6.790349]\n",
      "3832 [D loss: 0.055176, acc.: 100.00%] [G loss: 4.015269]\n",
      "3833 [D loss: 0.309864, acc.: 83.33%] [G loss: 6.165341]\n",
      "3834 [D loss: 0.023004, acc.: 100.00%] [G loss: 7.802121]\n",
      "3835 [D loss: 0.024007, acc.: 100.00%] [G loss: 6.091238]\n",
      "3836 [D loss: 0.051609, acc.: 100.00%] [G loss: 6.141073]\n",
      "3837 [D loss: 0.073631, acc.: 100.00%] [G loss: 5.695091]\n",
      "3838 [D loss: 0.062592, acc.: 100.00%] [G loss: 3.222748]\n",
      "3839 [D loss: 0.002717, acc.: 100.00%] [G loss: 7.520134]\n",
      "3840 [D loss: 0.032691, acc.: 100.00%] [G loss: 6.843260]\n",
      "3841 [D loss: 0.096747, acc.: 100.00%] [G loss: 5.421709]\n",
      "3842 [D loss: 0.150533, acc.: 94.44%] [G loss: 5.545626]\n",
      "3843 [D loss: 0.004692, acc.: 100.00%] [G loss: 10.232960]\n",
      "3844 [D loss: 0.046243, acc.: 100.00%] [G loss: 7.745764]\n",
      "3845 [D loss: 0.101568, acc.: 94.44%] [G loss: 5.750135]\n",
      "3846 [D loss: 0.016449, acc.: 100.00%] [G loss: 6.885873]\n",
      "3847 [D loss: 0.132315, acc.: 94.44%] [G loss: 2.701257]\n",
      "3848 [D loss: 0.015255, acc.: 100.00%] [G loss: 5.336306]\n",
      "3849 [D loss: 0.047006, acc.: 100.00%] [G loss: 4.550888]\n",
      "3850 [D loss: 0.063222, acc.: 100.00%] [G loss: 4.684992]\n",
      "3851 [D loss: 0.115114, acc.: 94.44%] [G loss: 5.977962]\n",
      "3852 [D loss: 0.044999, acc.: 100.00%] [G loss: 6.211133]\n",
      "3853 [D loss: 0.133354, acc.: 94.44%] [G loss: 5.234079]\n",
      "3854 [D loss: 0.062872, acc.: 94.44%] [G loss: 6.003917]\n",
      "3855 [D loss: 0.077253, acc.: 100.00%] [G loss: 6.973231]\n",
      "3856 [D loss: 0.052904, acc.: 100.00%] [G loss: 5.845955]\n",
      "3857 [D loss: 0.040504, acc.: 100.00%] [G loss: 5.934456]\n",
      "3858 [D loss: 0.157185, acc.: 94.44%] [G loss: 5.710812]\n",
      "3859 [D loss: 0.084149, acc.: 94.44%] [G loss: 5.574170]\n",
      "3860 [D loss: 0.018174, acc.: 100.00%] [G loss: 6.508256]\n",
      "3861 [D loss: 0.043479, acc.: 100.00%] [G loss: 5.329774]\n",
      "3862 [D loss: 0.092295, acc.: 94.44%] [G loss: 6.708593]\n",
      "3863 [D loss: 0.014055, acc.: 100.00%] [G loss: 6.819742]\n",
      "3864 [D loss: 0.023463, acc.: 100.00%] [G loss: 5.586287]\n",
      "3865 [D loss: 0.026096, acc.: 100.00%] [G loss: 6.615186]\n",
      "3866 [D loss: 0.079026, acc.: 100.00%] [G loss: 4.799131]\n",
      "3867 [D loss: 0.051951, acc.: 100.00%] [G loss: 5.165474]\n",
      "3868 [D loss: 0.018590, acc.: 100.00%] [G loss: 5.024965]\n",
      "3869 [D loss: 0.163940, acc.: 94.44%] [G loss: 4.983956]\n",
      "3870 [D loss: 0.127807, acc.: 94.44%] [G loss: 3.946611]\n",
      "3871 [D loss: 0.376020, acc.: 77.78%] [G loss: 5.914116]\n",
      "3872 [D loss: 0.054184, acc.: 100.00%] [G loss: 6.588142]\n",
      "3873 [D loss: 0.194233, acc.: 94.44%] [G loss: 4.895446]\n",
      "3874 [D loss: 0.332396, acc.: 77.78%] [G loss: 5.960826]\n",
      "3875 [D loss: 0.102163, acc.: 94.44%] [G loss: 7.515339]\n",
      "3876 [D loss: 0.010208, acc.: 100.00%] [G loss: 8.075016]\n",
      "3877 [D loss: 0.247575, acc.: 94.44%] [G loss: 4.668524]\n",
      "3878 [D loss: 0.052718, acc.: 100.00%] [G loss: 4.645699]\n",
      "3879 [D loss: 0.076686, acc.: 94.44%] [G loss: 5.371400]\n",
      "3880 [D loss: 0.110265, acc.: 94.44%] [G loss: 4.401838]\n",
      "3881 [D loss: 0.022137, acc.: 100.00%] [G loss: 7.580265]\n",
      "3882 [D loss: 0.008556, acc.: 100.00%] [G loss: 7.838674]\n",
      "3883 [D loss: 0.087706, acc.: 94.44%] [G loss: 5.129814]\n",
      "3884 [D loss: 0.029946, acc.: 100.00%] [G loss: 6.396007]\n",
      "3885 [D loss: 0.087421, acc.: 100.00%] [G loss: 3.930363]\n",
      "3886 [D loss: 0.029360, acc.: 100.00%] [G loss: 5.121369]\n",
      "3887 [D loss: 0.015851, acc.: 100.00%] [G loss: 5.042909]\n",
      "3888 [D loss: 0.033989, acc.: 100.00%] [G loss: 7.272703]\n",
      "3889 [D loss: 0.008667, acc.: 100.00%] [G loss: 8.430538]\n",
      "3890 [D loss: 0.045552, acc.: 100.00%] [G loss: 5.811686]\n",
      "3891 [D loss: 0.041803, acc.: 100.00%] [G loss: 7.502649]\n",
      "3892 [D loss: 0.016829, acc.: 100.00%] [G loss: 5.250896]\n",
      "3893 [D loss: 0.021284, acc.: 100.00%] [G loss: 9.346396]\n",
      "3894 [D loss: 0.148381, acc.: 94.44%] [G loss: 4.417685]\n",
      "3895 [D loss: 0.090139, acc.: 94.44%] [G loss: 4.813733]\n",
      "3896 [D loss: 0.024861, acc.: 100.00%] [G loss: 6.997167]\n",
      "3897 [D loss: 0.114498, acc.: 94.44%] [G loss: 7.035889]\n",
      "3898 [D loss: 0.045096, acc.: 100.00%] [G loss: 7.407809]\n",
      "3899 [D loss: 0.032777, acc.: 100.00%] [G loss: 7.477325]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900 [D loss: 0.148987, acc.: 94.44%] [G loss: 6.170576]\n",
      "3901 [D loss: 0.055128, acc.: 100.00%] [G loss: 6.877337]\n",
      "3902 [D loss: 0.066059, acc.: 100.00%] [G loss: 4.192609]\n",
      "3903 [D loss: 0.212523, acc.: 83.33%] [G loss: 5.690176]\n",
      "3904 [D loss: 0.055929, acc.: 100.00%] [G loss: 6.709536]\n",
      "3905 [D loss: 0.226866, acc.: 83.33%] [G loss: 6.567162]\n",
      "3906 [D loss: 0.059509, acc.: 100.00%] [G loss: 8.851903]\n",
      "3907 [D loss: 0.341071, acc.: 72.22%] [G loss: 4.190863]\n",
      "3908 [D loss: 0.300262, acc.: 83.33%] [G loss: 4.623854]\n",
      "3909 [D loss: 0.007760, acc.: 100.00%] [G loss: 7.025997]\n",
      "3910 [D loss: 0.263918, acc.: 88.89%] [G loss: 5.775872]\n",
      "3911 [D loss: 0.031799, acc.: 100.00%] [G loss: 5.205369]\n",
      "3912 [D loss: 0.266388, acc.: 83.33%] [G loss: 5.290163]\n",
      "3913 [D loss: 0.049688, acc.: 94.44%] [G loss: 5.465803]\n",
      "3914 [D loss: 0.076621, acc.: 94.44%] [G loss: 7.740480]\n",
      "3915 [D loss: 0.020172, acc.: 100.00%] [G loss: 6.049012]\n",
      "3916 [D loss: 0.072126, acc.: 94.44%] [G loss: 8.797366]\n",
      "3917 [D loss: 0.004626, acc.: 100.00%] [G loss: 7.609195]\n",
      "3918 [D loss: 0.062628, acc.: 94.44%] [G loss: 8.900558]\n",
      "3919 [D loss: 0.031463, acc.: 100.00%] [G loss: 8.439218]\n",
      "3920 [D loss: 0.015283, acc.: 100.00%] [G loss: 5.470914]\n",
      "3921 [D loss: 0.014441, acc.: 100.00%] [G loss: 7.892317]\n",
      "3922 [D loss: 0.022526, acc.: 100.00%] [G loss: 6.777212]\n",
      "3923 [D loss: 0.105550, acc.: 94.44%] [G loss: 7.431231]\n",
      "3924 [D loss: 0.231955, acc.: 94.44%] [G loss: 6.187280]\n",
      "3925 [D loss: 0.041112, acc.: 100.00%] [G loss: 10.912576]\n",
      "3926 [D loss: 0.045531, acc.: 100.00%] [G loss: 7.183004]\n",
      "3927 [D loss: 0.010810, acc.: 100.00%] [G loss: 5.328725]\n",
      "3928 [D loss: 0.042319, acc.: 100.00%] [G loss: 6.482044]\n",
      "3929 [D loss: 0.047721, acc.: 100.00%] [G loss: 8.179708]\n",
      "3930 [D loss: 0.102059, acc.: 94.44%] [G loss: 5.796279]\n",
      "3931 [D loss: 0.022035, acc.: 100.00%] [G loss: 8.208314]\n",
      "3932 [D loss: 0.151891, acc.: 88.89%] [G loss: 5.157610]\n",
      "3933 [D loss: 0.010111, acc.: 100.00%] [G loss: 7.351230]\n",
      "3934 [D loss: 0.045082, acc.: 100.00%] [G loss: 6.276606]\n",
      "3935 [D loss: 0.007154, acc.: 100.00%] [G loss: 7.017933]\n",
      "3936 [D loss: 0.046575, acc.: 100.00%] [G loss: 5.704002]\n",
      "3937 [D loss: 0.108500, acc.: 94.44%] [G loss: 7.070375]\n",
      "3938 [D loss: 0.010752, acc.: 100.00%] [G loss: 10.529138]\n",
      "3939 [D loss: 0.012035, acc.: 100.00%] [G loss: 4.911787]\n",
      "3940 [D loss: 0.065544, acc.: 100.00%] [G loss: 6.791545]\n",
      "3941 [D loss: 0.123214, acc.: 94.44%] [G loss: 5.427524]\n",
      "3942 [D loss: 0.020718, acc.: 100.00%] [G loss: 6.420482]\n",
      "3943 [D loss: 0.007090, acc.: 100.00%] [G loss: 7.850786]\n",
      "3944 [D loss: 0.060643, acc.: 100.00%] [G loss: 6.015203]\n",
      "3945 [D loss: 0.405050, acc.: 94.44%] [G loss: 4.952572]\n",
      "3946 [D loss: 0.244348, acc.: 88.89%] [G loss: 6.889746]\n",
      "3947 [D loss: 0.009401, acc.: 100.00%] [G loss: 7.206672]\n",
      "3948 [D loss: 0.256367, acc.: 88.89%] [G loss: 6.407897]\n",
      "3949 [D loss: 0.004359, acc.: 100.00%] [G loss: 6.550473]\n",
      "3950 [D loss: 0.053347, acc.: 100.00%] [G loss: 8.410517]\n",
      "3951 [D loss: 0.014391, acc.: 100.00%] [G loss: 7.446030]\n",
      "3952 [D loss: 0.044084, acc.: 100.00%] [G loss: 8.091774]\n",
      "3953 [D loss: 0.061157, acc.: 100.00%] [G loss: 7.083869]\n",
      "3954 [D loss: 0.046137, acc.: 100.00%] [G loss: 8.029563]\n",
      "3955 [D loss: 0.159829, acc.: 88.89%] [G loss: 6.450902]\n",
      "3956 [D loss: 0.260270, acc.: 94.44%] [G loss: 7.007346]\n",
      "3957 [D loss: 0.033097, acc.: 100.00%] [G loss: 7.776190]\n",
      "3958 [D loss: 0.030585, acc.: 100.00%] [G loss: 6.987612]\n",
      "3959 [D loss: 0.376797, acc.: 88.89%] [G loss: 2.459757]\n",
      "3960 [D loss: 0.227559, acc.: 83.33%] [G loss: 6.725222]\n",
      "3961 [D loss: 0.250603, acc.: 88.89%] [G loss: 6.508940]\n",
      "3962 [D loss: 0.124665, acc.: 100.00%] [G loss: 5.707397]\n",
      "3963 [D loss: 0.066107, acc.: 100.00%] [G loss: 6.402059]\n",
      "3964 [D loss: 0.019423, acc.: 100.00%] [G loss: 6.728852]\n",
      "3965 [D loss: 0.073977, acc.: 94.44%] [G loss: 8.896789]\n",
      "3966 [D loss: 0.192478, acc.: 94.44%] [G loss: 5.659521]\n",
      "3967 [D loss: 0.129754, acc.: 94.44%] [G loss: 6.865563]\n",
      "3968 [D loss: 0.027846, acc.: 100.00%] [G loss: 7.164571]\n",
      "3969 [D loss: 0.119910, acc.: 94.44%] [G loss: 9.098592]\n",
      "3970 [D loss: 0.041993, acc.: 100.00%] [G loss: 7.180037]\n",
      "3971 [D loss: 0.039222, acc.: 100.00%] [G loss: 6.860771]\n",
      "3972 [D loss: 0.006744, acc.: 100.00%] [G loss: 9.033970]\n",
      "3973 [D loss: 0.009147, acc.: 100.00%] [G loss: 7.503019]\n",
      "3974 [D loss: 0.051266, acc.: 100.00%] [G loss: 7.271773]\n",
      "3975 [D loss: 0.016840, acc.: 100.00%] [G loss: 6.263625]\n",
      "3976 [D loss: 0.063812, acc.: 100.00%] [G loss: 4.608984]\n",
      "3977 [D loss: 0.023262, acc.: 100.00%] [G loss: 6.429633]\n",
      "3978 [D loss: 0.006042, acc.: 100.00%] [G loss: 6.049307]\n",
      "3979 [D loss: 0.007876, acc.: 100.00%] [G loss: 6.723596]\n",
      "3980 [D loss: 0.005251, acc.: 100.00%] [G loss: 5.477501]\n",
      "3981 [D loss: 0.029401, acc.: 100.00%] [G loss: 6.139811]\n",
      "3982 [D loss: 0.024827, acc.: 100.00%] [G loss: 6.378473]\n",
      "3983 [D loss: 0.078528, acc.: 94.44%] [G loss: 6.212770]\n",
      "3984 [D loss: 0.009882, acc.: 100.00%] [G loss: 7.418741]\n",
      "3985 [D loss: 0.062698, acc.: 94.44%] [G loss: 7.309031]\n",
      "3986 [D loss: 0.005559, acc.: 100.00%] [G loss: 6.248494]\n",
      "3987 [D loss: 0.033095, acc.: 100.00%] [G loss: 5.134198]\n",
      "3988 [D loss: 0.048361, acc.: 100.00%] [G loss: 5.307013]\n",
      "3989 [D loss: 0.006840, acc.: 100.00%] [G loss: 6.158806]\n",
      "3990 [D loss: 0.115253, acc.: 94.44%] [G loss: 6.869284]\n",
      "3991 [D loss: 0.041092, acc.: 100.00%] [G loss: 5.254216]\n",
      "3992 [D loss: 0.023905, acc.: 100.00%] [G loss: 6.421966]\n",
      "3993 [D loss: 0.009210, acc.: 100.00%] [G loss: 6.200528]\n",
      "3994 [D loss: 0.061829, acc.: 100.00%] [G loss: 5.663875]\n",
      "3995 [D loss: 0.023208, acc.: 100.00%] [G loss: 6.690026]\n",
      "3996 [D loss: 0.038692, acc.: 100.00%] [G loss: 9.759638]\n",
      "3997 [D loss: 0.012592, acc.: 100.00%] [G loss: 7.168116]\n",
      "3998 [D loss: 0.010390, acc.: 100.00%] [G loss: 6.488731]\n",
      "3999 [D loss: 0.024735, acc.: 100.00%] [G loss: 5.824591]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 [D loss: 0.138695, acc.: 88.89%] [G loss: 5.306630]\n",
      "4001 [D loss: 0.044130, acc.: 100.00%] [G loss: 8.066011]\n",
      "4002 [D loss: 0.043709, acc.: 100.00%] [G loss: 6.306827]\n",
      "4003 [D loss: 0.032490, acc.: 100.00%] [G loss: 6.038203]\n",
      "4004 [D loss: 0.186920, acc.: 88.89%] [G loss: 5.497344]\n",
      "4005 [D loss: 0.049765, acc.: 94.44%] [G loss: 7.565796]\n",
      "4006 [D loss: 0.448594, acc.: 66.67%] [G loss: 4.768034]\n",
      "4007 [D loss: 0.014118, acc.: 100.00%] [G loss: 3.734018]\n",
      "4008 [D loss: 0.070638, acc.: 94.44%] [G loss: 5.107704]\n",
      "4009 [D loss: 0.042987, acc.: 100.00%] [G loss: 5.957022]\n",
      "4010 [D loss: 0.111556, acc.: 94.44%] [G loss: 6.035875]\n",
      "4011 [D loss: 0.109823, acc.: 94.44%] [G loss: 5.867850]\n",
      "4012 [D loss: 0.025111, acc.: 100.00%] [G loss: 5.056747]\n",
      "4013 [D loss: 0.167235, acc.: 88.89%] [G loss: 6.409474]\n",
      "4014 [D loss: 0.264701, acc.: 94.44%] [G loss: 4.141423]\n",
      "4015 [D loss: 0.069131, acc.: 100.00%] [G loss: 4.069417]\n",
      "4016 [D loss: 0.089460, acc.: 100.00%] [G loss: 4.399414]\n",
      "4017 [D loss: 0.118292, acc.: 94.44%] [G loss: 6.284716]\n",
      "4018 [D loss: 0.069826, acc.: 94.44%] [G loss: 6.996936]\n",
      "4019 [D loss: 0.278048, acc.: 88.89%] [G loss: 6.523418]\n",
      "4020 [D loss: 0.050003, acc.: 100.00%] [G loss: 4.641348]\n",
      "4021 [D loss: 0.057199, acc.: 100.00%] [G loss: 6.430247]\n",
      "4022 [D loss: 0.055543, acc.: 100.00%] [G loss: 5.826740]\n",
      "4023 [D loss: 0.201490, acc.: 83.33%] [G loss: 6.944437]\n",
      "4024 [D loss: 0.006181, acc.: 100.00%] [G loss: 8.337973]\n",
      "4025 [D loss: 0.077522, acc.: 94.44%] [G loss: 7.492903]\n",
      "4026 [D loss: 0.097014, acc.: 94.44%] [G loss: 6.608489]\n",
      "4027 [D loss: 0.028896, acc.: 100.00%] [G loss: 6.002557]\n",
      "4028 [D loss: 0.045870, acc.: 100.00%] [G loss: 5.050543]\n",
      "4029 [D loss: 0.105573, acc.: 94.44%] [G loss: 6.122125]\n",
      "4030 [D loss: 0.043670, acc.: 100.00%] [G loss: 9.243773]\n",
      "4031 [D loss: 0.016269, acc.: 100.00%] [G loss: 9.467614]\n",
      "4032 [D loss: 0.014692, acc.: 100.00%] [G loss: 5.896666]\n",
      "4033 [D loss: 0.159201, acc.: 94.44%] [G loss: 4.408195]\n",
      "4034 [D loss: 0.217622, acc.: 94.44%] [G loss: 6.224870]\n",
      "4035 [D loss: 0.060101, acc.: 94.44%] [G loss: 5.328356]\n",
      "4036 [D loss: 0.019599, acc.: 100.00%] [G loss: 6.804529]\n",
      "4037 [D loss: 0.377314, acc.: 72.22%] [G loss: 6.372438]\n",
      "4038 [D loss: 0.156622, acc.: 88.89%] [G loss: 6.713929]\n",
      "4039 [D loss: 0.044013, acc.: 100.00%] [G loss: 7.754903]\n",
      "4040 [D loss: 0.111412, acc.: 94.44%] [G loss: 6.159091]\n",
      "4041 [D loss: 0.052186, acc.: 100.00%] [G loss: 6.334047]\n",
      "4042 [D loss: 0.092381, acc.: 94.44%] [G loss: 5.918032]\n",
      "4043 [D loss: 0.026709, acc.: 100.00%] [G loss: 7.269007]\n",
      "4044 [D loss: 0.016540, acc.: 100.00%] [G loss: 7.896895]\n",
      "4045 [D loss: 0.063072, acc.: 100.00%] [G loss: 6.948968]\n",
      "4046 [D loss: 0.014918, acc.: 100.00%] [G loss: 4.912509]\n",
      "4047 [D loss: 0.157305, acc.: 94.44%] [G loss: 6.603144]\n",
      "4048 [D loss: 0.015992, acc.: 100.00%] [G loss: 6.346590]\n",
      "4049 [D loss: 0.132982, acc.: 94.44%] [G loss: 4.805602]\n",
      "4050 [D loss: 0.087642, acc.: 100.00%] [G loss: 5.594004]\n",
      "4051 [D loss: 0.238892, acc.: 94.44%] [G loss: 6.155233]\n",
      "4052 [D loss: 0.017908, acc.: 100.00%] [G loss: 7.519393]\n",
      "4053 [D loss: 0.163289, acc.: 88.89%] [G loss: 4.848186]\n",
      "4054 [D loss: 0.124506, acc.: 88.89%] [G loss: 6.338648]\n",
      "4055 [D loss: 0.047084, acc.: 100.00%] [G loss: 7.324072]\n",
      "4056 [D loss: 0.052068, acc.: 100.00%] [G loss: 9.786860]\n",
      "4057 [D loss: 0.072836, acc.: 94.44%] [G loss: 6.648691]\n",
      "4058 [D loss: 0.023922, acc.: 100.00%] [G loss: 6.034490]\n",
      "4059 [D loss: 0.125462, acc.: 94.44%] [G loss: 5.010214]\n",
      "4060 [D loss: 0.230368, acc.: 94.44%] [G loss: 5.595105]\n",
      "4061 [D loss: 0.003015, acc.: 100.00%] [G loss: 8.297843]\n",
      "4062 [D loss: 0.021424, acc.: 100.00%] [G loss: 6.035555]\n",
      "4063 [D loss: 0.040161, acc.: 100.00%] [G loss: 5.042747]\n",
      "4064 [D loss: 0.100723, acc.: 94.44%] [G loss: 4.739832]\n",
      "4065 [D loss: 0.048814, acc.: 100.00%] [G loss: 4.603189]\n",
      "4066 [D loss: 0.096089, acc.: 100.00%] [G loss: 5.104903]\n",
      "4067 [D loss: 0.029806, acc.: 100.00%] [G loss: 5.404710]\n",
      "4068 [D loss: 0.033282, acc.: 100.00%] [G loss: 6.541724]\n",
      "4069 [D loss: 0.015603, acc.: 100.00%] [G loss: 7.650777]\n",
      "4070 [D loss: 0.009075, acc.: 100.00%] [G loss: 5.668224]\n",
      "4071 [D loss: 0.086204, acc.: 94.44%] [G loss: 6.356737]\n",
      "4072 [D loss: 0.129144, acc.: 100.00%] [G loss: 5.264559]\n",
      "4073 [D loss: 0.009843, acc.: 100.00%] [G loss: 5.214436]\n",
      "4074 [D loss: 0.229619, acc.: 88.89%] [G loss: 7.025511]\n",
      "4075 [D loss: 0.026393, acc.: 100.00%] [G loss: 6.753991]\n",
      "4076 [D loss: 0.262684, acc.: 94.44%] [G loss: 4.367483]\n",
      "4077 [D loss: 0.706199, acc.: 61.11%] [G loss: 4.979853]\n",
      "4078 [D loss: 0.016215, acc.: 100.00%] [G loss: 7.210666]\n",
      "4079 [D loss: 1.577250, acc.: 44.44%] [G loss: 7.075701]\n",
      "4080 [D loss: 0.091349, acc.: 94.44%] [G loss: 9.086970]\n",
      "4081 [D loss: 0.446404, acc.: 77.78%] [G loss: 6.678937]\n",
      "4082 [D loss: 0.163071, acc.: 88.89%] [G loss: 5.414564]\n",
      "4083 [D loss: 0.031938, acc.: 100.00%] [G loss: 5.450266]\n",
      "4084 [D loss: 0.046407, acc.: 100.00%] [G loss: 6.287020]\n",
      "4085 [D loss: 0.015240, acc.: 100.00%] [G loss: 5.660021]\n",
      "4086 [D loss: 0.170929, acc.: 94.44%] [G loss: 5.732935]\n",
      "4087 [D loss: 0.066561, acc.: 100.00%] [G loss: 6.857794]\n",
      "4088 [D loss: 0.000736, acc.: 100.00%] [G loss: 8.823421]\n",
      "4089 [D loss: 0.483728, acc.: 77.78%] [G loss: 9.509377]\n",
      "4090 [D loss: 0.058987, acc.: 94.44%] [G loss: 8.967318]\n",
      "4091 [D loss: 0.036578, acc.: 100.00%] [G loss: 8.035817]\n",
      "4092 [D loss: 0.306587, acc.: 83.33%] [G loss: 6.392734]\n",
      "4093 [D loss: 0.050538, acc.: 94.44%] [G loss: 7.274336]\n",
      "4094 [D loss: 0.178389, acc.: 94.44%] [G loss: 5.751195]\n",
      "4095 [D loss: 0.074400, acc.: 94.44%] [G loss: 5.677409]\n",
      "4096 [D loss: 0.094851, acc.: 94.44%] [G loss: 5.488962]\n",
      "4097 [D loss: 0.173638, acc.: 94.44%] [G loss: 7.202541]\n",
      "4098 [D loss: 0.012685, acc.: 100.00%] [G loss: 6.901541]\n",
      "4099 [D loss: 0.367390, acc.: 94.44%] [G loss: 5.975689]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100 [D loss: 0.252907, acc.: 83.33%] [G loss: 7.711395]\n",
      "4101 [D loss: 0.009317, acc.: 100.00%] [G loss: 8.683826]\n",
      "4102 [D loss: 0.289889, acc.: 77.78%] [G loss: 5.441077]\n",
      "4103 [D loss: 0.408862, acc.: 83.33%] [G loss: 7.117412]\n",
      "4104 [D loss: 0.051228, acc.: 94.44%] [G loss: 10.391943]\n",
      "4105 [D loss: 0.119854, acc.: 94.44%] [G loss: 5.894426]\n",
      "4106 [D loss: 0.228386, acc.: 94.44%] [G loss: 5.791636]\n",
      "4107 [D loss: 0.082859, acc.: 94.44%] [G loss: 5.720581]\n",
      "4108 [D loss: 0.766702, acc.: 72.22%] [G loss: 5.469406]\n",
      "4109 [D loss: 0.031236, acc.: 100.00%] [G loss: 9.344153]\n",
      "4110 [D loss: 0.232088, acc.: 94.44%] [G loss: 4.411787]\n",
      "4111 [D loss: 0.067013, acc.: 100.00%] [G loss: 5.929808]\n",
      "4112 [D loss: 0.118180, acc.: 94.44%] [G loss: 4.327047]\n",
      "4113 [D loss: 0.106179, acc.: 94.44%] [G loss: 7.301900]\n",
      "4114 [D loss: 0.568737, acc.: 83.33%] [G loss: 3.977166]\n",
      "4115 [D loss: 0.012734, acc.: 100.00%] [G loss: 8.247804]\n",
      "4116 [D loss: 0.092821, acc.: 94.44%] [G loss: 6.183068]\n",
      "4117 [D loss: 0.231777, acc.: 88.89%] [G loss: 6.414585]\n",
      "4118 [D loss: 0.129242, acc.: 94.44%] [G loss: 6.585546]\n",
      "4119 [D loss: 0.050913, acc.: 100.00%] [G loss: 8.002547]\n",
      "4120 [D loss: 0.033807, acc.: 100.00%] [G loss: 7.787960]\n",
      "4121 [D loss: 0.056698, acc.: 100.00%] [G loss: 7.848224]\n",
      "4122 [D loss: 0.076870, acc.: 94.44%] [G loss: 8.595863]\n",
      "4123 [D loss: 0.203903, acc.: 88.89%] [G loss: 7.719109]\n",
      "4124 [D loss: 0.111389, acc.: 94.44%] [G loss: 6.680922]\n",
      "4125 [D loss: 0.094963, acc.: 94.44%] [G loss: 8.137238]\n",
      "4126 [D loss: 0.055167, acc.: 100.00%] [G loss: 4.933891]\n",
      "4127 [D loss: 0.127254, acc.: 94.44%] [G loss: 4.030245]\n",
      "4128 [D loss: 0.186852, acc.: 88.89%] [G loss: 5.667531]\n",
      "4129 [D loss: 0.001687, acc.: 100.00%] [G loss: 7.350153]\n",
      "4130 [D loss: 0.083707, acc.: 100.00%] [G loss: 5.962879]\n",
      "4131 [D loss: 0.142142, acc.: 100.00%] [G loss: 4.811048]\n",
      "4132 [D loss: 0.023628, acc.: 100.00%] [G loss: 5.732976]\n",
      "4133 [D loss: 0.153406, acc.: 94.44%] [G loss: 3.600692]\n",
      "4134 [D loss: 0.018210, acc.: 100.00%] [G loss: 7.011734]\n",
      "4135 [D loss: 0.018869, acc.: 100.00%] [G loss: 5.323653]\n",
      "4136 [D loss: 0.025676, acc.: 100.00%] [G loss: 6.364106]\n",
      "4137 [D loss: 0.068999, acc.: 100.00%] [G loss: 3.918392]\n",
      "4138 [D loss: 0.082667, acc.: 94.44%] [G loss: 5.753511]\n",
      "4139 [D loss: 0.040614, acc.: 100.00%] [G loss: 6.168921]\n",
      "4140 [D loss: 0.089184, acc.: 94.44%] [G loss: 7.030331]\n",
      "4141 [D loss: 0.052427, acc.: 100.00%] [G loss: 6.393928]\n",
      "4142 [D loss: 0.032101, acc.: 100.00%] [G loss: 4.467752]\n",
      "4143 [D loss: 0.121916, acc.: 94.44%] [G loss: 5.446272]\n",
      "4144 [D loss: 0.038270, acc.: 100.00%] [G loss: 5.942584]\n",
      "4145 [D loss: 0.484181, acc.: 72.22%] [G loss: 4.553471]\n",
      "4146 [D loss: 0.047500, acc.: 100.00%] [G loss: 6.355738]\n",
      "4147 [D loss: 0.037321, acc.: 100.00%] [G loss: 6.856829]\n",
      "4148 [D loss: 0.113499, acc.: 94.44%] [G loss: 7.219069]\n",
      "4149 [D loss: 0.045816, acc.: 100.00%] [G loss: 5.528498]\n",
      "4150 [D loss: 0.007817, acc.: 100.00%] [G loss: 9.188678]\n",
      "4151 [D loss: 0.018062, acc.: 100.00%] [G loss: 3.895693]\n",
      "4152 [D loss: 0.027332, acc.: 100.00%] [G loss: 8.675810]\n",
      "4153 [D loss: 0.004512, acc.: 100.00%] [G loss: 7.826981]\n",
      "4154 [D loss: 0.129271, acc.: 100.00%] [G loss: 5.342099]\n",
      "4155 [D loss: 0.068399, acc.: 94.44%] [G loss: 7.388896]\n",
      "4156 [D loss: 0.039402, acc.: 100.00%] [G loss: 9.005933]\n",
      "4157 [D loss: 0.316799, acc.: 88.89%] [G loss: 5.727649]\n",
      "4158 [D loss: 0.013004, acc.: 100.00%] [G loss: 5.371934]\n",
      "4159 [D loss: 0.127182, acc.: 94.44%] [G loss: 5.643633]\n",
      "4160 [D loss: 0.137348, acc.: 94.44%] [G loss: 5.784779]\n",
      "4161 [D loss: 0.084976, acc.: 94.44%] [G loss: 9.046848]\n",
      "4162 [D loss: 0.115658, acc.: 94.44%] [G loss: 8.619070]\n",
      "4163 [D loss: 0.800339, acc.: 72.22%] [G loss: 7.475374]\n",
      "4164 [D loss: 0.121281, acc.: 88.89%] [G loss: 6.975679]\n",
      "4165 [D loss: 0.064264, acc.: 100.00%] [G loss: 7.247664]\n",
      "4166 [D loss: 0.027002, acc.: 100.00%] [G loss: 6.514609]\n",
      "4167 [D loss: 0.058027, acc.: 100.00%] [G loss: 5.695315]\n",
      "4168 [D loss: 0.113410, acc.: 94.44%] [G loss: 5.519328]\n",
      "4169 [D loss: 0.057667, acc.: 100.00%] [G loss: 8.653254]\n",
      "4170 [D loss: 0.056902, acc.: 94.44%] [G loss: 7.229718]\n",
      "4171 [D loss: 0.099604, acc.: 94.44%] [G loss: 5.525301]\n",
      "4172 [D loss: 0.222701, acc.: 88.89%] [G loss: 5.098554]\n",
      "4173 [D loss: 0.031071, acc.: 100.00%] [G loss: 7.344173]\n",
      "4174 [D loss: 0.053561, acc.: 100.00%] [G loss: 6.729521]\n",
      "4175 [D loss: 0.070571, acc.: 94.44%] [G loss: 6.482204]\n",
      "4176 [D loss: 0.006640, acc.: 100.00%] [G loss: 6.940962]\n",
      "4177 [D loss: 0.044529, acc.: 100.00%] [G loss: 5.640546]\n",
      "4178 [D loss: 0.254119, acc.: 88.89%] [G loss: 4.757607]\n",
      "4179 [D loss: 0.060456, acc.: 100.00%] [G loss: 5.941309]\n",
      "4180 [D loss: 0.071758, acc.: 94.44%] [G loss: 7.588825]\n",
      "4181 [D loss: 0.238081, acc.: 94.44%] [G loss: 5.057557]\n",
      "4182 [D loss: 0.043252, acc.: 100.00%] [G loss: 6.746717]\n",
      "4183 [D loss: 0.102719, acc.: 100.00%] [G loss: 5.387037]\n",
      "4184 [D loss: 0.010040, acc.: 100.00%] [G loss: 5.793921]\n",
      "4185 [D loss: 0.042623, acc.: 100.00%] [G loss: 6.097192]\n",
      "4186 [D loss: 0.156504, acc.: 88.89%] [G loss: 7.370440]\n",
      "4187 [D loss: 0.057550, acc.: 100.00%] [G loss: 7.791522]\n",
      "4188 [D loss: 0.092766, acc.: 94.44%] [G loss: 7.770145]\n",
      "4189 [D loss: 0.144091, acc.: 94.44%] [G loss: 3.893779]\n",
      "4190 [D loss: 0.028030, acc.: 100.00%] [G loss: 4.949808]\n",
      "4191 [D loss: 0.144659, acc.: 88.89%] [G loss: 6.568077]\n",
      "4192 [D loss: 0.018474, acc.: 100.00%] [G loss: 7.365450]\n",
      "4193 [D loss: 0.055740, acc.: 100.00%] [G loss: 8.741787]\n",
      "4194 [D loss: 0.031354, acc.: 100.00%] [G loss: 8.337317]\n",
      "4195 [D loss: 0.157448, acc.: 94.44%] [G loss: 5.617196]\n",
      "4196 [D loss: 0.092912, acc.: 94.44%] [G loss: 5.461849]\n",
      "4197 [D loss: 0.010153, acc.: 100.00%] [G loss: 7.504146]\n",
      "4198 [D loss: 0.035019, acc.: 100.00%] [G loss: 6.439946]\n",
      "4199 [D loss: 0.221327, acc.: 83.33%] [G loss: 4.688818]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 [D loss: 0.246025, acc.: 94.44%] [G loss: 6.848848]\n",
      "4201 [D loss: 0.051105, acc.: 100.00%] [G loss: 7.772864]\n",
      "4202 [D loss: 0.183052, acc.: 94.44%] [G loss: 7.341078]\n",
      "4203 [D loss: 0.029353, acc.: 100.00%] [G loss: 6.079885]\n",
      "4204 [D loss: 0.019793, acc.: 100.00%] [G loss: 6.672869]\n",
      "4205 [D loss: 0.089194, acc.: 94.44%] [G loss: 7.821185]\n",
      "4206 [D loss: 0.032174, acc.: 100.00%] [G loss: 7.280311]\n",
      "4207 [D loss: 0.034233, acc.: 100.00%] [G loss: 6.377739]\n",
      "4208 [D loss: 0.002995, acc.: 100.00%] [G loss: 6.938996]\n",
      "4209 [D loss: 0.006745, acc.: 100.00%] [G loss: 7.389327]\n",
      "4210 [D loss: 0.180173, acc.: 94.44%] [G loss: 5.264985]\n",
      "4211 [D loss: 0.549436, acc.: 77.78%] [G loss: 6.614450]\n",
      "4212 [D loss: 0.126095, acc.: 94.44%] [G loss: 5.620081]\n",
      "4213 [D loss: 0.036390, acc.: 100.00%] [G loss: 5.422142]\n",
      "4214 [D loss: 0.011123, acc.: 100.00%] [G loss: 6.246781]\n",
      "4215 [D loss: 0.312251, acc.: 83.33%] [G loss: 5.152298]\n",
      "4216 [D loss: 0.054875, acc.: 100.00%] [G loss: 8.529113]\n",
      "4217 [D loss: 0.055080, acc.: 100.00%] [G loss: 7.976164]\n",
      "4218 [D loss: 0.039033, acc.: 100.00%] [G loss: 7.120494]\n",
      "4219 [D loss: 0.103168, acc.: 94.44%] [G loss: 6.152579]\n",
      "4220 [D loss: 0.007882, acc.: 100.00%] [G loss: 7.506239]\n",
      "4221 [D loss: 0.144476, acc.: 94.44%] [G loss: 6.452266]\n",
      "4222 [D loss: 0.095180, acc.: 94.44%] [G loss: 7.162019]\n",
      "4223 [D loss: 0.025893, acc.: 100.00%] [G loss: 8.596851]\n",
      "4224 [D loss: 0.544894, acc.: 77.78%] [G loss: 4.688841]\n",
      "4225 [D loss: 0.184506, acc.: 88.89%] [G loss: 5.235968]\n",
      "4226 [D loss: 0.368178, acc.: 88.89%] [G loss: 8.765560]\n",
      "4227 [D loss: 0.069204, acc.: 100.00%] [G loss: 6.831007]\n",
      "4228 [D loss: 0.151658, acc.: 94.44%] [G loss: 6.058687]\n",
      "4229 [D loss: 0.203959, acc.: 88.89%] [G loss: 6.511803]\n",
      "4230 [D loss: 0.006906, acc.: 100.00%] [G loss: 6.295498]\n",
      "4231 [D loss: 0.018335, acc.: 100.00%] [G loss: 5.861515]\n",
      "4232 [D loss: 0.039568, acc.: 100.00%] [G loss: 5.202140]\n",
      "4233 [D loss: 0.266771, acc.: 88.89%] [G loss: 7.622031]\n",
      "4234 [D loss: 0.130401, acc.: 100.00%] [G loss: 5.162350]\n",
      "4235 [D loss: 0.247369, acc.: 88.89%] [G loss: 6.799918]\n",
      "4236 [D loss: 0.245983, acc.: 88.89%] [G loss: 5.683000]\n",
      "4237 [D loss: 0.049784, acc.: 100.00%] [G loss: 7.502215]\n",
      "4238 [D loss: 0.212478, acc.: 94.44%] [G loss: 6.073191]\n",
      "4239 [D loss: 0.043405, acc.: 100.00%] [G loss: 7.338412]\n",
      "4240 [D loss: 0.142264, acc.: 94.44%] [G loss: 6.149120]\n",
      "4241 [D loss: 0.026418, acc.: 100.00%] [G loss: 8.516444]\n",
      "4242 [D loss: 0.338896, acc.: 83.33%] [G loss: 4.971802]\n",
      "4243 [D loss: 0.199069, acc.: 94.44%] [G loss: 4.876769]\n",
      "4244 [D loss: 0.019737, acc.: 100.00%] [G loss: 7.601774]\n",
      "4245 [D loss: 0.116052, acc.: 100.00%] [G loss: 5.796644]\n",
      "4246 [D loss: 0.017125, acc.: 100.00%] [G loss: 6.491377]\n",
      "4247 [D loss: 0.104297, acc.: 94.44%] [G loss: 6.477852]\n",
      "4248 [D loss: 0.104760, acc.: 94.44%] [G loss: 9.473737]\n",
      "4249 [D loss: 0.092323, acc.: 94.44%] [G loss: 4.935644]\n",
      "4250 [D loss: 0.139728, acc.: 94.44%] [G loss: 5.481044]\n",
      "4251 [D loss: 0.023042, acc.: 100.00%] [G loss: 5.638758]\n",
      "4252 [D loss: 0.222392, acc.: 88.89%] [G loss: 5.726298]\n",
      "4253 [D loss: 0.056069, acc.: 100.00%] [G loss: 5.414994]\n",
      "4254 [D loss: 0.113718, acc.: 94.44%] [G loss: 3.382992]\n",
      "4255 [D loss: 0.068806, acc.: 100.00%] [G loss: 4.533859]\n",
      "4256 [D loss: 0.047717, acc.: 100.00%] [G loss: 6.172328]\n",
      "4257 [D loss: 0.051322, acc.: 100.00%] [G loss: 5.970236]\n",
      "4258 [D loss: 0.038254, acc.: 100.00%] [G loss: 6.808221]\n",
      "4259 [D loss: 0.069806, acc.: 94.44%] [G loss: 8.210281]\n",
      "4260 [D loss: 0.144223, acc.: 94.44%] [G loss: 6.875060]\n",
      "4261 [D loss: 0.042238, acc.: 100.00%] [G loss: 7.341115]\n",
      "4262 [D loss: 0.030580, acc.: 100.00%] [G loss: 8.542816]\n",
      "4263 [D loss: 0.054360, acc.: 100.00%] [G loss: 4.607388]\n",
      "4264 [D loss: 0.133741, acc.: 94.44%] [G loss: 4.654428]\n",
      "4265 [D loss: 0.161401, acc.: 94.44%] [G loss: 3.664483]\n",
      "4266 [D loss: 0.106652, acc.: 100.00%] [G loss: 5.154118]\n",
      "4267 [D loss: 0.138483, acc.: 88.89%] [G loss: 5.534263]\n",
      "4268 [D loss: 0.025665, acc.: 100.00%] [G loss: 6.306326]\n",
      "4269 [D loss: 0.204023, acc.: 88.89%] [G loss: 5.795185]\n",
      "4270 [D loss: 0.126010, acc.: 94.44%] [G loss: 7.824671]\n",
      "4271 [D loss: 0.093015, acc.: 94.44%] [G loss: 6.543857]\n",
      "4272 [D loss: 0.020214, acc.: 100.00%] [G loss: 6.862375]\n",
      "4273 [D loss: 0.006692, acc.: 100.00%] [G loss: 7.619982]\n",
      "4274 [D loss: 0.094959, acc.: 94.44%] [G loss: 6.253531]\n",
      "4275 [D loss: 0.007465, acc.: 100.00%] [G loss: 8.331675]\n",
      "4276 [D loss: 0.326394, acc.: 83.33%] [G loss: 7.219721]\n",
      "4277 [D loss: 0.006935, acc.: 100.00%] [G loss: 9.537991]\n",
      "4278 [D loss: 0.052467, acc.: 94.44%] [G loss: 7.597615]\n",
      "4279 [D loss: 0.264013, acc.: 77.78%] [G loss: 3.947829]\n",
      "4280 [D loss: 0.461960, acc.: 88.89%] [G loss: 6.600077]\n",
      "4281 [D loss: 0.031473, acc.: 100.00%] [G loss: 7.611986]\n",
      "4282 [D loss: 0.003156, acc.: 100.00%] [G loss: 7.185926]\n",
      "4283 [D loss: 0.094796, acc.: 94.44%] [G loss: 7.199817]\n",
      "4284 [D loss: 0.048255, acc.: 100.00%] [G loss: 8.574421]\n",
      "4285 [D loss: 0.289561, acc.: 88.89%] [G loss: 6.390059]\n",
      "4286 [D loss: 0.020033, acc.: 100.00%] [G loss: 8.086072]\n",
      "4287 [D loss: 0.083782, acc.: 94.44%] [G loss: 5.392542]\n",
      "4288 [D loss: 0.074256, acc.: 94.44%] [G loss: 4.432878]\n",
      "4289 [D loss: 0.005619, acc.: 100.00%] [G loss: 6.960732]\n",
      "4290 [D loss: 0.026662, acc.: 100.00%] [G loss: 5.772541]\n",
      "4291 [D loss: 0.020171, acc.: 100.00%] [G loss: 6.093441]\n",
      "4292 [D loss: 0.010910, acc.: 100.00%] [G loss: 7.541755]\n",
      "4293 [D loss: 0.148533, acc.: 88.89%] [G loss: 6.929396]\n",
      "4294 [D loss: 0.156686, acc.: 88.89%] [G loss: 7.868043]\n",
      "4295 [D loss: 0.076890, acc.: 94.44%] [G loss: 6.057151]\n",
      "4296 [D loss: 0.123175, acc.: 94.44%] [G loss: 5.513887]\n",
      "4297 [D loss: 0.537666, acc.: 83.33%] [G loss: 4.751173]\n",
      "4298 [D loss: 0.070914, acc.: 100.00%] [G loss: 6.233236]\n",
      "4299 [D loss: 0.067575, acc.: 100.00%] [G loss: 5.545694]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300 [D loss: 0.011274, acc.: 100.00%] [G loss: 6.427683]\n",
      "4301 [D loss: 0.028931, acc.: 100.00%] [G loss: 6.487882]\n",
      "4302 [D loss: 0.428907, acc.: 83.33%] [G loss: 5.183815]\n",
      "4303 [D loss: 0.018909, acc.: 100.00%] [G loss: 9.040239]\n",
      "4304 [D loss: 0.042463, acc.: 100.00%] [G loss: 7.190939]\n",
      "4305 [D loss: 0.083995, acc.: 94.44%] [G loss: 6.970292]\n",
      "4306 [D loss: 0.020400, acc.: 100.00%] [G loss: 7.383848]\n",
      "4307 [D loss: 0.014203, acc.: 100.00%] [G loss: 6.069060]\n",
      "4308 [D loss: 0.172953, acc.: 94.44%] [G loss: 7.927656]\n",
      "4309 [D loss: 0.030900, acc.: 100.00%] [G loss: 8.723196]\n",
      "4310 [D loss: 0.012094, acc.: 100.00%] [G loss: 7.004834]\n",
      "4311 [D loss: 0.059863, acc.: 94.44%] [G loss: 9.275786]\n",
      "4312 [D loss: 0.231777, acc.: 94.44%] [G loss: 5.981512]\n",
      "4313 [D loss: 0.015509, acc.: 100.00%] [G loss: 6.552620]\n",
      "4314 [D loss: 0.039206, acc.: 100.00%] [G loss: 6.414389]\n",
      "4315 [D loss: 0.057532, acc.: 100.00%] [G loss: 6.153649]\n",
      "4316 [D loss: 0.018577, acc.: 100.00%] [G loss: 5.035545]\n",
      "4317 [D loss: 0.034744, acc.: 100.00%] [G loss: 5.195566]\n",
      "4318 [D loss: 0.397577, acc.: 83.33%] [G loss: 3.680978]\n",
      "4319 [D loss: 0.117309, acc.: 94.44%] [G loss: 2.668946]\n",
      "4320 [D loss: 0.131213, acc.: 94.44%] [G loss: 4.536343]\n",
      "4321 [D loss: 0.294041, acc.: 94.44%] [G loss: 6.041048]\n",
      "4322 [D loss: 0.241226, acc.: 94.44%] [G loss: 6.529775]\n",
      "4323 [D loss: 0.014078, acc.: 100.00%] [G loss: 7.006973]\n",
      "4324 [D loss: 0.018305, acc.: 100.00%] [G loss: 7.771148]\n",
      "4325 [D loss: 0.012293, acc.: 100.00%] [G loss: 7.614103]\n",
      "4326 [D loss: 0.069933, acc.: 100.00%] [G loss: 5.813659]\n",
      "4327 [D loss: 0.281599, acc.: 94.44%] [G loss: 6.843592]\n",
      "4328 [D loss: 0.016781, acc.: 100.00%] [G loss: 7.806952]\n",
      "4329 [D loss: 0.102175, acc.: 94.44%] [G loss: 7.782926]\n",
      "4330 [D loss: 0.054377, acc.: 100.00%] [G loss: 5.879518]\n",
      "4331 [D loss: 0.004958, acc.: 100.00%] [G loss: 7.132185]\n",
      "4332 [D loss: 0.075616, acc.: 100.00%] [G loss: 8.948978]\n",
      "4333 [D loss: 0.049402, acc.: 100.00%] [G loss: 4.761081]\n",
      "4334 [D loss: 0.085305, acc.: 94.44%] [G loss: 4.600538]\n",
      "4335 [D loss: 0.028926, acc.: 100.00%] [G loss: 7.655877]\n",
      "4336 [D loss: 0.013129, acc.: 100.00%] [G loss: 8.738517]\n",
      "4337 [D loss: 0.077482, acc.: 94.44%] [G loss: 6.301126]\n",
      "4338 [D loss: 0.032918, acc.: 100.00%] [G loss: 5.566599]\n",
      "4339 [D loss: 0.035747, acc.: 100.00%] [G loss: 5.084124]\n",
      "4340 [D loss: 0.045923, acc.: 100.00%] [G loss: 6.939584]\n",
      "4341 [D loss: 0.020190, acc.: 100.00%] [G loss: 9.067396]\n",
      "4342 [D loss: 0.025104, acc.: 100.00%] [G loss: 6.682085]\n",
      "4343 [D loss: 0.041106, acc.: 100.00%] [G loss: 8.381210]\n",
      "4344 [D loss: 0.003527, acc.: 100.00%] [G loss: 7.039400]\n",
      "4345 [D loss: 0.004344, acc.: 100.00%] [G loss: 8.294102]\n",
      "4346 [D loss: 0.093218, acc.: 88.89%] [G loss: 7.283184]\n",
      "4347 [D loss: 0.015582, acc.: 100.00%] [G loss: 8.733721]\n",
      "4348 [D loss: 0.299796, acc.: 77.78%] [G loss: 7.033627]\n",
      "4349 [D loss: 0.050185, acc.: 100.00%] [G loss: 8.090449]\n",
      "4350 [D loss: 0.158447, acc.: 88.89%] [G loss: 7.175849]\n",
      "4351 [D loss: 0.041741, acc.: 100.00%] [G loss: 6.939076]\n",
      "4352 [D loss: 0.220247, acc.: 83.33%] [G loss: 5.714612]\n",
      "4353 [D loss: 0.019190, acc.: 100.00%] [G loss: 7.786463]\n",
      "4354 [D loss: 0.063801, acc.: 100.00%] [G loss: 6.328454]\n",
      "4355 [D loss: 0.033907, acc.: 100.00%] [G loss: 7.446026]\n",
      "4356 [D loss: 0.338761, acc.: 88.89%] [G loss: 3.606966]\n",
      "4357 [D loss: 0.181394, acc.: 94.44%] [G loss: 4.386211]\n",
      "4358 [D loss: 0.096896, acc.: 100.00%] [G loss: 7.820935]\n",
      "4359 [D loss: 0.013771, acc.: 100.00%] [G loss: 6.555898]\n",
      "4360 [D loss: 0.009631, acc.: 100.00%] [G loss: 7.306199]\n",
      "4361 [D loss: 0.005583, acc.: 100.00%] [G loss: 6.236975]\n",
      "4362 [D loss: 0.089784, acc.: 100.00%] [G loss: 6.968252]\n",
      "4363 [D loss: 0.050672, acc.: 100.00%] [G loss: 6.761147]\n",
      "4364 [D loss: 0.021848, acc.: 100.00%] [G loss: 6.196322]\n",
      "4365 [D loss: 0.020518, acc.: 100.00%] [G loss: 4.599644]\n",
      "4366 [D loss: 0.015735, acc.: 100.00%] [G loss: 7.424259]\n",
      "4367 [D loss: 0.035124, acc.: 100.00%] [G loss: 5.643597]\n",
      "4368 [D loss: 0.057850, acc.: 94.44%] [G loss: 5.337745]\n",
      "4369 [D loss: 0.143736, acc.: 88.89%] [G loss: 4.967724]\n",
      "4370 [D loss: 0.129535, acc.: 88.89%] [G loss: 6.687274]\n",
      "4371 [D loss: 0.117011, acc.: 94.44%] [G loss: 4.636558]\n",
      "4372 [D loss: 0.052416, acc.: 100.00%] [G loss: 5.375350]\n",
      "4373 [D loss: 0.106837, acc.: 94.44%] [G loss: 6.301984]\n",
      "4374 [D loss: 0.117660, acc.: 100.00%] [G loss: 4.955581]\n",
      "4375 [D loss: 0.097861, acc.: 100.00%] [G loss: 6.180059]\n",
      "4376 [D loss: 0.027486, acc.: 100.00%] [G loss: 5.630051]\n",
      "4377 [D loss: 0.184487, acc.: 94.44%] [G loss: 6.561053]\n",
      "4378 [D loss: 0.020081, acc.: 100.00%] [G loss: 7.073102]\n",
      "4379 [D loss: 0.056012, acc.: 100.00%] [G loss: 5.608974]\n",
      "4380 [D loss: 0.101701, acc.: 94.44%] [G loss: 5.708576]\n",
      "4381 [D loss: 0.106141, acc.: 88.89%] [G loss: 7.016788]\n",
      "4382 [D loss: 0.190787, acc.: 94.44%] [G loss: 6.004745]\n",
      "4383 [D loss: 0.088316, acc.: 94.44%] [G loss: 5.524436]\n",
      "4384 [D loss: 0.076523, acc.: 94.44%] [G loss: 5.799334]\n",
      "4385 [D loss: 0.028772, acc.: 100.00%] [G loss: 5.501717]\n",
      "4386 [D loss: 0.224466, acc.: 88.89%] [G loss: 6.859624]\n",
      "4387 [D loss: 0.046339, acc.: 100.00%] [G loss: 10.768908]\n",
      "4388 [D loss: 0.152661, acc.: 88.89%] [G loss: 5.973572]\n",
      "4389 [D loss: 0.040301, acc.: 100.00%] [G loss: 7.100076]\n",
      "4390 [D loss: 0.068383, acc.: 100.00%] [G loss: 4.872340]\n",
      "4391 [D loss: 0.065898, acc.: 94.44%] [G loss: 5.752807]\n",
      "4392 [D loss: 0.008129, acc.: 100.00%] [G loss: 5.651855]\n",
      "4393 [D loss: 0.104193, acc.: 94.44%] [G loss: 5.746206]\n",
      "4394 [D loss: 0.019147, acc.: 100.00%] [G loss: 7.301115]\n",
      "4395 [D loss: 0.123609, acc.: 94.44%] [G loss: 5.758751]\n",
      "4396 [D loss: 0.134785, acc.: 94.44%] [G loss: 6.581303]\n",
      "4397 [D loss: 0.091875, acc.: 100.00%] [G loss: 6.478258]\n",
      "4398 [D loss: 0.246912, acc.: 88.89%] [G loss: 4.350600]\n",
      "4399 [D loss: 0.657311, acc.: 83.33%] [G loss: 7.415756]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400 [D loss: 0.027089, acc.: 100.00%] [G loss: 10.822055]\n",
      "4401 [D loss: 0.070617, acc.: 100.00%] [G loss: 8.296513]\n",
      "4402 [D loss: 0.030564, acc.: 100.00%] [G loss: 7.231042]\n",
      "4403 [D loss: 0.011015, acc.: 100.00%] [G loss: 9.196519]\n",
      "4404 [D loss: 0.017565, acc.: 100.00%] [G loss: 7.558994]\n",
      "4405 [D loss: 0.006948, acc.: 100.00%] [G loss: 6.632598]\n",
      "4406 [D loss: 0.048445, acc.: 100.00%] [G loss: 5.800571]\n",
      "4407 [D loss: 0.017121, acc.: 100.00%] [G loss: 10.120152]\n",
      "4408 [D loss: 0.003180, acc.: 100.00%] [G loss: 8.155932]\n",
      "4409 [D loss: 0.007576, acc.: 100.00%] [G loss: 8.039251]\n",
      "4410 [D loss: 0.003885, acc.: 100.00%] [G loss: 6.989463]\n",
      "4411 [D loss: 0.013237, acc.: 100.00%] [G loss: 5.448461]\n",
      "4412 [D loss: 0.003217, acc.: 100.00%] [G loss: 6.856031]\n",
      "4413 [D loss: 0.026175, acc.: 100.00%] [G loss: 5.040664]\n",
      "4414 [D loss: 0.019846, acc.: 100.00%] [G loss: 4.661082]\n",
      "4415 [D loss: 0.177590, acc.: 94.44%] [G loss: 4.507521]\n",
      "4416 [D loss: 0.377299, acc.: 83.33%] [G loss: 6.610727]\n",
      "4417 [D loss: 0.008351, acc.: 100.00%] [G loss: 7.693257]\n",
      "4418 [D loss: 0.052647, acc.: 100.00%] [G loss: 6.176909]\n",
      "4419 [D loss: 0.009211, acc.: 100.00%] [G loss: 6.271512]\n",
      "4420 [D loss: 0.020276, acc.: 100.00%] [G loss: 7.034354]\n",
      "4421 [D loss: 0.075261, acc.: 100.00%] [G loss: 7.005179]\n",
      "4422 [D loss: 0.072295, acc.: 100.00%] [G loss: 6.731684]\n",
      "4423 [D loss: 0.112577, acc.: 94.44%] [G loss: 5.803535]\n",
      "4424 [D loss: 0.060488, acc.: 94.44%] [G loss: 6.597891]\n",
      "4425 [D loss: 0.020492, acc.: 100.00%] [G loss: 7.287005]\n",
      "4426 [D loss: 0.005432, acc.: 100.00%] [G loss: 5.568947]\n",
      "4427 [D loss: 0.009805, acc.: 100.00%] [G loss: 6.737658]\n",
      "4428 [D loss: 0.031829, acc.: 100.00%] [G loss: 7.120697]\n",
      "4429 [D loss: 0.263018, acc.: 88.89%] [G loss: 6.747956]\n",
      "4430 [D loss: 0.641606, acc.: 61.11%] [G loss: 5.719064]\n",
      "4431 [D loss: 0.026873, acc.: 100.00%] [G loss: 5.599311]\n",
      "4432 [D loss: 0.066453, acc.: 100.00%] [G loss: 5.857951]\n",
      "4433 [D loss: 0.058635, acc.: 100.00%] [G loss: 6.060430]\n",
      "4434 [D loss: 0.084938, acc.: 94.44%] [G loss: 5.852854]\n",
      "4435 [D loss: 0.051314, acc.: 100.00%] [G loss: 6.718283]\n",
      "4436 [D loss: 0.232515, acc.: 94.44%] [G loss: 4.993854]\n",
      "4437 [D loss: 0.005807, acc.: 100.00%] [G loss: 7.329875]\n",
      "4438 [D loss: 0.032325, acc.: 100.00%] [G loss: 8.810802]\n",
      "4439 [D loss: 0.095072, acc.: 94.44%] [G loss: 5.451313]\n",
      "4440 [D loss: 0.085343, acc.: 94.44%] [G loss: 4.354384]\n",
      "4441 [D loss: 0.018257, acc.: 100.00%] [G loss: 4.853913]\n",
      "4442 [D loss: 0.042469, acc.: 100.00%] [G loss: 5.082203]\n",
      "4443 [D loss: 0.321027, acc.: 94.44%] [G loss: 6.175271]\n",
      "4444 [D loss: 0.179161, acc.: 94.44%] [G loss: 7.067903]\n",
      "4445 [D loss: 0.311109, acc.: 83.33%] [G loss: 4.458444]\n",
      "4446 [D loss: 0.412850, acc.: 88.89%] [G loss: 7.772600]\n",
      "4447 [D loss: 0.069485, acc.: 100.00%] [G loss: 6.881809]\n",
      "4448 [D loss: 0.230363, acc.: 94.44%] [G loss: 6.033846]\n",
      "4449 [D loss: 0.117588, acc.: 94.44%] [G loss: 5.297059]\n",
      "4450 [D loss: 0.023881, acc.: 100.00%] [G loss: 5.681629]\n",
      "4451 [D loss: 0.025589, acc.: 100.00%] [G loss: 5.568923]\n",
      "4452 [D loss: 0.002924, acc.: 100.00%] [G loss: 8.054697]\n",
      "4453 [D loss: 0.041868, acc.: 100.00%] [G loss: 6.773938]\n",
      "4454 [D loss: 0.184285, acc.: 94.44%] [G loss: 5.929654]\n",
      "4455 [D loss: 0.046104, acc.: 100.00%] [G loss: 7.700871]\n",
      "4456 [D loss: 0.080147, acc.: 94.44%] [G loss: 5.606337]\n",
      "4457 [D loss: 0.079151, acc.: 100.00%] [G loss: 7.661041]\n",
      "4458 [D loss: 0.097685, acc.: 94.44%] [G loss: 7.329401]\n",
      "4459 [D loss: 0.103640, acc.: 94.44%] [G loss: 5.436205]\n",
      "4460 [D loss: 0.075406, acc.: 100.00%] [G loss: 4.766504]\n",
      "4461 [D loss: 0.104661, acc.: 94.44%] [G loss: 7.737364]\n",
      "4462 [D loss: 0.094111, acc.: 94.44%] [G loss: 7.977112]\n",
      "4463 [D loss: 0.046939, acc.: 100.00%] [G loss: 5.700045]\n",
      "4464 [D loss: 0.004461, acc.: 100.00%] [G loss: 7.434576]\n",
      "4465 [D loss: 0.035732, acc.: 100.00%] [G loss: 6.389364]\n",
      "4466 [D loss: 0.058103, acc.: 100.00%] [G loss: 5.358222]\n",
      "4467 [D loss: 0.008428, acc.: 100.00%] [G loss: 7.023934]\n",
      "4468 [D loss: 0.014506, acc.: 100.00%] [G loss: 6.281988]\n",
      "4469 [D loss: 0.021362, acc.: 100.00%] [G loss: 6.638735]\n",
      "4470 [D loss: 0.241159, acc.: 83.33%] [G loss: 7.212039]\n",
      "4471 [D loss: 0.036504, acc.: 100.00%] [G loss: 5.944668]\n",
      "4472 [D loss: 0.032440, acc.: 100.00%] [G loss: 6.972652]\n",
      "4473 [D loss: 0.221563, acc.: 88.89%] [G loss: 2.992755]\n",
      "4474 [D loss: 0.039247, acc.: 100.00%] [G loss: 4.291524]\n",
      "4475 [D loss: 0.031884, acc.: 100.00%] [G loss: 4.973465]\n",
      "4476 [D loss: 0.034571, acc.: 100.00%] [G loss: 5.283643]\n",
      "4477 [D loss: 0.068324, acc.: 94.44%] [G loss: 6.052662]\n",
      "4478 [D loss: 0.022864, acc.: 100.00%] [G loss: 6.632672]\n",
      "4479 [D loss: 0.056153, acc.: 100.00%] [G loss: 5.987520]\n",
      "4480 [D loss: 0.030360, acc.: 100.00%] [G loss: 8.001794]\n",
      "4481 [D loss: 0.004389, acc.: 100.00%] [G loss: 7.780560]\n",
      "4482 [D loss: 0.075246, acc.: 94.44%] [G loss: 6.868139]\n",
      "4483 [D loss: 0.009169, acc.: 100.00%] [G loss: 8.446883]\n",
      "4484 [D loss: 0.051173, acc.: 100.00%] [G loss: 5.738596]\n",
      "4485 [D loss: 0.040415, acc.: 100.00%] [G loss: 6.857545]\n",
      "4486 [D loss: 0.079080, acc.: 94.44%] [G loss: 6.268399]\n",
      "4487 [D loss: 0.053801, acc.: 100.00%] [G loss: 5.947391]\n",
      "4488 [D loss: 0.190265, acc.: 94.44%] [G loss: 5.620811]\n",
      "4489 [D loss: 0.123488, acc.: 100.00%] [G loss: 4.971418]\n",
      "4490 [D loss: 0.031309, acc.: 100.00%] [G loss: 6.116814]\n",
      "4491 [D loss: 0.043040, acc.: 100.00%] [G loss: 5.835515]\n",
      "4492 [D loss: 0.045846, acc.: 100.00%] [G loss: 5.836106]\n",
      "4493 [D loss: 0.011889, acc.: 100.00%] [G loss: 6.574326]\n",
      "4494 [D loss: 0.033384, acc.: 100.00%] [G loss: 7.291490]\n",
      "4495 [D loss: 0.012474, acc.: 100.00%] [G loss: 7.336077]\n",
      "4496 [D loss: 0.042144, acc.: 100.00%] [G loss: 6.778397]\n",
      "4497 [D loss: 0.115406, acc.: 94.44%] [G loss: 7.084795]\n",
      "4498 [D loss: 0.003927, acc.: 100.00%] [G loss: 6.931094]\n",
      "4499 [D loss: 0.131024, acc.: 94.44%] [G loss: 4.374608]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 [D loss: 0.013552, acc.: 100.00%] [G loss: 5.146023]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4501 [D loss: 0.323808, acc.: 94.44%] [G loss: 5.977964]\n",
      "4502 [D loss: 0.228710, acc.: 94.44%] [G loss: 5.612944]\n",
      "4503 [D loss: 0.045096, acc.: 100.00%] [G loss: 5.369969]\n",
      "4504 [D loss: 0.028046, acc.: 100.00%] [G loss: 4.913447]\n",
      "4505 [D loss: 0.377646, acc.: 88.89%] [G loss: 5.548483]\n",
      "4506 [D loss: 0.030858, acc.: 100.00%] [G loss: 4.741785]\n",
      "4507 [D loss: 0.060601, acc.: 100.00%] [G loss: 6.567088]\n",
      "4508 [D loss: 0.016221, acc.: 100.00%] [G loss: 7.280294]\n",
      "4509 [D loss: 0.199928, acc.: 83.33%] [G loss: 5.060733]\n",
      "4510 [D loss: 0.205688, acc.: 88.89%] [G loss: 6.513801]\n",
      "4511 [D loss: 0.090201, acc.: 94.44%] [G loss: 7.780595]\n",
      "4512 [D loss: 0.033357, acc.: 100.00%] [G loss: 6.682261]\n",
      "4513 [D loss: 0.054645, acc.: 100.00%] [G loss: 6.248487]\n",
      "4514 [D loss: 0.074499, acc.: 94.44%] [G loss: 5.853903]\n",
      "4515 [D loss: 0.197324, acc.: 94.44%] [G loss: 6.600099]\n",
      "4516 [D loss: 0.013798, acc.: 100.00%] [G loss: 7.497238]\n",
      "4517 [D loss: 0.252111, acc.: 88.89%] [G loss: 6.544543]\n",
      "4518 [D loss: 0.777298, acc.: 77.78%] [G loss: 6.689112]\n",
      "4519 [D loss: 0.062376, acc.: 94.44%] [G loss: 8.386189]\n",
      "4520 [D loss: 0.125239, acc.: 94.44%] [G loss: 6.898264]\n",
      "4521 [D loss: 0.188536, acc.: 94.44%] [G loss: 4.218621]\n",
      "4522 [D loss: 0.037836, acc.: 100.00%] [G loss: 6.506826]\n",
      "4523 [D loss: 0.020364, acc.: 100.00%] [G loss: 6.218579]\n",
      "4524 [D loss: 0.009564, acc.: 100.00%] [G loss: 6.116170]\n",
      "4525 [D loss: 0.017609, acc.: 100.00%] [G loss: 5.176114]\n",
      "4526 [D loss: 0.022085, acc.: 100.00%] [G loss: 5.553006]\n",
      "4527 [D loss: 0.084383, acc.: 94.44%] [G loss: 6.472242]\n",
      "4528 [D loss: 0.137020, acc.: 94.44%] [G loss: 5.458150]\n",
      "4529 [D loss: 0.058242, acc.: 94.44%] [G loss: 7.229513]\n",
      "4530 [D loss: 0.176163, acc.: 94.44%] [G loss: 7.558202]\n",
      "4531 [D loss: 0.005728, acc.: 100.00%] [G loss: 8.507830]\n",
      "4532 [D loss: 0.060670, acc.: 100.00%] [G loss: 6.458609]\n",
      "4533 [D loss: 0.040256, acc.: 100.00%] [G loss: 8.406932]\n",
      "4534 [D loss: 0.194797, acc.: 94.44%] [G loss: 5.152883]\n",
      "4535 [D loss: 0.090083, acc.: 100.00%] [G loss: 5.911325]\n",
      "4536 [D loss: 0.091021, acc.: 94.44%] [G loss: 5.138366]\n",
      "4537 [D loss: 0.015444, acc.: 100.00%] [G loss: 8.080365]\n",
      "4538 [D loss: 0.093689, acc.: 94.44%] [G loss: 6.720324]\n",
      "4539 [D loss: 0.068284, acc.: 94.44%] [G loss: 5.610473]\n",
      "4540 [D loss: 0.158697, acc.: 88.89%] [G loss: 6.747148]\n",
      "4541 [D loss: 0.290447, acc.: 88.89%] [G loss: 6.671104]\n",
      "4542 [D loss: 0.018085, acc.: 100.00%] [G loss: 11.656342]\n",
      "4543 [D loss: 0.340406, acc.: 88.89%] [G loss: 4.741846]\n",
      "4544 [D loss: 0.039591, acc.: 100.00%] [G loss: 3.578380]\n",
      "4545 [D loss: 0.294092, acc.: 88.89%] [G loss: 5.982735]\n",
      "4546 [D loss: 0.013617, acc.: 100.00%] [G loss: 8.735194]\n",
      "4547 [D loss: 0.550291, acc.: 77.78%] [G loss: 5.214979]\n",
      "4548 [D loss: 0.164976, acc.: 94.44%] [G loss: 7.104613]\n",
      "4549 [D loss: 0.173296, acc.: 94.44%] [G loss: 6.874995]\n",
      "4550 [D loss: 0.058073, acc.: 100.00%] [G loss: 7.552085]\n",
      "4551 [D loss: 0.056699, acc.: 100.00%] [G loss: 6.165638]\n",
      "4552 [D loss: 0.045701, acc.: 100.00%] [G loss: 4.490714]\n",
      "4553 [D loss: 0.053305, acc.: 100.00%] [G loss: 5.314355]\n",
      "4554 [D loss: 0.093126, acc.: 94.44%] [G loss: 4.851645]\n",
      "4555 [D loss: 0.047657, acc.: 100.00%] [G loss: 6.629529]\n",
      "4556 [D loss: 0.005456, acc.: 100.00%] [G loss: 6.648379]\n",
      "4557 [D loss: 0.206605, acc.: 94.44%] [G loss: 4.239439]\n",
      "4558 [D loss: 0.015975, acc.: 100.00%] [G loss: 4.929339]\n",
      "4559 [D loss: 0.389688, acc.: 88.89%] [G loss: 8.458671]\n",
      "4560 [D loss: 0.087001, acc.: 100.00%] [G loss: 7.789953]\n",
      "4561 [D loss: 0.054400, acc.: 100.00%] [G loss: 7.195754]\n",
      "4562 [D loss: 1.434028, acc.: 44.44%] [G loss: 4.763152]\n",
      "4563 [D loss: 0.177389, acc.: 94.44%] [G loss: 6.188238]\n",
      "4564 [D loss: 0.027654, acc.: 100.00%] [G loss: 8.662150]\n",
      "4565 [D loss: 0.880657, acc.: 61.11%] [G loss: 2.809139]\n",
      "4566 [D loss: 1.004432, acc.: 72.22%] [G loss: 8.303906]\n",
      "4567 [D loss: 0.353580, acc.: 83.33%] [G loss: 5.977295]\n",
      "4568 [D loss: 0.395783, acc.: 77.78%] [G loss: 7.898782]\n",
      "4569 [D loss: 0.073181, acc.: 100.00%] [G loss: 6.326767]\n",
      "4570 [D loss: 0.160134, acc.: 94.44%] [G loss: 6.462012]\n",
      "4571 [D loss: 0.031409, acc.: 100.00%] [G loss: 6.373581]\n",
      "4572 [D loss: 0.260745, acc.: 83.33%] [G loss: 4.262843]\n",
      "4573 [D loss: 0.426133, acc.: 83.33%] [G loss: 7.283117]\n",
      "4574 [D loss: 0.277689, acc.: 88.89%] [G loss: 6.666143]\n",
      "4575 [D loss: 0.398599, acc.: 83.33%] [G loss: 7.330621]\n",
      "4576 [D loss: 0.222485, acc.: 88.89%] [G loss: 7.247928]\n",
      "4577 [D loss: 0.151836, acc.: 94.44%] [G loss: 6.712816]\n",
      "4578 [D loss: 0.063916, acc.: 100.00%] [G loss: 7.005214]\n",
      "4579 [D loss: 0.035440, acc.: 100.00%] [G loss: 5.432476]\n",
      "4580 [D loss: 0.050526, acc.: 100.00%] [G loss: 4.029901]\n",
      "4581 [D loss: 0.133354, acc.: 94.44%] [G loss: 6.538967]\n",
      "4582 [D loss: 0.035548, acc.: 100.00%] [G loss: 7.079836]\n",
      "4583 [D loss: 0.066207, acc.: 100.00%] [G loss: 6.790767]\n",
      "4584 [D loss: 0.174588, acc.: 94.44%] [G loss: 5.097132]\n",
      "4585 [D loss: 0.012046, acc.: 100.00%] [G loss: 6.718569]\n",
      "4586 [D loss: 0.030838, acc.: 100.00%] [G loss: 6.453717]\n",
      "4587 [D loss: 0.137889, acc.: 94.44%] [G loss: 4.650702]\n",
      "4588 [D loss: 0.192124, acc.: 88.89%] [G loss: 8.036047]\n",
      "4589 [D loss: 0.128453, acc.: 94.44%] [G loss: 7.457591]\n",
      "4590 [D loss: 0.266472, acc.: 83.33%] [G loss: 4.837321]\n",
      "4591 [D loss: 0.154985, acc.: 88.89%] [G loss: 6.643596]\n",
      "4592 [D loss: 0.045712, acc.: 100.00%] [G loss: 6.435404]\n",
      "4593 [D loss: 0.456537, acc.: 66.67%] [G loss: 5.907605]\n",
      "4594 [D loss: 0.061592, acc.: 94.44%] [G loss: 8.453406]\n",
      "4595 [D loss: 0.245669, acc.: 83.33%] [G loss: 5.802545]\n",
      "4596 [D loss: 0.082721, acc.: 100.00%] [G loss: 5.620796]\n",
      "4597 [D loss: 0.016705, acc.: 100.00%] [G loss: 8.259311]\n",
      "4598 [D loss: 0.176886, acc.: 88.89%] [G loss: 9.128994]\n",
      "4599 [D loss: 0.042104, acc.: 100.00%] [G loss: 6.632573]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600 [D loss: 0.116366, acc.: 94.44%] [G loss: 6.145597]\n",
      "4601 [D loss: 0.288326, acc.: 88.89%] [G loss: 4.092856]\n",
      "4602 [D loss: 0.012386, acc.: 100.00%] [G loss: 5.940478]\n",
      "4603 [D loss: 0.106931, acc.: 94.44%] [G loss: 5.410605]\n",
      "4604 [D loss: 0.012471, acc.: 100.00%] [G loss: 9.913627]\n",
      "4605 [D loss: 0.003506, acc.: 100.00%] [G loss: 9.567945]\n",
      "4606 [D loss: 0.141838, acc.: 94.44%] [G loss: 7.847738]\n",
      "4607 [D loss: 0.070282, acc.: 94.44%] [G loss: 7.204386]\n",
      "4608 [D loss: 0.060813, acc.: 94.44%] [G loss: 5.513463]\n",
      "4609 [D loss: 0.292971, acc.: 83.33%] [G loss: 8.537551]\n",
      "4610 [D loss: 0.017757, acc.: 100.00%] [G loss: 13.306903]\n",
      "4611 [D loss: 1.292355, acc.: 55.56%] [G loss: 4.347107]\n",
      "4612 [D loss: 0.342948, acc.: 88.89%] [G loss: 4.032328]\n",
      "4613 [D loss: 0.501843, acc.: 88.89%] [G loss: 3.887327]\n",
      "4614 [D loss: 0.304006, acc.: 83.33%] [G loss: 4.480494]\n",
      "4615 [D loss: 0.161836, acc.: 94.44%] [G loss: 5.751721]\n",
      "4616 [D loss: 0.120556, acc.: 94.44%] [G loss: 4.590755]\n",
      "4617 [D loss: 0.096272, acc.: 94.44%] [G loss: 5.876243]\n",
      "4618 [D loss: 0.024678, acc.: 100.00%] [G loss: 8.734377]\n",
      "4619 [D loss: 0.030579, acc.: 100.00%] [G loss: 7.408332]\n",
      "4620 [D loss: 0.057844, acc.: 100.00%] [G loss: 7.000981]\n",
      "4621 [D loss: 0.044245, acc.: 100.00%] [G loss: 4.628795]\n",
      "4622 [D loss: 0.081765, acc.: 94.44%] [G loss: 4.895791]\n",
      "4623 [D loss: 0.314722, acc.: 88.89%] [G loss: 7.327990]\n",
      "4624 [D loss: 0.053525, acc.: 94.44%] [G loss: 9.276159]\n",
      "4625 [D loss: 0.012135, acc.: 100.00%] [G loss: 5.904122]\n",
      "4626 [D loss: 0.044942, acc.: 100.00%] [G loss: 5.779953]\n",
      "4627 [D loss: 0.040785, acc.: 100.00%] [G loss: 4.544091]\n",
      "4628 [D loss: 0.054944, acc.: 100.00%] [G loss: 5.513083]\n",
      "4629 [D loss: 0.015578, acc.: 100.00%] [G loss: 6.221723]\n",
      "4630 [D loss: 0.055190, acc.: 94.44%] [G loss: 4.002615]\n",
      "4631 [D loss: 0.043053, acc.: 100.00%] [G loss: 6.981443]\n",
      "4632 [D loss: 0.078637, acc.: 100.00%] [G loss: 5.526456]\n",
      "4633 [D loss: 0.086502, acc.: 94.44%] [G loss: 6.465476]\n",
      "4634 [D loss: 0.011218, acc.: 100.00%] [G loss: 8.201776]\n",
      "4635 [D loss: 0.071444, acc.: 94.44%] [G loss: 7.340948]\n",
      "4636 [D loss: 0.106599, acc.: 94.44%] [G loss: 5.900198]\n",
      "4637 [D loss: 0.019365, acc.: 100.00%] [G loss: 7.381275]\n",
      "4638 [D loss: 0.072600, acc.: 100.00%] [G loss: 4.963830]\n",
      "4639 [D loss: 0.187422, acc.: 94.44%] [G loss: 5.707660]\n",
      "4640 [D loss: 0.076095, acc.: 94.44%] [G loss: 5.288562]\n",
      "4641 [D loss: 0.003793, acc.: 100.00%] [G loss: 7.784158]\n",
      "4642 [D loss: 0.043625, acc.: 100.00%] [G loss: 6.619501]\n",
      "4643 [D loss: 0.098674, acc.: 94.44%] [G loss: 6.628984]\n",
      "4644 [D loss: 0.013579, acc.: 100.00%] [G loss: 8.351399]\n",
      "4645 [D loss: 0.014107, acc.: 100.00%] [G loss: 7.345867]\n",
      "4646 [D loss: 0.136595, acc.: 94.44%] [G loss: 6.538938]\n",
      "4647 [D loss: 0.006655, acc.: 100.00%] [G loss: 5.462950]\n",
      "4648 [D loss: 0.111043, acc.: 94.44%] [G loss: 5.028329]\n",
      "4649 [D loss: 0.117556, acc.: 94.44%] [G loss: 5.008246]\n",
      "4650 [D loss: 0.041999, acc.: 100.00%] [G loss: 7.715089]\n",
      "4651 [D loss: 0.013643, acc.: 100.00%] [G loss: 8.719942]\n",
      "4652 [D loss: 0.019931, acc.: 100.00%] [G loss: 9.448750]\n",
      "4653 [D loss: 0.147022, acc.: 88.89%] [G loss: 5.707441]\n",
      "4654 [D loss: 0.155776, acc.: 94.44%] [G loss: 6.179025]\n",
      "4655 [D loss: 0.004140, acc.: 100.00%] [G loss: 6.890043]\n",
      "4656 [D loss: 0.075378, acc.: 94.44%] [G loss: 9.921072]\n",
      "4657 [D loss: 0.013245, acc.: 100.00%] [G loss: 7.670804]\n",
      "4658 [D loss: 0.163643, acc.: 94.44%] [G loss: 5.526408]\n",
      "4659 [D loss: 0.117388, acc.: 100.00%] [G loss: 4.244424]\n",
      "4660 [D loss: 0.009456, acc.: 100.00%] [G loss: 5.454405]\n",
      "4661 [D loss: 0.025960, acc.: 100.00%] [G loss: 4.423883]\n",
      "4662 [D loss: 0.352259, acc.: 88.89%] [G loss: 6.603844]\n",
      "4663 [D loss: 0.006478, acc.: 100.00%] [G loss: 9.615315]\n",
      "4664 [D loss: 0.065607, acc.: 94.44%] [G loss: 7.638936]\n",
      "4665 [D loss: 0.067674, acc.: 100.00%] [G loss: 5.025660]\n",
      "4666 [D loss: 0.048930, acc.: 100.00%] [G loss: 5.175578]\n",
      "4667 [D loss: 0.317404, acc.: 83.33%] [G loss: 5.552350]\n",
      "4668 [D loss: 0.003809, acc.: 100.00%] [G loss: 9.092516]\n",
      "4669 [D loss: 0.016649, acc.: 100.00%] [G loss: 7.760450]\n",
      "4670 [D loss: 0.074060, acc.: 100.00%] [G loss: 6.945652]\n",
      "4671 [D loss: 0.020539, acc.: 100.00%] [G loss: 8.542072]\n",
      "4672 [D loss: 0.430196, acc.: 77.78%] [G loss: 3.753161]\n",
      "4673 [D loss: 0.039779, acc.: 100.00%] [G loss: 5.515526]\n",
      "4674 [D loss: 0.053229, acc.: 100.00%] [G loss: 6.564584]\n",
      "4675 [D loss: 0.096509, acc.: 94.44%] [G loss: 6.010139]\n",
      "4676 [D loss: 0.029835, acc.: 100.00%] [G loss: 7.048709]\n",
      "4677 [D loss: 0.141308, acc.: 94.44%] [G loss: 5.667057]\n",
      "4678 [D loss: 0.098317, acc.: 100.00%] [G loss: 4.660767]\n",
      "4679 [D loss: 0.008781, acc.: 100.00%] [G loss: 9.236722]\n",
      "4680 [D loss: 0.008979, acc.: 100.00%] [G loss: 6.030037]\n",
      "4681 [D loss: 0.057324, acc.: 100.00%] [G loss: 6.508089]\n",
      "4682 [D loss: 0.042262, acc.: 100.00%] [G loss: 6.642473]\n",
      "4683 [D loss: 0.033702, acc.: 100.00%] [G loss: 5.206211]\n",
      "4684 [D loss: 0.108255, acc.: 94.44%] [G loss: 4.355296]\n",
      "4685 [D loss: 0.113644, acc.: 94.44%] [G loss: 6.048959]\n",
      "4686 [D loss: 0.026491, acc.: 100.00%] [G loss: 6.814439]\n",
      "4687 [D loss: 0.052005, acc.: 100.00%] [G loss: 7.379536]\n",
      "4688 [D loss: 0.009858, acc.: 100.00%] [G loss: 8.283261]\n",
      "4689 [D loss: 0.032322, acc.: 100.00%] [G loss: 6.565898]\n",
      "4690 [D loss: 0.034639, acc.: 100.00%] [G loss: 7.404319]\n",
      "4691 [D loss: 0.083275, acc.: 94.44%] [G loss: 6.736619]\n",
      "4692 [D loss: 0.022051, acc.: 100.00%] [G loss: 7.503045]\n",
      "4693 [D loss: 0.248914, acc.: 77.78%] [G loss: 6.155339]\n",
      "4694 [D loss: 0.238032, acc.: 94.44%] [G loss: 5.504012]\n",
      "4695 [D loss: 0.020580, acc.: 100.00%] [G loss: 9.493870]\n",
      "4696 [D loss: 0.066449, acc.: 100.00%] [G loss: 6.360946]\n",
      "4697 [D loss: 0.088070, acc.: 100.00%] [G loss: 6.043157]\n",
      "4698 [D loss: 0.009266, acc.: 100.00%] [G loss: 8.943131]\n",
      "4699 [D loss: 0.006860, acc.: 100.00%] [G loss: 8.919754]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700 [D loss: 0.016213, acc.: 100.00%] [G loss: 9.186079]\n",
      "4701 [D loss: 0.104509, acc.: 94.44%] [G loss: 5.054007]\n",
      "4702 [D loss: 0.064099, acc.: 94.44%] [G loss: 6.596852]\n",
      "4703 [D loss: 0.029872, acc.: 100.00%] [G loss: 6.604027]\n",
      "4704 [D loss: 0.049037, acc.: 94.44%] [G loss: 5.968901]\n",
      "4705 [D loss: 0.054627, acc.: 100.00%] [G loss: 6.258445]\n",
      "4706 [D loss: 0.015779, acc.: 100.00%] [G loss: 5.805821]\n",
      "4707 [D loss: 0.049779, acc.: 94.44%] [G loss: 4.264862]\n",
      "4708 [D loss: 0.037799, acc.: 100.00%] [G loss: 7.626029]\n",
      "4709 [D loss: 0.053582, acc.: 100.00%] [G loss: 4.651927]\n",
      "4710 [D loss: 0.103507, acc.: 94.44%] [G loss: 7.867868]\n",
      "4711 [D loss: 0.021813, acc.: 100.00%] [G loss: 6.212797]\n",
      "4712 [D loss: 0.078324, acc.: 100.00%] [G loss: 6.036853]\n",
      "4713 [D loss: 0.003298, acc.: 100.00%] [G loss: 7.187170]\n",
      "4714 [D loss: 0.027952, acc.: 100.00%] [G loss: 6.253560]\n",
      "4715 [D loss: 0.023298, acc.: 100.00%] [G loss: 7.904724]\n",
      "4716 [D loss: 0.016869, acc.: 100.00%] [G loss: 7.466237]\n",
      "4717 [D loss: 0.293275, acc.: 94.44%] [G loss: 5.679845]\n",
      "4718 [D loss: 0.031705, acc.: 100.00%] [G loss: 4.626556]\n",
      "4719 [D loss: 0.048322, acc.: 100.00%] [G loss: 6.112158]\n",
      "4720 [D loss: 0.015605, acc.: 100.00%] [G loss: 5.345599]\n",
      "4721 [D loss: 0.020455, acc.: 100.00%] [G loss: 6.652442]\n",
      "4722 [D loss: 0.351357, acc.: 83.33%] [G loss: 6.816543]\n",
      "4723 [D loss: 0.002852, acc.: 100.00%] [G loss: 10.050869]\n",
      "4724 [D loss: 0.016049, acc.: 100.00%] [G loss: 7.999123]\n",
      "4725 [D loss: 0.005498, acc.: 100.00%] [G loss: 7.429975]\n",
      "4726 [D loss: 0.152463, acc.: 88.89%] [G loss: 5.008059]\n",
      "4727 [D loss: 0.028953, acc.: 100.00%] [G loss: 8.910651]\n",
      "4728 [D loss: 0.064507, acc.: 100.00%] [G loss: 7.134734]\n",
      "4729 [D loss: 0.034845, acc.: 100.00%] [G loss: 6.048995]\n",
      "4730 [D loss: 0.037780, acc.: 100.00%] [G loss: 5.521140]\n",
      "4731 [D loss: 0.034227, acc.: 100.00%] [G loss: 6.327185]\n",
      "4732 [D loss: 0.023228, acc.: 100.00%] [G loss: 5.005214]\n",
      "4733 [D loss: 0.022228, acc.: 100.00%] [G loss: 5.552739]\n",
      "4734 [D loss: 0.137899, acc.: 88.89%] [G loss: 6.557249]\n",
      "4735 [D loss: 0.231408, acc.: 88.89%] [G loss: 6.421764]\n",
      "4736 [D loss: 0.069197, acc.: 100.00%] [G loss: 5.563595]\n",
      "4737 [D loss: 0.013417, acc.: 100.00%] [G loss: 7.037386]\n",
      "4738 [D loss: 0.032514, acc.: 100.00%] [G loss: 6.829659]\n",
      "4739 [D loss: 0.040796, acc.: 100.00%] [G loss: 8.076180]\n",
      "4740 [D loss: 0.046356, acc.: 100.00%] [G loss: 6.486149]\n",
      "4741 [D loss: 0.013200, acc.: 100.00%] [G loss: 7.393760]\n",
      "4742 [D loss: 0.050052, acc.: 100.00%] [G loss: 7.188934]\n",
      "4743 [D loss: 0.011005, acc.: 100.00%] [G loss: 6.697699]\n",
      "4744 [D loss: 0.053200, acc.: 100.00%] [G loss: 6.503711]\n",
      "4745 [D loss: 0.027116, acc.: 100.00%] [G loss: 6.076494]\n",
      "4746 [D loss: 0.014715, acc.: 100.00%] [G loss: 6.398458]\n",
      "4747 [D loss: 0.012478, acc.: 100.00%] [G loss: 7.691462]\n",
      "4748 [D loss: 0.133875, acc.: 94.44%] [G loss: 7.045140]\n",
      "4749 [D loss: 0.157600, acc.: 94.44%] [G loss: 7.416852]\n",
      "4750 [D loss: 0.290014, acc.: 88.89%] [G loss: 5.914240]\n",
      "4751 [D loss: 0.011265, acc.: 100.00%] [G loss: 5.978943]\n",
      "4752 [D loss: 0.102129, acc.: 100.00%] [G loss: 5.611875]\n",
      "4753 [D loss: 0.061286, acc.: 100.00%] [G loss: 6.217716]\n",
      "4754 [D loss: 0.013371, acc.: 100.00%] [G loss: 7.073569]\n",
      "4755 [D loss: 0.214075, acc.: 88.89%] [G loss: 6.211215]\n",
      "4756 [D loss: 0.032287, acc.: 100.00%] [G loss: 5.985469]\n",
      "4757 [D loss: 0.027841, acc.: 100.00%] [G loss: 6.633577]\n",
      "4758 [D loss: 0.005986, acc.: 100.00%] [G loss: 7.416336]\n",
      "4759 [D loss: 0.036238, acc.: 100.00%] [G loss: 4.983327]\n",
      "4760 [D loss: 0.211519, acc.: 94.44%] [G loss: 7.299474]\n",
      "4761 [D loss: 0.050012, acc.: 100.00%] [G loss: 7.704027]\n",
      "4762 [D loss: 0.008846, acc.: 100.00%] [G loss: 9.013759]\n",
      "4763 [D loss: 0.015653, acc.: 100.00%] [G loss: 9.740531]\n",
      "4764 [D loss: 0.012839, acc.: 100.00%] [G loss: 6.266078]\n",
      "4765 [D loss: 0.026019, acc.: 100.00%] [G loss: 6.205906]\n",
      "4766 [D loss: 0.043968, acc.: 100.00%] [G loss: 8.693475]\n",
      "4767 [D loss: 0.008996, acc.: 100.00%] [G loss: 7.359278]\n",
      "4768 [D loss: 0.036207, acc.: 100.00%] [G loss: 8.068829]\n",
      "4769 [D loss: 0.038214, acc.: 100.00%] [G loss: 7.199292]\n",
      "4770 [D loss: 0.038837, acc.: 100.00%] [G loss: 6.374611]\n",
      "4771 [D loss: 0.015374, acc.: 100.00%] [G loss: 7.431353]\n",
      "4772 [D loss: 0.047614, acc.: 100.00%] [G loss: 9.740589]\n",
      "4773 [D loss: 0.087846, acc.: 94.44%] [G loss: 9.827230]\n",
      "4774 [D loss: 0.109563, acc.: 94.44%] [G loss: 10.078948]\n",
      "4775 [D loss: 0.013567, acc.: 100.00%] [G loss: 9.987619]\n",
      "4776 [D loss: 0.152709, acc.: 94.44%] [G loss: 6.023236]\n",
      "4777 [D loss: 0.029372, acc.: 100.00%] [G loss: 8.194988]\n",
      "4778 [D loss: 0.026830, acc.: 100.00%] [G loss: 8.105287]\n",
      "4779 [D loss: 0.057314, acc.: 100.00%] [G loss: 6.968925]\n",
      "4780 [D loss: 0.035506, acc.: 100.00%] [G loss: 7.193956]\n",
      "4781 [D loss: 0.102494, acc.: 94.44%] [G loss: 7.308977]\n",
      "4782 [D loss: 0.111033, acc.: 94.44%] [G loss: 6.611852]\n",
      "4783 [D loss: 0.018797, acc.: 100.00%] [G loss: 5.581484]\n",
      "4784 [D loss: 0.271973, acc.: 83.33%] [G loss: 7.459038]\n",
      "4785 [D loss: 0.054190, acc.: 100.00%] [G loss: 7.622808]\n",
      "4786 [D loss: 0.203608, acc.: 94.44%] [G loss: 6.331669]\n",
      "4787 [D loss: 0.186705, acc.: 88.89%] [G loss: 5.646912]\n",
      "4788 [D loss: 0.065585, acc.: 100.00%] [G loss: 5.264780]\n",
      "4789 [D loss: 0.080647, acc.: 100.00%] [G loss: 7.784443]\n",
      "4790 [D loss: 0.238790, acc.: 83.33%] [G loss: 7.439856]\n",
      "4791 [D loss: 0.017319, acc.: 100.00%] [G loss: 7.046574]\n",
      "4792 [D loss: 0.052976, acc.: 100.00%] [G loss: 6.113339]\n",
      "4793 [D loss: 0.030825, acc.: 100.00%] [G loss: 6.836541]\n",
      "4794 [D loss: 0.163460, acc.: 88.89%] [G loss: 7.548650]\n",
      "4795 [D loss: 0.015695, acc.: 100.00%] [G loss: 7.386129]\n",
      "4796 [D loss: 0.336451, acc.: 94.44%] [G loss: 6.013999]\n",
      "4797 [D loss: 0.100018, acc.: 94.44%] [G loss: 4.561423]\n",
      "4798 [D loss: 0.006857, acc.: 100.00%] [G loss: 7.296456]\n",
      "4799 [D loss: 0.019985, acc.: 100.00%] [G loss: 5.600337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 [D loss: 0.027607, acc.: 100.00%] [G loss: 8.714710]\n",
      "4801 [D loss: 0.044125, acc.: 100.00%] [G loss: 7.473441]\n",
      "4802 [D loss: 0.052654, acc.: 94.44%] [G loss: 6.619019]\n",
      "4803 [D loss: 0.022301, acc.: 100.00%] [G loss: 6.751647]\n",
      "4804 [D loss: 0.011055, acc.: 100.00%] [G loss: 7.969460]\n",
      "4805 [D loss: 0.089744, acc.: 94.44%] [G loss: 9.592865]\n",
      "4806 [D loss: 0.043178, acc.: 100.00%] [G loss: 6.807141]\n",
      "4807 [D loss: 0.087211, acc.: 94.44%] [G loss: 7.521374]\n",
      "4808 [D loss: 0.085333, acc.: 100.00%] [G loss: 7.150793]\n",
      "4809 [D loss: 0.644788, acc.: 66.67%] [G loss: 5.625956]\n",
      "4810 [D loss: 0.076109, acc.: 94.44%] [G loss: 4.578459]\n",
      "4811 [D loss: 0.015659, acc.: 100.00%] [G loss: 7.846182]\n",
      "4812 [D loss: 0.203735, acc.: 94.44%] [G loss: 7.569677]\n",
      "4813 [D loss: 0.009873, acc.: 100.00%] [G loss: 8.935592]\n",
      "4814 [D loss: 0.123195, acc.: 94.44%] [G loss: 6.447972]\n",
      "4815 [D loss: 0.009721, acc.: 100.00%] [G loss: 6.030533]\n",
      "4816 [D loss: 0.211192, acc.: 83.33%] [G loss: 5.043490]\n",
      "4817 [D loss: 0.011140, acc.: 100.00%] [G loss: 6.280820]\n",
      "4818 [D loss: 0.005711, acc.: 100.00%] [G loss: 7.380680]\n",
      "4819 [D loss: 0.117723, acc.: 94.44%] [G loss: 5.492897]\n",
      "4820 [D loss: 0.034359, acc.: 100.00%] [G loss: 8.283935]\n",
      "4821 [D loss: 0.565195, acc.: 77.78%] [G loss: 5.989944]\n",
      "4822 [D loss: 0.010679, acc.: 100.00%] [G loss: 10.861481]\n",
      "4823 [D loss: 0.044151, acc.: 100.00%] [G loss: 4.891424]\n",
      "4824 [D loss: 0.207237, acc.: 88.89%] [G loss: 5.273310]\n",
      "4825 [D loss: 0.082651, acc.: 94.44%] [G loss: 7.401853]\n",
      "4826 [D loss: 0.068019, acc.: 94.44%] [G loss: 7.679690]\n",
      "4827 [D loss: 0.099163, acc.: 100.00%] [G loss: 6.940753]\n",
      "4828 [D loss: 0.123499, acc.: 94.44%] [G loss: 6.794688]\n",
      "4829 [D loss: 0.065376, acc.: 94.44%] [G loss: 5.941859]\n",
      "4830 [D loss: 0.013524, acc.: 100.00%] [G loss: 7.298440]\n",
      "4831 [D loss: 0.112736, acc.: 100.00%] [G loss: 6.062662]\n",
      "4832 [D loss: 0.012865, acc.: 100.00%] [G loss: 5.961016]\n",
      "4833 [D loss: 0.020354, acc.: 100.00%] [G loss: 5.802140]\n",
      "4834 [D loss: 0.017096, acc.: 100.00%] [G loss: 7.205899]\n",
      "4835 [D loss: 0.151297, acc.: 94.44%] [G loss: 4.920168]\n",
      "4836 [D loss: 0.133167, acc.: 94.44%] [G loss: 7.358686]\n",
      "4837 [D loss: 0.101698, acc.: 88.89%] [G loss: 5.140914]\n",
      "4838 [D loss: 0.048749, acc.: 94.44%] [G loss: 7.510817]\n",
      "4839 [D loss: 0.102141, acc.: 100.00%] [G loss: 5.427122]\n",
      "4840 [D loss: 0.030837, acc.: 100.00%] [G loss: 7.277356]\n",
      "4841 [D loss: 0.039244, acc.: 100.00%] [G loss: 8.440837]\n",
      "4842 [D loss: 0.007653, acc.: 100.00%] [G loss: 5.480279]\n",
      "4843 [D loss: 0.034817, acc.: 100.00%] [G loss: 6.802451]\n",
      "4844 [D loss: 0.029319, acc.: 100.00%] [G loss: 5.447775]\n",
      "4845 [D loss: 0.041755, acc.: 100.00%] [G loss: 6.465356]\n",
      "4846 [D loss: 0.074899, acc.: 100.00%] [G loss: 4.569417]\n",
      "4847 [D loss: 0.022297, acc.: 100.00%] [G loss: 5.095554]\n",
      "4848 [D loss: 0.006734, acc.: 100.00%] [G loss: 6.696676]\n",
      "4849 [D loss: 0.006206, acc.: 100.00%] [G loss: 5.991237]\n",
      "4850 [D loss: 0.175660, acc.: 94.44%] [G loss: 5.014148]\n",
      "4851 [D loss: 0.013866, acc.: 100.00%] [G loss: 8.886125]\n",
      "4852 [D loss: 0.225645, acc.: 88.89%] [G loss: 6.734278]\n",
      "4853 [D loss: 0.050991, acc.: 100.00%] [G loss: 8.646284]\n",
      "4854 [D loss: 0.017377, acc.: 100.00%] [G loss: 8.593711]\n",
      "4855 [D loss: 0.102437, acc.: 88.89%] [G loss: 7.796969]\n",
      "4856 [D loss: 0.041125, acc.: 100.00%] [G loss: 7.327020]\n",
      "4857 [D loss: 0.013405, acc.: 100.00%] [G loss: 8.337754]\n",
      "4858 [D loss: 0.030713, acc.: 100.00%] [G loss: 8.574987]\n",
      "4859 [D loss: 0.014036, acc.: 100.00%] [G loss: 10.575950]\n",
      "4860 [D loss: 0.029013, acc.: 100.00%] [G loss: 7.860587]\n",
      "4861 [D loss: 0.071188, acc.: 94.44%] [G loss: 7.875383]\n",
      "4862 [D loss: 0.010118, acc.: 100.00%] [G loss: 7.719866]\n",
      "4863 [D loss: 0.004884, acc.: 100.00%] [G loss: 6.917145]\n",
      "4864 [D loss: 0.040904, acc.: 100.00%] [G loss: 8.840931]\n",
      "4865 [D loss: 0.124659, acc.: 94.44%] [G loss: 6.269890]\n",
      "4866 [D loss: 0.038364, acc.: 100.00%] [G loss: 7.983946]\n",
      "4867 [D loss: 0.014825, acc.: 100.00%] [G loss: 8.831628]\n",
      "4868 [D loss: 0.051068, acc.: 100.00%] [G loss: 7.798589]\n",
      "4869 [D loss: 0.035949, acc.: 100.00%] [G loss: 6.377811]\n",
      "4870 [D loss: 0.018832, acc.: 100.00%] [G loss: 9.300682]\n",
      "4871 [D loss: 0.151579, acc.: 88.89%] [G loss: 6.623944]\n",
      "4872 [D loss: 0.014402, acc.: 100.00%] [G loss: 5.884146]\n",
      "4873 [D loss: 0.007565, acc.: 100.00%] [G loss: 6.513107]\n",
      "4874 [D loss: 0.006659, acc.: 100.00%] [G loss: 9.097075]\n",
      "4875 [D loss: 0.056240, acc.: 100.00%] [G loss: 6.685196]\n",
      "4876 [D loss: 0.021590, acc.: 100.00%] [G loss: 6.346060]\n",
      "4877 [D loss: 0.293803, acc.: 88.89%] [G loss: 8.254237]\n",
      "4878 [D loss: 0.011242, acc.: 100.00%] [G loss: 8.642673]\n",
      "4879 [D loss: 0.733705, acc.: 83.33%] [G loss: 5.532144]\n",
      "4880 [D loss: 0.199148, acc.: 88.89%] [G loss: 4.110013]\n",
      "4881 [D loss: 0.022044, acc.: 100.00%] [G loss: 7.046748]\n",
      "4882 [D loss: 0.030974, acc.: 100.00%] [G loss: 5.877739]\n",
      "4883 [D loss: 0.424490, acc.: 88.89%] [G loss: 7.915861]\n",
      "4884 [D loss: 0.065928, acc.: 100.00%] [G loss: 8.567743]\n",
      "4885 [D loss: 0.006080, acc.: 100.00%] [G loss: 9.664810]\n",
      "4886 [D loss: 0.041900, acc.: 100.00%] [G loss: 7.282077]\n",
      "4887 [D loss: 0.028160, acc.: 100.00%] [G loss: 7.282812]\n",
      "4888 [D loss: 0.030787, acc.: 100.00%] [G loss: 5.347963]\n",
      "4889 [D loss: 0.148511, acc.: 94.44%] [G loss: 6.824208]\n",
      "4890 [D loss: 0.021451, acc.: 100.00%] [G loss: 8.048539]\n",
      "4891 [D loss: 0.135982, acc.: 94.44%] [G loss: 5.906149]\n",
      "4892 [D loss: 0.049465, acc.: 100.00%] [G loss: 5.856557]\n",
      "4893 [D loss: 0.074591, acc.: 94.44%] [G loss: 6.663057]\n",
      "4894 [D loss: 0.111575, acc.: 94.44%] [G loss: 7.781855]\n",
      "4895 [D loss: 0.040447, acc.: 94.44%] [G loss: 8.718260]\n",
      "4896 [D loss: 0.006458, acc.: 100.00%] [G loss: 5.947018]\n",
      "4897 [D loss: 0.009781, acc.: 100.00%] [G loss: 6.205737]\n",
      "4898 [D loss: 0.039801, acc.: 100.00%] [G loss: 7.509274]\n",
      "4899 [D loss: 0.127521, acc.: 88.89%] [G loss: 6.823147]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900 [D loss: 0.064820, acc.: 94.44%] [G loss: 8.802380]\n",
      "4901 [D loss: 0.088792, acc.: 94.44%] [G loss: 4.968966]\n",
      "4902 [D loss: 0.016185, acc.: 100.00%] [G loss: 6.115877]\n",
      "4903 [D loss: 0.018913, acc.: 100.00%] [G loss: 5.497027]\n",
      "4904 [D loss: 0.014181, acc.: 100.00%] [G loss: 6.401626]\n",
      "4905 [D loss: 0.062888, acc.: 94.44%] [G loss: 4.961969]\n",
      "4906 [D loss: 0.047003, acc.: 94.44%] [G loss: 7.624018]\n",
      "4907 [D loss: 0.034725, acc.: 100.00%] [G loss: 5.030175]\n",
      "4908 [D loss: 0.004863, acc.: 100.00%] [G loss: 6.561237]\n",
      "4909 [D loss: 0.019993, acc.: 100.00%] [G loss: 6.938011]\n",
      "4910 [D loss: 0.130431, acc.: 94.44%] [G loss: 4.271101]\n",
      "4911 [D loss: 0.145311, acc.: 94.44%] [G loss: 7.560479]\n",
      "4912 [D loss: 0.036722, acc.: 100.00%] [G loss: 8.613165]\n",
      "4913 [D loss: 0.044563, acc.: 100.00%] [G loss: 9.243509]\n",
      "4914 [D loss: 0.040860, acc.: 100.00%] [G loss: 9.728489]\n",
      "4915 [D loss: 0.083856, acc.: 94.44%] [G loss: 9.658076]\n",
      "4916 [D loss: 0.141662, acc.: 88.89%] [G loss: 5.135421]\n",
      "4917 [D loss: 0.004000, acc.: 100.00%] [G loss: 6.200959]\n",
      "4918 [D loss: 0.138235, acc.: 94.44%] [G loss: 7.772421]\n",
      "4919 [D loss: 0.019092, acc.: 100.00%] [G loss: 8.500813]\n",
      "4920 [D loss: 0.497273, acc.: 77.78%] [G loss: 3.772054]\n",
      "4921 [D loss: 0.029913, acc.: 100.00%] [G loss: 5.447280]\n",
      "4922 [D loss: 0.111157, acc.: 94.44%] [G loss: 7.141985]\n",
      "4923 [D loss: 0.092035, acc.: 100.00%] [G loss: 7.666312]\n",
      "4924 [D loss: 0.238858, acc.: 83.33%] [G loss: 8.046598]\n",
      "4925 [D loss: 0.365593, acc.: 88.89%] [G loss: 7.281220]\n",
      "4926 [D loss: 0.066807, acc.: 94.44%] [G loss: 6.273264]\n",
      "4927 [D loss: 0.078496, acc.: 94.44%] [G loss: 7.459866]\n",
      "4928 [D loss: 0.023896, acc.: 100.00%] [G loss: 9.588715]\n",
      "4929 [D loss: 0.002185, acc.: 100.00%] [G loss: 8.878612]\n",
      "4930 [D loss: 0.108969, acc.: 94.44%] [G loss: 7.702137]\n",
      "4931 [D loss: 0.014145, acc.: 100.00%] [G loss: 8.077005]\n",
      "4932 [D loss: 0.034936, acc.: 100.00%] [G loss: 8.323702]\n",
      "4933 [D loss: 0.023031, acc.: 100.00%] [G loss: 7.969282]\n",
      "4934 [D loss: 0.015647, acc.: 100.00%] [G loss: 7.267687]\n",
      "4935 [D loss: 0.065657, acc.: 94.44%] [G loss: 7.731046]\n",
      "4936 [D loss: 0.035658, acc.: 100.00%] [G loss: 8.962962]\n",
      "4937 [D loss: 0.046829, acc.: 100.00%] [G loss: 6.578212]\n",
      "4938 [D loss: 0.171233, acc.: 88.89%] [G loss: 5.716952]\n",
      "4939 [D loss: 0.070284, acc.: 100.00%] [G loss: 4.072888]\n",
      "4940 [D loss: 0.018281, acc.: 100.00%] [G loss: 8.699462]\n",
      "4941 [D loss: 0.268047, acc.: 88.89%] [G loss: 7.693716]\n",
      "4942 [D loss: 0.031239, acc.: 100.00%] [G loss: 8.452135]\n",
      "4943 [D loss: 0.024156, acc.: 100.00%] [G loss: 8.839346]\n",
      "4944 [D loss: 0.154608, acc.: 94.44%] [G loss: 7.056139]\n",
      "4945 [D loss: 0.114991, acc.: 94.44%] [G loss: 5.474614]\n",
      "4946 [D loss: 0.114486, acc.: 94.44%] [G loss: 8.774791]\n",
      "4947 [D loss: 0.050795, acc.: 100.00%] [G loss: 7.236527]\n",
      "4948 [D loss: 0.037715, acc.: 100.00%] [G loss: 8.984256]\n",
      "4949 [D loss: 0.054075, acc.: 100.00%] [G loss: 5.750899]\n",
      "4950 [D loss: 0.018839, acc.: 100.00%] [G loss: 7.088900]\n",
      "4951 [D loss: 0.134997, acc.: 94.44%] [G loss: 5.585814]\n",
      "4952 [D loss: 0.024046, acc.: 100.00%] [G loss: 5.952500]\n",
      "4953 [D loss: 0.009837, acc.: 100.00%] [G loss: 6.972544]\n",
      "4954 [D loss: 0.093461, acc.: 94.44%] [G loss: 6.128052]\n",
      "4955 [D loss: 0.015160, acc.: 100.00%] [G loss: 8.093258]\n",
      "4956 [D loss: 0.113382, acc.: 94.44%] [G loss: 5.920192]\n",
      "4957 [D loss: 0.028860, acc.: 100.00%] [G loss: 9.139706]\n",
      "4958 [D loss: 0.216401, acc.: 94.44%] [G loss: 5.164047]\n",
      "4959 [D loss: 0.031279, acc.: 100.00%] [G loss: 5.913031]\n",
      "4960 [D loss: 0.055112, acc.: 100.00%] [G loss: 5.933267]\n",
      "4961 [D loss: 0.065037, acc.: 100.00%] [G loss: 6.682210]\n",
      "4962 [D loss: 0.010962, acc.: 100.00%] [G loss: 9.012695]\n",
      "4963 [D loss: 0.059905, acc.: 100.00%] [G loss: 4.535497]\n",
      "4964 [D loss: 0.212963, acc.: 94.44%] [G loss: 6.809237]\n",
      "4965 [D loss: 0.158265, acc.: 94.44%] [G loss: 6.128587]\n",
      "4966 [D loss: 0.003353, acc.: 100.00%] [G loss: 7.400571]\n",
      "4967 [D loss: 0.024366, acc.: 100.00%] [G loss: 6.837573]\n",
      "4968 [D loss: 0.273226, acc.: 83.33%] [G loss: 4.230713]\n",
      "4969 [D loss: 0.250159, acc.: 83.33%] [G loss: 6.095485]\n",
      "4970 [D loss: 0.039473, acc.: 100.00%] [G loss: 9.658275]\n",
      "4971 [D loss: 0.123002, acc.: 94.44%] [G loss: 3.798198]\n",
      "4972 [D loss: 0.075208, acc.: 100.00%] [G loss: 5.916151]\n",
      "4973 [D loss: 0.091293, acc.: 94.44%] [G loss: 7.704058]\n",
      "4974 [D loss: 0.016547, acc.: 100.00%] [G loss: 5.819124]\n",
      "4975 [D loss: 0.029397, acc.: 100.00%] [G loss: 6.967918]\n",
      "4976 [D loss: 0.020486, acc.: 100.00%] [G loss: 6.974230]\n",
      "4977 [D loss: 0.042479, acc.: 100.00%] [G loss: 9.224024]\n",
      "4978 [D loss: 0.003595, acc.: 100.00%] [G loss: 9.131019]\n",
      "4979 [D loss: 0.123205, acc.: 94.44%] [G loss: 7.629257]\n",
      "4980 [D loss: 0.026189, acc.: 100.00%] [G loss: 7.838877]\n",
      "4981 [D loss: 0.033182, acc.: 100.00%] [G loss: 8.927893]\n",
      "4982 [D loss: 0.056222, acc.: 94.44%] [G loss: 9.749342]\n",
      "4983 [D loss: 0.006573, acc.: 100.00%] [G loss: 7.682888]\n",
      "4984 [D loss: 0.068041, acc.: 94.44%] [G loss: 4.903086]\n",
      "4985 [D loss: 0.008226, acc.: 100.00%] [G loss: 6.742723]\n",
      "4986 [D loss: 0.002859, acc.: 100.00%] [G loss: 5.780888]\n",
      "4987 [D loss: 0.020086, acc.: 100.00%] [G loss: 5.131681]\n",
      "4988 [D loss: 0.025053, acc.: 100.00%] [G loss: 4.965487]\n",
      "4989 [D loss: 0.007174, acc.: 100.00%] [G loss: 7.121534]\n",
      "4990 [D loss: 0.066690, acc.: 94.44%] [G loss: 6.393778]\n",
      "4991 [D loss: 0.007883, acc.: 100.00%] [G loss: 6.870527]\n",
      "4992 [D loss: 0.077013, acc.: 100.00%] [G loss: 5.604610]\n",
      "4993 [D loss: 0.037434, acc.: 100.00%] [G loss: 8.070287]\n",
      "4994 [D loss: 0.077537, acc.: 100.00%] [G loss: 7.547097]\n",
      "4995 [D loss: 0.011479, acc.: 100.00%] [G loss: 7.138485]\n",
      "4996 [D loss: 0.007894, acc.: 100.00%] [G loss: 6.072658]\n",
      "4997 [D loss: 0.044991, acc.: 100.00%] [G loss: 8.776663]\n",
      "4998 [D loss: 0.050938, acc.: 100.00%] [G loss: 5.636984]\n",
      "4999 [D loss: 0.038391, acc.: 100.00%] [G loss: 4.818795]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 [D loss: 0.207142, acc.: 88.89%] [G loss: 7.690008]\n",
      "5001 [D loss: 0.024712, acc.: 100.00%] [G loss: 6.035645]\n",
      "5002 [D loss: 0.242500, acc.: 94.44%] [G loss: 6.294543]\n",
      "5003 [D loss: 0.068893, acc.: 100.00%] [G loss: 7.447214]\n",
      "5004 [D loss: 0.142855, acc.: 94.44%] [G loss: 5.783701]\n",
      "5005 [D loss: 0.013021, acc.: 100.00%] [G loss: 9.757273]\n",
      "5006 [D loss: 0.015211, acc.: 100.00%] [G loss: 6.862313]\n",
      "5007 [D loss: 0.012940, acc.: 100.00%] [G loss: 6.233262]\n",
      "5008 [D loss: 0.086640, acc.: 88.89%] [G loss: 6.975705]\n",
      "5009 [D loss: 1.039702, acc.: 72.22%] [G loss: 5.152544]\n",
      "5010 [D loss: 0.575164, acc.: 83.33%] [G loss: 8.049057]\n",
      "5011 [D loss: 0.038966, acc.: 100.00%] [G loss: 9.466529]\n",
      "5012 [D loss: 0.515793, acc.: 77.78%] [G loss: 4.813373]\n",
      "5013 [D loss: 0.126440, acc.: 94.44%] [G loss: 5.906380]\n",
      "5014 [D loss: 0.018372, acc.: 100.00%] [G loss: 5.395441]\n",
      "5015 [D loss: 0.250660, acc.: 88.89%] [G loss: 6.776626]\n",
      "5016 [D loss: 0.015258, acc.: 100.00%] [G loss: 7.584800]\n",
      "5017 [D loss: 0.257838, acc.: 94.44%] [G loss: 7.688456]\n",
      "5018 [D loss: 0.137749, acc.: 94.44%] [G loss: 8.892234]\n",
      "5019 [D loss: 0.016605, acc.: 100.00%] [G loss: 7.082251]\n",
      "5020 [D loss: 0.046233, acc.: 100.00%] [G loss: 7.899282]\n",
      "5021 [D loss: 0.294333, acc.: 88.89%] [G loss: 6.806851]\n",
      "5022 [D loss: 0.009068, acc.: 100.00%] [G loss: 6.252986]\n",
      "5023 [D loss: 0.308325, acc.: 83.33%] [G loss: 4.385408]\n",
      "5024 [D loss: 0.031375, acc.: 100.00%] [G loss: 4.838917]\n",
      "5025 [D loss: 0.027929, acc.: 100.00%] [G loss: 6.127525]\n",
      "5026 [D loss: 0.049922, acc.: 100.00%] [G loss: 7.134406]\n",
      "5027 [D loss: 0.221608, acc.: 94.44%] [G loss: 6.113022]\n",
      "5028 [D loss: 0.033738, acc.: 100.00%] [G loss: 5.831434]\n",
      "5029 [D loss: 0.265254, acc.: 94.44%] [G loss: 5.197965]\n",
      "5030 [D loss: 0.150453, acc.: 94.44%] [G loss: 6.996788]\n",
      "5031 [D loss: 0.103891, acc.: 94.44%] [G loss: 6.131761]\n",
      "5032 [D loss: 0.109321, acc.: 94.44%] [G loss: 5.844080]\n",
      "5033 [D loss: 0.117124, acc.: 100.00%] [G loss: 7.259845]\n",
      "5034 [D loss: 0.053129, acc.: 100.00%] [G loss: 6.388429]\n",
      "5035 [D loss: 0.063333, acc.: 94.44%] [G loss: 6.888746]\n",
      "5036 [D loss: 0.015152, acc.: 100.00%] [G loss: 5.091904]\n",
      "5037 [D loss: 0.008117, acc.: 100.00%] [G loss: 8.027179]\n",
      "5038 [D loss: 0.101321, acc.: 94.44%] [G loss: 5.582239]\n",
      "5039 [D loss: 0.140913, acc.: 94.44%] [G loss: 5.285878]\n",
      "5040 [D loss: 0.066925, acc.: 94.44%] [G loss: 5.480932]\n",
      "5041 [D loss: 0.023195, acc.: 100.00%] [G loss: 7.969223]\n",
      "5042 [D loss: 0.018284, acc.: 100.00%] [G loss: 9.471298]\n",
      "5043 [D loss: 0.051911, acc.: 100.00%] [G loss: 7.780799]\n",
      "5044 [D loss: 0.015418, acc.: 100.00%] [G loss: 5.165059]\n",
      "5045 [D loss: 0.164108, acc.: 88.89%] [G loss: 6.982650]\n",
      "5046 [D loss: 0.008624, acc.: 100.00%] [G loss: 8.281462]\n",
      "5047 [D loss: 0.060468, acc.: 100.00%] [G loss: 7.836493]\n",
      "5048 [D loss: 0.031167, acc.: 100.00%] [G loss: 4.909957]\n",
      "5049 [D loss: 0.065760, acc.: 100.00%] [G loss: 4.850793]\n",
      "5050 [D loss: 0.125129, acc.: 94.44%] [G loss: 7.780268]\n",
      "5051 [D loss: 0.026984, acc.: 100.00%] [G loss: 7.120275]\n",
      "5052 [D loss: 0.034430, acc.: 100.00%] [G loss: 4.705540]\n",
      "5053 [D loss: 0.096864, acc.: 94.44%] [G loss: 8.792408]\n",
      "5054 [D loss: 0.028813, acc.: 100.00%] [G loss: 6.889279]\n",
      "5055 [D loss: 0.082313, acc.: 94.44%] [G loss: 6.525999]\n",
      "5056 [D loss: 0.017568, acc.: 100.00%] [G loss: 7.186007]\n",
      "5057 [D loss: 0.024028, acc.: 100.00%] [G loss: 8.611370]\n",
      "5058 [D loss: 0.030725, acc.: 100.00%] [G loss: 6.111775]\n",
      "5059 [D loss: 0.014048, acc.: 100.00%] [G loss: 5.193627]\n",
      "5060 [D loss: 0.006716, acc.: 100.00%] [G loss: 5.270963]\n",
      "5061 [D loss: 0.048284, acc.: 100.00%] [G loss: 6.324133]\n",
      "5062 [D loss: 0.134949, acc.: 94.44%] [G loss: 7.365934]\n",
      "5063 [D loss: 0.068297, acc.: 94.44%] [G loss: 5.365443]\n",
      "5064 [D loss: 0.032029, acc.: 100.00%] [G loss: 3.637397]\n",
      "5065 [D loss: 0.013942, acc.: 100.00%] [G loss: 6.284292]\n",
      "5066 [D loss: 0.143960, acc.: 88.89%] [G loss: 6.684052]\n",
      "5067 [D loss: 0.043484, acc.: 100.00%] [G loss: 8.034306]\n",
      "5068 [D loss: 0.039595, acc.: 100.00%] [G loss: 5.651859]\n",
      "5069 [D loss: 0.139385, acc.: 94.44%] [G loss: 5.833683]\n",
      "5070 [D loss: 0.028010, acc.: 100.00%] [G loss: 8.395702]\n",
      "5071 [D loss: 0.121769, acc.: 94.44%] [G loss: 5.787344]\n",
      "5072 [D loss: 0.064908, acc.: 94.44%] [G loss: 6.200447]\n",
      "5073 [D loss: 0.062835, acc.: 100.00%] [G loss: 5.251041]\n",
      "5074 [D loss: 0.166277, acc.: 88.89%] [G loss: 5.224416]\n",
      "5075 [D loss: 0.294624, acc.: 88.89%] [G loss: 6.908038]\n",
      "5076 [D loss: 0.005489, acc.: 100.00%] [G loss: 10.308139]\n",
      "5077 [D loss: 0.011595, acc.: 100.00%] [G loss: 9.311749]\n",
      "5078 [D loss: 0.726372, acc.: 77.78%] [G loss: 4.026896]\n",
      "5079 [D loss: 0.074532, acc.: 94.44%] [G loss: 7.151245]\n",
      "5080 [D loss: 0.121281, acc.: 88.89%] [G loss: 8.309757]\n",
      "5081 [D loss: 0.053374, acc.: 100.00%] [G loss: 8.034170]\n",
      "5082 [D loss: 0.044953, acc.: 100.00%] [G loss: 8.553728]\n",
      "5083 [D loss: 0.055831, acc.: 100.00%] [G loss: 8.054666]\n",
      "5084 [D loss: 0.209089, acc.: 94.44%] [G loss: 7.763925]\n",
      "5085 [D loss: 0.068077, acc.: 100.00%] [G loss: 6.552857]\n",
      "5086 [D loss: 0.026109, acc.: 100.00%] [G loss: 7.596353]\n",
      "5087 [D loss: 0.030054, acc.: 100.00%] [G loss: 5.075028]\n",
      "5088 [D loss: 0.010291, acc.: 100.00%] [G loss: 9.124310]\n",
      "5089 [D loss: 0.121890, acc.: 88.89%] [G loss: 7.006319]\n",
      "5090 [D loss: 0.069068, acc.: 100.00%] [G loss: 6.106036]\n",
      "5091 [D loss: 0.021093, acc.: 100.00%] [G loss: 7.414971]\n",
      "5092 [D loss: 0.008441, acc.: 100.00%] [G loss: 6.136282]\n",
      "5093 [D loss: 0.055080, acc.: 100.00%] [G loss: 7.141012]\n",
      "5094 [D loss: 0.021716, acc.: 100.00%] [G loss: 7.407934]\n",
      "5095 [D loss: 0.036112, acc.: 100.00%] [G loss: 11.259855]\n",
      "5096 [D loss: 0.063898, acc.: 100.00%] [G loss: 5.257360]\n",
      "5097 [D loss: 0.101055, acc.: 94.44%] [G loss: 7.033327]\n",
      "5098 [D loss: 0.010728, acc.: 100.00%] [G loss: 6.814549]\n",
      "5099 [D loss: 0.016478, acc.: 100.00%] [G loss: 8.351337]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100 [D loss: 0.004226, acc.: 100.00%] [G loss: 8.250305]\n",
      "5101 [D loss: 0.248499, acc.: 88.89%] [G loss: 4.886527]\n",
      "5102 [D loss: 0.148637, acc.: 88.89%] [G loss: 7.164707]\n",
      "5103 [D loss: 0.096664, acc.: 94.44%] [G loss: 8.292620]\n",
      "5104 [D loss: 0.243524, acc.: 88.89%] [G loss: 5.577019]\n",
      "5105 [D loss: 0.087196, acc.: 94.44%] [G loss: 6.646661]\n",
      "5106 [D loss: 0.006103, acc.: 100.00%] [G loss: 7.386274]\n",
      "5107 [D loss: 0.002658, acc.: 100.00%] [G loss: 7.378094]\n",
      "5108 [D loss: 0.030504, acc.: 100.00%] [G loss: 8.373103]\n",
      "5109 [D loss: 0.039655, acc.: 100.00%] [G loss: 7.652150]\n",
      "5110 [D loss: 0.063800, acc.: 94.44%] [G loss: 7.914242]\n",
      "5111 [D loss: 0.009270, acc.: 100.00%] [G loss: 7.457387]\n",
      "5112 [D loss: 0.020337, acc.: 100.00%] [G loss: 9.933625]\n",
      "5113 [D loss: 0.086953, acc.: 94.44%] [G loss: 6.397830]\n",
      "5114 [D loss: 0.021954, acc.: 100.00%] [G loss: 6.630522]\n",
      "5115 [D loss: 0.009456, acc.: 100.00%] [G loss: 7.177786]\n",
      "5116 [D loss: 0.019057, acc.: 100.00%] [G loss: 8.310105]\n",
      "5117 [D loss: 0.007040, acc.: 100.00%] [G loss: 7.918221]\n",
      "5118 [D loss: 0.030506, acc.: 100.00%] [G loss: 5.298502]\n",
      "5119 [D loss: 0.075810, acc.: 94.44%] [G loss: 7.214625]\n",
      "5120 [D loss: 0.099682, acc.: 94.44%] [G loss: 3.721851]\n",
      "5121 [D loss: 0.026697, acc.: 100.00%] [G loss: 5.090849]\n",
      "5122 [D loss: 0.139876, acc.: 88.89%] [G loss: 7.987591]\n",
      "5123 [D loss: 0.003919, acc.: 100.00%] [G loss: 9.122334]\n",
      "5124 [D loss: 0.097390, acc.: 100.00%] [G loss: 6.807516]\n",
      "5125 [D loss: 0.271006, acc.: 88.89%] [G loss: 3.488399]\n",
      "5126 [D loss: 0.432803, acc.: 83.33%] [G loss: 6.018418]\n",
      "5127 [D loss: 0.025100, acc.: 100.00%] [G loss: 6.876312]\n",
      "5128 [D loss: 0.204384, acc.: 88.89%] [G loss: 5.441429]\n",
      "5129 [D loss: 0.192610, acc.: 88.89%] [G loss: 8.752223]\n",
      "5130 [D loss: 0.222013, acc.: 88.89%] [G loss: 5.337122]\n",
      "5131 [D loss: 0.040002, acc.: 100.00%] [G loss: 5.027420]\n",
      "5132 [D loss: 0.048335, acc.: 100.00%] [G loss: 5.894416]\n",
      "5133 [D loss: 0.028702, acc.: 100.00%] [G loss: 5.525305]\n",
      "5134 [D loss: 0.003961, acc.: 100.00%] [G loss: 9.141663]\n",
      "5135 [D loss: 0.018434, acc.: 100.00%] [G loss: 4.816164]\n",
      "5136 [D loss: 0.008879, acc.: 100.00%] [G loss: 6.679286]\n",
      "5137 [D loss: 0.047039, acc.: 100.00%] [G loss: 6.472132]\n",
      "5138 [D loss: 0.092121, acc.: 94.44%] [G loss: 6.584980]\n",
      "5139 [D loss: 0.028766, acc.: 100.00%] [G loss: 8.411984]\n",
      "5140 [D loss: 0.003796, acc.: 100.00%] [G loss: 7.852919]\n",
      "5141 [D loss: 0.284084, acc.: 77.78%] [G loss: 5.234450]\n",
      "5142 [D loss: 0.037118, acc.: 100.00%] [G loss: 5.871859]\n",
      "5143 [D loss: 0.098014, acc.: 94.44%] [G loss: 5.035596]\n",
      "5144 [D loss: 0.036656, acc.: 100.00%] [G loss: 5.861833]\n",
      "5145 [D loss: 0.152115, acc.: 88.89%] [G loss: 5.609424]\n",
      "5146 [D loss: 0.837890, acc.: 66.67%] [G loss: 7.864401]\n",
      "5147 [D loss: 0.065532, acc.: 100.00%] [G loss: 8.866269]\n",
      "5148 [D loss: 0.015363, acc.: 100.00%] [G loss: 8.701067]\n",
      "5149 [D loss: 0.080085, acc.: 100.00%] [G loss: 5.251325]\n",
      "5150 [D loss: 0.401984, acc.: 83.33%] [G loss: 4.702571]\n",
      "5151 [D loss: 0.064300, acc.: 100.00%] [G loss: 5.261686]\n",
      "5152 [D loss: 0.149300, acc.: 94.44%] [G loss: 5.717589]\n",
      "5153 [D loss: 0.099063, acc.: 94.44%] [G loss: 7.453709]\n",
      "5154 [D loss: 0.033011, acc.: 100.00%] [G loss: 6.632374]\n",
      "5155 [D loss: 0.013080, acc.: 100.00%] [G loss: 8.632233]\n",
      "5156 [D loss: 0.030623, acc.: 100.00%] [G loss: 7.150024]\n",
      "5157 [D loss: 0.043808, acc.: 100.00%] [G loss: 7.409458]\n",
      "5158 [D loss: 0.008443, acc.: 100.00%] [G loss: 6.316493]\n",
      "5159 [D loss: 0.021328, acc.: 100.00%] [G loss: 6.974391]\n",
      "5160 [D loss: 0.086597, acc.: 94.44%] [G loss: 7.570084]\n",
      "5161 [D loss: 0.003975, acc.: 100.00%] [G loss: 5.944524]\n",
      "5162 [D loss: 0.144619, acc.: 88.89%] [G loss: 3.832935]\n",
      "5163 [D loss: 0.146191, acc.: 94.44%] [G loss: 6.094526]\n",
      "5164 [D loss: 0.132231, acc.: 88.89%] [G loss: 6.296701]\n",
      "5165 [D loss: 0.030708, acc.: 100.00%] [G loss: 7.274880]\n",
      "5166 [D loss: 0.039474, acc.: 100.00%] [G loss: 5.876743]\n",
      "5167 [D loss: 0.007911, acc.: 100.00%] [G loss: 6.678729]\n",
      "5168 [D loss: 0.422265, acc.: 77.78%] [G loss: 4.240191]\n",
      "5169 [D loss: 0.033007, acc.: 100.00%] [G loss: 5.300285]\n",
      "5170 [D loss: 0.027803, acc.: 100.00%] [G loss: 5.522639]\n",
      "5171 [D loss: 0.454913, acc.: 77.78%] [G loss: 7.177378]\n",
      "5172 [D loss: 0.005416, acc.: 100.00%] [G loss: 6.834457]\n",
      "5173 [D loss: 0.061029, acc.: 94.44%] [G loss: 7.321186]\n",
      "5174 [D loss: 0.004309, acc.: 100.00%] [G loss: 6.616771]\n",
      "5175 [D loss: 0.198296, acc.: 94.44%] [G loss: 5.893408]\n",
      "5176 [D loss: 0.113330, acc.: 94.44%] [G loss: 5.227956]\n",
      "5177 [D loss: 0.127897, acc.: 94.44%] [G loss: 7.997507]\n",
      "5178 [D loss: 1.152511, acc.: 72.22%] [G loss: 7.721661]\n",
      "5179 [D loss: 0.082150, acc.: 94.44%] [G loss: 6.941208]\n",
      "5180 [D loss: 0.285102, acc.: 83.33%] [G loss: 6.895437]\n",
      "5181 [D loss: 0.051152, acc.: 100.00%] [G loss: 11.747095]\n",
      "5182 [D loss: 0.284557, acc.: 77.78%] [G loss: 7.252350]\n",
      "5183 [D loss: 0.036130, acc.: 100.00%] [G loss: 6.814535]\n",
      "5184 [D loss: 0.278923, acc.: 88.89%] [G loss: 7.288345]\n",
      "5185 [D loss: 0.089837, acc.: 100.00%] [G loss: 6.341962]\n",
      "5186 [D loss: 0.065541, acc.: 100.00%] [G loss: 7.486312]\n",
      "5187 [D loss: 0.014416, acc.: 100.00%] [G loss: 8.647667]\n",
      "5188 [D loss: 0.260564, acc.: 94.44%] [G loss: 7.451387]\n",
      "5189 [D loss: 0.017111, acc.: 100.00%] [G loss: 6.520430]\n",
      "5190 [D loss: 0.323346, acc.: 88.89%] [G loss: 7.643410]\n",
      "5191 [D loss: 0.031694, acc.: 100.00%] [G loss: 6.380035]\n",
      "5192 [D loss: 0.028113, acc.: 100.00%] [G loss: 6.960974]\n",
      "5193 [D loss: 0.057276, acc.: 100.00%] [G loss: 7.636591]\n",
      "5194 [D loss: 0.033469, acc.: 100.00%] [G loss: 6.251998]\n",
      "5195 [D loss: 0.115461, acc.: 94.44%] [G loss: 5.436131]\n",
      "5196 [D loss: 0.088903, acc.: 94.44%] [G loss: 6.808741]\n",
      "5197 [D loss: 0.125372, acc.: 94.44%] [G loss: 7.483492]\n",
      "5198 [D loss: 0.025849, acc.: 100.00%] [G loss: 4.811359]\n",
      "5199 [D loss: 0.022422, acc.: 100.00%] [G loss: 6.352991]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5200 [D loss: 0.029362, acc.: 100.00%] [G loss: 6.500815]\n",
      "5201 [D loss: 0.013541, acc.: 100.00%] [G loss: 5.007258]\n",
      "5202 [D loss: 0.276365, acc.: 83.33%] [G loss: 3.751021]\n",
      "5203 [D loss: 0.275770, acc.: 94.44%] [G loss: 6.676264]\n",
      "5204 [D loss: 0.046214, acc.: 100.00%] [G loss: 9.327424]\n",
      "5205 [D loss: 0.078020, acc.: 94.44%] [G loss: 5.582407]\n",
      "5206 [D loss: 0.322667, acc.: 88.89%] [G loss: 4.121466]\n",
      "5207 [D loss: 0.176571, acc.: 94.44%] [G loss: 6.254508]\n",
      "5208 [D loss: 0.026607, acc.: 100.00%] [G loss: 8.671462]\n",
      "5209 [D loss: 0.066341, acc.: 100.00%] [G loss: 6.438763]\n",
      "5210 [D loss: 0.096087, acc.: 94.44%] [G loss: 6.482570]\n",
      "5211 [D loss: 0.034096, acc.: 100.00%] [G loss: 7.317235]\n",
      "5212 [D loss: 0.067214, acc.: 94.44%] [G loss: 8.292516]\n",
      "5213 [D loss: 0.010836, acc.: 100.00%] [G loss: 6.049232]\n",
      "5214 [D loss: 0.134679, acc.: 94.44%] [G loss: 5.627648]\n",
      "5215 [D loss: 0.064940, acc.: 100.00%] [G loss: 7.072684]\n",
      "5216 [D loss: 0.067750, acc.: 94.44%] [G loss: 6.671682]\n",
      "5217 [D loss: 0.001756, acc.: 100.00%] [G loss: 6.505401]\n",
      "5218 [D loss: 0.086685, acc.: 94.44%] [G loss: 6.461667]\n",
      "5219 [D loss: 0.070077, acc.: 100.00%] [G loss: 5.821673]\n",
      "5220 [D loss: 0.182569, acc.: 88.89%] [G loss: 4.489904]\n",
      "5221 [D loss: 0.013870, acc.: 100.00%] [G loss: 8.097971]\n",
      "5222 [D loss: 0.072247, acc.: 100.00%] [G loss: 8.679836]\n",
      "5223 [D loss: 0.070169, acc.: 100.00%] [G loss: 7.616577]\n",
      "5224 [D loss: 0.075355, acc.: 94.44%] [G loss: 5.834986]\n",
      "5225 [D loss: 0.261739, acc.: 83.33%] [G loss: 5.678928]\n",
      "5226 [D loss: 0.339239, acc.: 83.33%] [G loss: 6.178373]\n",
      "5227 [D loss: 0.051036, acc.: 100.00%] [G loss: 6.720754]\n",
      "5228 [D loss: 0.019788, acc.: 100.00%] [G loss: 7.069238]\n",
      "5229 [D loss: 0.016370, acc.: 100.00%] [G loss: 9.248849]\n",
      "5230 [D loss: 0.070981, acc.: 100.00%] [G loss: 7.856622]\n",
      "5231 [D loss: 0.038729, acc.: 100.00%] [G loss: 7.363374]\n",
      "5232 [D loss: 0.026535, acc.: 100.00%] [G loss: 7.338392]\n",
      "5233 [D loss: 0.314711, acc.: 83.33%] [G loss: 7.844717]\n",
      "5234 [D loss: 0.120164, acc.: 94.44%] [G loss: 6.669365]\n",
      "5235 [D loss: 0.061692, acc.: 100.00%] [G loss: 7.516378]\n",
      "5236 [D loss: 0.208978, acc.: 88.89%] [G loss: 5.775156]\n",
      "5237 [D loss: 0.027881, acc.: 100.00%] [G loss: 5.949719]\n",
      "5238 [D loss: 0.022556, acc.: 100.00%] [G loss: 6.127923]\n",
      "5239 [D loss: 0.034299, acc.: 100.00%] [G loss: 6.085523]\n",
      "5240 [D loss: 0.028154, acc.: 100.00%] [G loss: 6.697354]\n",
      "5241 [D loss: 0.013666, acc.: 100.00%] [G loss: 6.990068]\n",
      "5242 [D loss: 0.039846, acc.: 100.00%] [G loss: 7.907410]\n",
      "5243 [D loss: 0.015992, acc.: 100.00%] [G loss: 6.453780]\n",
      "5244 [D loss: 0.018809, acc.: 100.00%] [G loss: 7.921513]\n",
      "5245 [D loss: 0.151580, acc.: 88.89%] [G loss: 3.389631]\n",
      "5246 [D loss: 0.062043, acc.: 100.00%] [G loss: 5.544820]\n",
      "5247 [D loss: 0.086936, acc.: 100.00%] [G loss: 7.270774]\n",
      "5248 [D loss: 0.004463, acc.: 100.00%] [G loss: 5.761930]\n",
      "5249 [D loss: 0.103758, acc.: 88.89%] [G loss: 5.598392]\n",
      "5250 [D loss: 0.017659, acc.: 100.00%] [G loss: 8.461413]\n",
      "5251 [D loss: 0.020684, acc.: 100.00%] [G loss: 9.654988]\n",
      "5252 [D loss: 0.054563, acc.: 100.00%] [G loss: 5.592494]\n",
      "5253 [D loss: 0.037788, acc.: 100.00%] [G loss: 6.490134]\n",
      "5254 [D loss: 0.039081, acc.: 100.00%] [G loss: 5.896408]\n",
      "5255 [D loss: 0.023414, acc.: 100.00%] [G loss: 6.324016]\n",
      "5256 [D loss: 0.012934, acc.: 100.00%] [G loss: 7.303224]\n",
      "5257 [D loss: 0.091723, acc.: 94.44%] [G loss: 6.399530]\n",
      "5258 [D loss: 0.015804, acc.: 100.00%] [G loss: 6.400391]\n",
      "5259 [D loss: 0.042959, acc.: 100.00%] [G loss: 7.663744]\n",
      "5260 [D loss: 0.058175, acc.: 100.00%] [G loss: 5.600574]\n",
      "5261 [D loss: 0.033556, acc.: 100.00%] [G loss: 4.742586]\n",
      "5262 [D loss: 0.133872, acc.: 88.89%] [G loss: 7.887965]\n",
      "5263 [D loss: 0.116277, acc.: 94.44%] [G loss: 6.671153]\n",
      "5264 [D loss: 0.270279, acc.: 83.33%] [G loss: 5.340136]\n",
      "5265 [D loss: 0.198028, acc.: 94.44%] [G loss: 4.976150]\n",
      "5266 [D loss: 0.080697, acc.: 100.00%] [G loss: 6.790518]\n",
      "5267 [D loss: 0.042837, acc.: 100.00%] [G loss: 7.317228]\n",
      "5268 [D loss: 0.020329, acc.: 100.00%] [G loss: 4.153290]\n",
      "5269 [D loss: 0.102505, acc.: 88.89%] [G loss: 7.081380]\n",
      "5270 [D loss: 0.032930, acc.: 100.00%] [G loss: 6.443333]\n",
      "5271 [D loss: 0.107991, acc.: 94.44%] [G loss: 6.781887]\n",
      "5272 [D loss: 0.019588, acc.: 100.00%] [G loss: 5.691461]\n",
      "5273 [D loss: 0.020424, acc.: 100.00%] [G loss: 8.433488]\n",
      "5274 [D loss: 0.030486, acc.: 100.00%] [G loss: 4.933460]\n",
      "5275 [D loss: 0.023923, acc.: 100.00%] [G loss: 6.970769]\n",
      "5276 [D loss: 0.020184, acc.: 100.00%] [G loss: 7.358184]\n",
      "5277 [D loss: 0.029811, acc.: 100.00%] [G loss: 7.659461]\n",
      "5278 [D loss: 0.004181, acc.: 100.00%] [G loss: 6.296579]\n",
      "5279 [D loss: 0.174191, acc.: 94.44%] [G loss: 4.298554]\n",
      "5280 [D loss: 0.123332, acc.: 94.44%] [G loss: 6.313808]\n",
      "5281 [D loss: 0.024394, acc.: 100.00%] [G loss: 6.799494]\n",
      "5282 [D loss: 0.095613, acc.: 94.44%] [G loss: 6.326067]\n",
      "5283 [D loss: 0.105652, acc.: 94.44%] [G loss: 5.106336]\n",
      "5284 [D loss: 0.010519, acc.: 100.00%] [G loss: 7.813201]\n",
      "5285 [D loss: 0.071200, acc.: 94.44%] [G loss: 6.751327]\n",
      "5286 [D loss: 0.019296, acc.: 100.00%] [G loss: 8.770820]\n",
      "5287 [D loss: 0.130882, acc.: 94.44%] [G loss: 4.250789]\n",
      "5288 [D loss: 0.074539, acc.: 94.44%] [G loss: 6.787167]\n",
      "5289 [D loss: 0.008849, acc.: 100.00%] [G loss: 5.052639]\n",
      "5290 [D loss: 0.174135, acc.: 88.89%] [G loss: 7.211986]\n",
      "5291 [D loss: 0.024179, acc.: 100.00%] [G loss: 6.635736]\n",
      "5292 [D loss: 0.185660, acc.: 88.89%] [G loss: 3.561807]\n",
      "5293 [D loss: 0.147382, acc.: 94.44%] [G loss: 6.765756]\n",
      "5294 [D loss: 0.092432, acc.: 100.00%] [G loss: 6.319766]\n",
      "5295 [D loss: 0.038299, acc.: 100.00%] [G loss: 6.637935]\n",
      "5296 [D loss: 0.006874, acc.: 100.00%] [G loss: 7.536469]\n",
      "5297 [D loss: 0.068188, acc.: 94.44%] [G loss: 5.046738]\n",
      "5298 [D loss: 0.026572, acc.: 100.00%] [G loss: 5.706106]\n",
      "5299 [D loss: 0.026262, acc.: 100.00%] [G loss: 5.290619]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 [D loss: 0.054900, acc.: 100.00%] [G loss: 5.657694]\n",
      "5301 [D loss: 0.030116, acc.: 100.00%] [G loss: 6.644346]\n",
      "5302 [D loss: 0.099079, acc.: 94.44%] [G loss: 6.162218]\n",
      "5303 [D loss: 0.070692, acc.: 94.44%] [G loss: 6.882111]\n",
      "5304 [D loss: 0.021563, acc.: 100.00%] [G loss: 6.026284]\n",
      "5305 [D loss: 0.040566, acc.: 100.00%] [G loss: 4.764351]\n",
      "5306 [D loss: 0.013444, acc.: 100.00%] [G loss: 5.595057]\n",
      "5307 [D loss: 0.023687, acc.: 100.00%] [G loss: 6.047376]\n",
      "5308 [D loss: 0.058092, acc.: 100.00%] [G loss: 6.989233]\n",
      "5309 [D loss: 0.031672, acc.: 100.00%] [G loss: 6.944943]\n",
      "5310 [D loss: 0.084794, acc.: 100.00%] [G loss: 6.835189]\n",
      "5311 [D loss: 0.042522, acc.: 100.00%] [G loss: 7.789089]\n",
      "5312 [D loss: 0.022562, acc.: 100.00%] [G loss: 8.666778]\n",
      "5313 [D loss: 0.031221, acc.: 100.00%] [G loss: 5.684662]\n",
      "5314 [D loss: 0.092024, acc.: 94.44%] [G loss: 6.834345]\n",
      "5315 [D loss: 0.018403, acc.: 100.00%] [G loss: 9.424722]\n",
      "5316 [D loss: 0.006066, acc.: 100.00%] [G loss: 6.799337]\n",
      "5317 [D loss: 0.008092, acc.: 100.00%] [G loss: 10.131886]\n",
      "5318 [D loss: 0.065441, acc.: 100.00%] [G loss: 7.927635]\n",
      "5319 [D loss: 0.059383, acc.: 100.00%] [G loss: 7.127045]\n",
      "5320 [D loss: 0.086596, acc.: 94.44%] [G loss: 8.308022]\n",
      "5321 [D loss: 0.039096, acc.: 100.00%] [G loss: 6.305867]\n",
      "5322 [D loss: 0.001972, acc.: 100.00%] [G loss: 7.424548]\n",
      "5323 [D loss: 0.394686, acc.: 77.78%] [G loss: 8.217480]\n",
      "5324 [D loss: 0.006271, acc.: 100.00%] [G loss: 9.177739]\n",
      "5325 [D loss: 0.021190, acc.: 100.00%] [G loss: 5.575935]\n",
      "5326 [D loss: 0.005394, acc.: 100.00%] [G loss: 6.185530]\n",
      "5327 [D loss: 0.095227, acc.: 94.44%] [G loss: 7.813016]\n",
      "5328 [D loss: 0.013812, acc.: 100.00%] [G loss: 10.577081]\n",
      "5329 [D loss: 0.024514, acc.: 100.00%] [G loss: 9.778344]\n",
      "5330 [D loss: 0.155050, acc.: 94.44%] [G loss: 7.696332]\n",
      "5331 [D loss: 0.001957, acc.: 100.00%] [G loss: 8.132414]\n",
      "5332 [D loss: 0.025279, acc.: 100.00%] [G loss: 10.057077]\n",
      "5333 [D loss: 0.015244, acc.: 100.00%] [G loss: 5.927349]\n",
      "5334 [D loss: 0.028167, acc.: 100.00%] [G loss: 7.083521]\n",
      "5335 [D loss: 0.073100, acc.: 100.00%] [G loss: 8.770606]\n",
      "5336 [D loss: 0.018253, acc.: 100.00%] [G loss: 7.944908]\n",
      "5337 [D loss: 0.024505, acc.: 100.00%] [G loss: 4.033155]\n",
      "5338 [D loss: 0.005288, acc.: 100.00%] [G loss: 7.547813]\n",
      "5339 [D loss: 0.047976, acc.: 100.00%] [G loss: 5.649138]\n",
      "5340 [D loss: 0.025838, acc.: 100.00%] [G loss: 6.742324]\n",
      "5341 [D loss: 0.046192, acc.: 100.00%] [G loss: 7.724871]\n",
      "5342 [D loss: 0.073467, acc.: 94.44%] [G loss: 7.647139]\n",
      "5343 [D loss: 0.008571, acc.: 100.00%] [G loss: 9.032948]\n",
      "5344 [D loss: 0.214356, acc.: 88.89%] [G loss: 3.049812]\n",
      "5345 [D loss: 0.120437, acc.: 94.44%] [G loss: 6.532845]\n",
      "5346 [D loss: 0.003597, acc.: 100.00%] [G loss: 7.162321]\n",
      "5347 [D loss: 0.038215, acc.: 100.00%] [G loss: 10.475590]\n",
      "5348 [D loss: 0.039602, acc.: 100.00%] [G loss: 5.559495]\n",
      "5349 [D loss: 0.015100, acc.: 100.00%] [G loss: 7.159433]\n",
      "5350 [D loss: 0.027587, acc.: 100.00%] [G loss: 7.633955]\n",
      "5351 [D loss: 0.327749, acc.: 88.89%] [G loss: 3.086055]\n",
      "5352 [D loss: 0.282090, acc.: 83.33%] [G loss: 8.841554]\n",
      "5353 [D loss: 0.035112, acc.: 100.00%] [G loss: 7.387458]\n",
      "5354 [D loss: 0.110022, acc.: 94.44%] [G loss: 6.290218]\n",
      "5355 [D loss: 0.034704, acc.: 100.00%] [G loss: 9.192787]\n",
      "5356 [D loss: 0.190960, acc.: 88.89%] [G loss: 5.298208]\n",
      "5357 [D loss: 0.058595, acc.: 94.44%] [G loss: 5.449603]\n",
      "5358 [D loss: 0.090908, acc.: 94.44%] [G loss: 6.813261]\n",
      "5359 [D loss: 0.053509, acc.: 100.00%] [G loss: 8.801263]\n",
      "5360 [D loss: 0.015115, acc.: 100.00%] [G loss: 6.400797]\n",
      "5361 [D loss: 0.042646, acc.: 100.00%] [G loss: 6.361446]\n",
      "5362 [D loss: 0.229526, acc.: 94.44%] [G loss: 6.448160]\n",
      "5363 [D loss: 0.061623, acc.: 100.00%] [G loss: 6.856022]\n",
      "5364 [D loss: 0.151985, acc.: 94.44%] [G loss: 5.053904]\n",
      "5365 [D loss: 0.130411, acc.: 94.44%] [G loss: 5.727903]\n",
      "5366 [D loss: 0.283394, acc.: 88.89%] [G loss: 7.373781]\n",
      "5367 [D loss: 0.062092, acc.: 100.00%] [G loss: 5.676512]\n",
      "5368 [D loss: 0.022370, acc.: 100.00%] [G loss: 7.088382]\n",
      "5369 [D loss: 0.099356, acc.: 100.00%] [G loss: 4.497726]\n",
      "5370 [D loss: 0.195029, acc.: 94.44%] [G loss: 7.330424]\n",
      "5371 [D loss: 0.079666, acc.: 94.44%] [G loss: 7.773464]\n",
      "5372 [D loss: 0.191210, acc.: 94.44%] [G loss: 5.328666]\n",
      "5373 [D loss: 0.043424, acc.: 100.00%] [G loss: 6.051937]\n",
      "5374 [D loss: 0.042680, acc.: 100.00%] [G loss: 6.786453]\n",
      "5375 [D loss: 0.023317, acc.: 100.00%] [G loss: 6.732267]\n",
      "5376 [D loss: 0.098407, acc.: 94.44%] [G loss: 6.281274]\n",
      "5377 [D loss: 0.107006, acc.: 94.44%] [G loss: 5.702265]\n",
      "5378 [D loss: 0.032204, acc.: 100.00%] [G loss: 7.843804]\n",
      "5379 [D loss: 0.121894, acc.: 94.44%] [G loss: 7.094560]\n",
      "5380 [D loss: 0.021990, acc.: 100.00%] [G loss: 7.216753]\n",
      "5381 [D loss: 0.235038, acc.: 88.89%] [G loss: 7.353926]\n",
      "5382 [D loss: 0.080908, acc.: 94.44%] [G loss: 7.259262]\n",
      "5383 [D loss: 0.005478, acc.: 100.00%] [G loss: 7.480926]\n",
      "5384 [D loss: 0.015278, acc.: 100.00%] [G loss: 7.364404]\n",
      "5385 [D loss: 0.024680, acc.: 100.00%] [G loss: 5.584870]\n",
      "5386 [D loss: 0.141771, acc.: 94.44%] [G loss: 4.514902]\n",
      "5387 [D loss: 0.322467, acc.: 83.33%] [G loss: 6.420809]\n",
      "5388 [D loss: 0.024596, acc.: 100.00%] [G loss: 6.954728]\n",
      "5389 [D loss: 0.019149, acc.: 100.00%] [G loss: 7.646343]\n",
      "5390 [D loss: 0.054100, acc.: 100.00%] [G loss: 5.979233]\n",
      "5391 [D loss: 0.035773, acc.: 100.00%] [G loss: 6.911273]\n",
      "5392 [D loss: 0.023581, acc.: 100.00%] [G loss: 7.227560]\n",
      "5393 [D loss: 0.012875, acc.: 100.00%] [G loss: 7.899534]\n",
      "5394 [D loss: 0.128824, acc.: 94.44%] [G loss: 7.496399]\n",
      "5395 [D loss: 0.045688, acc.: 100.00%] [G loss: 9.071164]\n",
      "5396 [D loss: 0.032342, acc.: 100.00%] [G loss: 6.873619]\n",
      "5397 [D loss: 0.031864, acc.: 100.00%] [G loss: 7.077754]\n",
      "5398 [D loss: 0.023772, acc.: 100.00%] [G loss: 8.445755]\n",
      "5399 [D loss: 0.190409, acc.: 94.44%] [G loss: 4.824604]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 [D loss: 0.059272, acc.: 100.00%] [G loss: 4.781893]\n",
      "5401 [D loss: 0.017785, acc.: 100.00%] [G loss: 5.095572]\n",
      "5402 [D loss: 0.039421, acc.: 100.00%] [G loss: 4.329530]\n",
      "5403 [D loss: 0.035208, acc.: 100.00%] [G loss: 4.726703]\n",
      "5404 [D loss: 0.311091, acc.: 77.78%] [G loss: 7.662988]\n",
      "5405 [D loss: 0.035803, acc.: 100.00%] [G loss: 11.875012]\n",
      "5406 [D loss: 0.398195, acc.: 88.89%] [G loss: 4.833623]\n",
      "5407 [D loss: 0.031912, acc.: 100.00%] [G loss: 6.750617]\n",
      "5408 [D loss: 0.342634, acc.: 83.33%] [G loss: 6.991236]\n",
      "5409 [D loss: 0.022425, acc.: 100.00%] [G loss: 6.822062]\n",
      "5410 [D loss: 0.106469, acc.: 94.44%] [G loss: 4.938700]\n",
      "5411 [D loss: 0.003033, acc.: 100.00%] [G loss: 9.383029]\n",
      "5412 [D loss: 0.152472, acc.: 94.44%] [G loss: 5.667368]\n",
      "5413 [D loss: 0.008193, acc.: 100.00%] [G loss: 5.691996]\n",
      "5414 [D loss: 0.031829, acc.: 100.00%] [G loss: 5.501588]\n",
      "5415 [D loss: 0.528266, acc.: 77.78%] [G loss: 8.700382]\n",
      "5416 [D loss: 0.126640, acc.: 94.44%] [G loss: 8.863685]\n",
      "5417 [D loss: 0.118513, acc.: 94.44%] [G loss: 6.502906]\n",
      "5418 [D loss: 0.021995, acc.: 100.00%] [G loss: 7.089807]\n",
      "5419 [D loss: 0.334750, acc.: 83.33%] [G loss: 4.845471]\n",
      "5420 [D loss: 0.082031, acc.: 94.44%] [G loss: 9.035068]\n",
      "5421 [D loss: 0.757263, acc.: 72.22%] [G loss: 4.190044]\n",
      "5422 [D loss: 0.223952, acc.: 88.89%] [G loss: 6.301364]\n",
      "5423 [D loss: 0.002278, acc.: 100.00%] [G loss: 7.957632]\n",
      "5424 [D loss: 0.374581, acc.: 83.33%] [G loss: 5.815526]\n",
      "5425 [D loss: 0.037647, acc.: 100.00%] [G loss: 7.490749]\n",
      "5426 [D loss: 0.017897, acc.: 100.00%] [G loss: 6.910497]\n",
      "5427 [D loss: 0.032899, acc.: 100.00%] [G loss: 7.149190]\n",
      "5428 [D loss: 0.073399, acc.: 100.00%] [G loss: 6.967963]\n",
      "5429 [D loss: 0.402662, acc.: 83.33%] [G loss: 7.868586]\n",
      "5430 [D loss: 0.146962, acc.: 94.44%] [G loss: 9.033692]\n",
      "5431 [D loss: 0.056904, acc.: 100.00%] [G loss: 5.908628]\n",
      "5432 [D loss: 0.056197, acc.: 94.44%] [G loss: 5.173557]\n",
      "5433 [D loss: 0.043667, acc.: 100.00%] [G loss: 4.612699]\n",
      "5434 [D loss: 0.076484, acc.: 94.44%] [G loss: 4.962777]\n",
      "5435 [D loss: 0.057317, acc.: 100.00%] [G loss: 4.968103]\n",
      "5436 [D loss: 0.240584, acc.: 94.44%] [G loss: 6.248446]\n",
      "5437 [D loss: 0.111250, acc.: 94.44%] [G loss: 9.269072]\n",
      "5438 [D loss: 0.025355, acc.: 100.00%] [G loss: 6.951097]\n",
      "5439 [D loss: 0.051113, acc.: 100.00%] [G loss: 5.196814]\n",
      "5440 [D loss: 0.033367, acc.: 100.00%] [G loss: 5.886173]\n",
      "5441 [D loss: 0.009949, acc.: 100.00%] [G loss: 8.308134]\n",
      "5442 [D loss: 0.047396, acc.: 100.00%] [G loss: 6.286388]\n",
      "5443 [D loss: 0.035521, acc.: 100.00%] [G loss: 6.590531]\n",
      "5444 [D loss: 0.016389, acc.: 100.00%] [G loss: 7.529882]\n",
      "5445 [D loss: 0.064500, acc.: 100.00%] [G loss: 5.415263]\n",
      "5446 [D loss: 0.017486, acc.: 100.00%] [G loss: 6.550709]\n",
      "5447 [D loss: 0.020866, acc.: 100.00%] [G loss: 6.024895]\n",
      "5448 [D loss: 0.067116, acc.: 100.00%] [G loss: 7.937777]\n",
      "5449 [D loss: 0.145128, acc.: 94.44%] [G loss: 7.791602]\n",
      "5450 [D loss: 0.024248, acc.: 100.00%] [G loss: 5.656977]\n",
      "5451 [D loss: 0.041999, acc.: 100.00%] [G loss: 6.680774]\n",
      "5452 [D loss: 0.042204, acc.: 100.00%] [G loss: 5.720511]\n",
      "5453 [D loss: 0.112164, acc.: 94.44%] [G loss: 5.526250]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-64699f43e10c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mg_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-a9188b593865>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;31m# Generate super resolution images from the random batch of images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mgen_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;31m# Train the discriminator (real classified as ones and generated as zeros)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_loss, d_loss = gan.train(epochs=15001, batch_size=9, save_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_loss)\n",
    "plt.plot(d_loss)\n",
    "plt.title('GAN Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Generator', 'Discriminator'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
